# typed: true

# DO NOT EDIT MANUALLY
# This is an autogenerated file for types exported from the `concurrent-ruby` gem.
# Please instead update this file by running `bin/tapioca gem concurrent-ruby`.


# {include:file:README.md}
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/constants.rb:1
module Concurrent
  extend ::Concurrent::Utility::EngineDetector
  extend ::Concurrent::Utility::NativeExtensionLoader
  extend ::Concurrent::Concern::Logging
  extend ::Concurrent::Concern::Deprecation

  private

  # Abort a currently running transaction - see `Concurrent::atomically`.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:139
  def abort_transaction; end

  # Run a block that reads and writes `TVar`s as a single atomic transaction.
  # With respect to the value of `TVar` objects, the transaction is atomic, in
  # that it either happens or it does not, consistent, in that the `TVar`
  # objects involved will never enter an illegal state, and isolated, in that
  # transactions never interfere with each other. You may recognise these
  # properties from database transactions.
  #
  # There are some very important and unusual semantics that you must be aware of:
  #
  # * Most importantly, the block that you pass to atomically may be executed
  #     more than once. In most cases your code should be free of
  #     side-effects, except for via TVar.
  #
  # * If an exception escapes an atomically block it will abort the transaction.
  #
  # * It is undefined behaviour to use callcc or Fiber with atomically.
  #
  # * If you create a new thread within an atomically, it will not be part of
  #     the transaction. Creating a thread counts as a side-effect.
  #
  # Transactions within transactions are flattened to a single transaction.
  #
  # @example
  #   a = new TVar(100_000)
  #   b = new TVar(100)
  #
  #   Concurrent::atomically do
  #     a.value -= 10
  #     b.value += 10
  #   end
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:82
  def atomically; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:56
  def call_dataflow(method, executor, *inputs, &block); end

  # Dataflow allows you to create a task that will be scheduled when all of its data dependencies are available.
  # {include:file:docs-source/dataflow.md}
  #
  # @param [Future] inputs zero or more `Future` operations that this dataflow depends upon
  #
  # @yield The operation to perform once all the dependencies are met
  # @yieldparam [Future] inputs each of the `Future` inputs to the dataflow
  # @yieldreturn [Object] the result of the block operation
  #
  # @return [Object] the result of all the operations
  #
  # @raise [ArgumentError] if no block is given
  # @raise [ArgumentError] if any of the inputs are not `IVar`s
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:34
  def dataflow(*inputs, &block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:44
  def dataflow!(*inputs, &block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:39
  def dataflow_with(executor, *inputs, &block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:49
  def dataflow_with!(executor, *inputs, &block); end

  # Leave a transaction without committing or aborting - see `Concurrent::atomically`.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:144
  def leave_transaction; end

  # @!macro monotonic_get_time
  #
  #   Returns the current time as tracked by the application monotonic clock.
  #
  #   @param [Symbol] unit the time unit to be returned, can be either
  #     :float_second, :float_millisecond, :float_microsecond, :second,
  #     :millisecond, :microsecond, or :nanosecond default to :float_second.
  #
  #   @return [Float] The current monotonic time since some unspecified
  #     starting point
  #
  #   @!macro monotonic_clock_warning
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/monotonic_time.rb:15
  def monotonic_time(unit = T.unsafe(nil)); end

  class << self
    # Abort a currently running transaction - see `Concurrent::atomically`.
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:148
    def abort_transaction; end

    # Run a block that reads and writes `TVar`s as a single atomic transaction.
    # With respect to the value of `TVar` objects, the transaction is atomic, in
    # that it either happens or it does not, consistent, in that the `TVar`
    # objects involved will never enter an illegal state, and isolated, in that
    # transactions never interfere with each other. You may recognise these
    # properties from database transactions.
    #
    # There are some very important and unusual semantics that you must be aware of:
    #
    # * Most importantly, the block that you pass to atomically may be executed
    #     more than once. In most cases your code should be free of
    #     side-effects, except for via TVar.
    #
    # * If an exception escapes an atomically block it will abort the transaction.
    #
    # * It is undefined behaviour to use callcc or Fiber with atomically.
    #
    # * If you create a new thread within an atomically, it will not be part of
    #     the transaction. Creating a thread counts as a side-effect.
    #
    # Transactions within transactions are flattened to a single transaction.
    #
    # @example
    #   a = new TVar(100_000)
    #   b = new TVar(100)
    #
    #   Concurrent::atomically do
    #     a.value -= 10
    #     b.value += 10
    #   end
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:148
    def atomically; end

    # Number of processors cores available for process scheduling.
    # This method takes in account the CPU quota if the process is inside a cgroup with a
    # dedicated CPU quota (typically Docker).
    # Otherwise it returns the same value as #processor_count but as a Float.
    #
    # For performance reasons the calculated value will be memoized on the first
    # call.
    #
    # @return [Float] number of available processors
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:194
    def available_processor_count; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:80
    def call_dataflow(method, executor, *inputs, &block); end

    # The maximum number of processors cores available for process scheduling.
    # Returns `nil` if there is no enforced limit, or a `Float` if the
    # process is inside a cgroup with a dedicated CPU quota (typically Docker).
    #
    # Note that nothing prevents setting a CPU quota higher than the actual number of
    # cores on the system.
    #
    # For performance reasons the calculated value will be memoized on the first
    # call.
    #
    # @return [nil, Float] Maximum number of available processors as set by a cgroup CPU quota, or nil if none set
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:209
    def cpu_quota; end

    # The CPU shares requested by the process. For performance reasons the calculated
    # value will be memoized on the first call.
    #
    # @return [Float, nil] CPU shares requested by the process, or nil if not set
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:217
    def cpu_shares; end

    # Create a simple logger with provided level and output.
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:38
    def create_simple_logger(level = T.unsafe(nil), output = T.unsafe(nil)); end

    # Create a stdlib logger with provided level and output.
    # If you use this deprecated method you might need to add logger to your Gemfile to avoid warnings from Ruby 3.3.5+.
    # @deprecated
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:73
    def create_stdlib_logger(level = T.unsafe(nil), output = T.unsafe(nil)); end

    # Dataflow allows you to create a task that will be scheduled when all of its data dependencies are available.
    # {include:file:docs-source/dataflow.md}
    #
    # @param [Future] inputs zero or more `Future` operations that this dataflow depends upon
    #
    # @yield The operation to perform once all the dependencies are met
    # @yieldparam [Future] inputs each of the `Future` inputs to the dataflow
    # @yieldreturn [Object] the result of the block operation
    #
    # @return [Object] the result of all the operations
    #
    # @raise [ArgumentError] if no block is given
    # @raise [ArgumentError] if any of the inputs are not `IVar`s
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:37
    def dataflow(*inputs, &block); end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:47
    def dataflow!(*inputs, &block); end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:42
    def dataflow_with(executor, *inputs, &block); end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:52
    def dataflow_with!(executor, *inputs, &block); end

    # Disables AtExit handlers including pool auto-termination handlers.
    # When disabled it will be the application programmer's responsibility
    # to ensure that the handlers are shutdown properly prior to application
    # exit by calling `AtExit.run` method.
    #
    # @note this option should be needed only because of `at_exit` ordering
    #   issues which may arise when running some of the testing frameworks.
    #   E.g. Minitest's test-suite runs itself in `at_exit` callback which
    #   executes after the pools are already terminated. Then auto termination
    #   needs to be disabled and called manually after test-suite ends.
    # @note This method should *never* be called
    #   from within a gem. It should *only* be used from within the main
    #   application and even then it should be used only when necessary.
    # @deprecated Has no effect since it is no longer needed, see https://github.com/ruby-concurrency/concurrent-ruby/pull/841.
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/configuration.rb:48
    def disable_at_exit_handlers!; end

    # General access point to global executors.
    # @param [Symbol, Executor] executor_identifier symbols:
    #   - :fast - {Concurrent.global_fast_executor}
    #   - :io - {Concurrent.global_io_executor}
    #   - :immediate - {Concurrent.global_immediate_executor}
    # @return [Executor]
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/configuration.rb:83
    def executor(executor_identifier); end

    # Global thread pool optimized for short, fast *operations*.
    #
    # @return [ThreadPoolExecutor] the thread pool
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/configuration.rb:55
    def global_fast_executor; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/configuration.rb:66
    def global_immediate_executor; end

    # Global thread pool optimized for long, blocking (IO) *tasks*.
    #
    # @return [ThreadPoolExecutor] the thread pool
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/configuration.rb:62
    def global_io_executor; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:114
    def global_logger; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:118
    def global_logger=(value); end

    # Global thread pool user for global *timers*.
    #
    # @return [Concurrent::TimerSet] the thread pool
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/configuration.rb:73
    def global_timer_set; end

    # Leave a transaction without committing or aborting - see `Concurrent::atomically`.
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:148
    def leave_transaction; end

    # @!macro monotonic_get_time
    #
    #   Returns the current time as tracked by the application monotonic clock.
    #
    #   @param [Symbol] unit the time unit to be returned, can be either
    #     :float_second, :float_millisecond, :float_microsecond, :second,
    #     :millisecond, :microsecond, or :nanosecond default to :float_second.
    #
    #   @return [Float] The current monotonic time since some unspecified
    #     starting point
    #
    #   @!macro monotonic_clock_warning
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/monotonic_time.rb:18
    def monotonic_time(unit = T.unsafe(nil)); end

    # @!visibility private
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/lock_local_var.rb:7
    def mutex_owned_per_thread?; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/configuration.rb:87
    def new_fast_executor(opts = T.unsafe(nil)); end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/configuration.rb:98
    def new_io_executor(opts = T.unsafe(nil)); end

    # Number of physical processor cores on the current system. For performance
    # reasons the calculated value will be memoized on the first call.
    #
    # On Windows the Win32 API will be queried for the `NumberOfCores from
    # Win32_Processor`. This will return the total number "of cores for the
    # current instance of the processor." On Unix-like operating systems either
    # the `hwprefs` or `sysctl` utility will be called in a subshell and the
    # returned value will be used. In the rare case where none of these methods
    # work or an exception is raised the function will simply return 1.
    #
    # @return [Integer] number physical processor cores on the current system
    #
    # @see https://github.com/grosser/parallel/blob/4fc8b89d08c7091fe0419ca8fba1ec3ce5a8d185/lib/parallel.rb
    #
    # @see http://msdn.microsoft.com/en-us/library/aa394373(v=vs.85).aspx
    # @see http://www.unix.com/man-page/osx/1/HWPREFS/
    # @see http://linux.die.net/man/8/sysctl
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:181
    def physical_processor_count; end

    # Number of processors seen by the OS and used for process scheduling. For
    # performance reasons the calculated value will be memoized on the first
    # call.
    #
    # When running under JRuby the Java runtime call
    # `java.lang.Runtime.getRuntime.availableProcessors` will be used. According
    # to the Java documentation this "value may change during a particular
    # invocation of the virtual machine... [applications] should therefore
    # occasionally poll this property." We still memoize this value once under
    # JRuby.
    #
    # Otherwise Ruby's Etc.nprocessors will be used.
    #
    # @return [Integer] number of processors seen by the OS or Java runtime
    #
    # @see http://docs.oracle.com/javase/6/docs/api/java/lang/Runtime.html#availableProcessors()
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:160
    def processor_count; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:142
    def processor_counter; end

    # Use logger created by #create_simple_logger to log concurrent-ruby messages.
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:66
    def use_simple_logger(level = T.unsafe(nil), output = T.unsafe(nil)); end

    # Use logger created by #create_stdlib_logger to log concurrent-ruby messages.
    # @deprecated
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:101
    def use_stdlib_logger(level = T.unsafe(nil), output = T.unsafe(nil)); end
  end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:38
class Concurrent::AbstractExchanger < ::Concurrent::Synchronization::Object
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:44
  def initialize; end

  # @!macro exchanger_method_do_exchange
  #
  #   Waits for another thread to arrive at this exchange point (unless the
  #   current thread is interrupted), and then transfers the given object to
  #   it, receiving its object in return. The timeout value indicates the
  #   approximate number of seconds the method should block while waiting
  #   for the exchange. When the timeout value is `nil` the method will
  #   block indefinitely.
  #
  #   @param [Object] value the value to exchange with another thread
  #   @param [Numeric, nil] timeout in seconds, `nil` blocks indefinitely
  #
  # @!macro exchanger_method_exchange
  #
  #   In some edge cases when a `timeout` is given a return value of `nil` may be
  #   ambiguous. Specifically, if `nil` is a valid value in the exchange it will
  #   be impossible to tell whether `nil` is the actual return value or if it
  #   signifies timeout. When `nil` is a valid value in the exchange consider
  #   using {#exchange!} or {#try_exchange} instead.
  #
  #   @return [Object] the value exchanged by the other thread or `nil` on timeout
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:69
  def exchange(value, timeout = T.unsafe(nil)); end

  # @!macro exchanger_method_do_exchange
  # @!macro exchanger_method_exchange_bang
  #
  #   On timeout a {Concurrent::TimeoutError} exception will be raised.
  #
  #   @return [Object] the value exchanged by the other thread
  #   @raise [Concurrent::TimeoutError] on timeout
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:80
  def exchange!(value, timeout = T.unsafe(nil)); end

  # @!macro exchanger_method_do_exchange
  # @!macro exchanger_method_try_exchange
  #
  #   The return value will be a {Concurrent::Maybe} set to `Just` on success or
  #   `Nothing` on timeout.
  #
  #   @return [Concurrent::Maybe] on success a `Just` maybe will be returned with
  #     the item exchanged by the other thread as `#value`; on timeout a
  #     `Nothing` maybe will be returned with {Concurrent::TimeoutError} as `#reason`
  #
  #   @example
  #
  #     exchanger = Concurrent::Exchanger.new
  #
  #     result = exchanger.exchange(:foo, 0.5)
  #
  #     if result.just?
  #       puts result.value #=> :bar
  #     else
  #       puts 'timeout'
  #     end
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:109
  def try_exchange(value, timeout = T.unsafe(nil)); end

  private

  # @!macro exchanger_method_do_exchange
  #
  # @return [Object, CANCEL] the value exchanged by the other thread; {CANCEL} on timeout
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:122
  def do_exchange(value, timeout); end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:41
Concurrent::AbstractExchanger::CANCEL = T.let(T.unsafe(nil), Object)

# @!macro abstract_executor_service_public_api
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:10
class Concurrent::AbstractExecutorService < ::Concurrent::Synchronization::LockableObject
  include ::Concurrent::Concern::Logging
  include ::Concurrent::ExecutorService
  include ::Concurrent::Concern::Deprecation

  # Create a new thread pool.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:23
  def initialize(opts = T.unsafe(nil), &block); end

  # @!macro executor_service_method_auto_terminate_setter
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:72
  def auto_terminate=(value); end

  # @!macro executor_service_method_auto_terminate_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:67
  def auto_terminate?; end

  # @!macro executor_service_attr_reader_fallback_policy
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:18
  def fallback_policy; end

  # @!macro executor_service_method_kill
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:42
  def kill; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:20
  def name; end

  # @!macro executor_service_method_running_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:52
  def running?; end

  # @!macro executor_service_method_shutdown
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:37
  def shutdown; end

  # @!macro executor_service_method_shutdown_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:62
  def shutdown?; end

  # @!macro executor_service_method_shuttingdown_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:57
  def shuttingdown?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:32
  def to_s; end

  # @!macro executor_service_method_wait_for_termination
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:47
  def wait_for_termination(timeout = T.unsafe(nil)); end

  private

  # Returns an action which executes the `fallback_policy` once the queue
  # size reaches `max_queue`. The reason for the indirection of an action
  # is so that the work can be deferred outside of synchronization.
  #
  # @param [Array] args the arguments to the task which is being handled.
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:85
  def fallback_action(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:126
  def ns_auto_terminate?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:106
  def ns_execute(*args, &task); end

  # @!macro executor_service_method_ns_kill_execution
  #
  #   Callback method called when the executor has been killed.
  #   The default behavior is to do nothing.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:122
  def ns_kill_execution; end

  # @!macro executor_service_method_ns_shutdown_execution
  #
  #   Callback method called when an orderly shutdown has completed.
  #   The default behavior is to signal all waiting threads.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:114
  def ns_shutdown_execution; end
end

# The set of possible fallback policies that may be set at thread pool creation.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb:15
Concurrent::AbstractExecutorService::FALLBACK_POLICIES = T.let(T.unsafe(nil), Array)

# @!visibility private
# @!macro internal_implementation_note
#
# An abstract implementation of local storage, with sub-classes for
# per-thread and per-fiber locals.
#
# Each execution context (EC, thread or fiber) has a lazily initialized array
# of local variable values. Each time a new local variable is created, we
# allocate an "index" for it.
#
# For example, if the allocated index is 1, that means slot #1 in EVERY EC's
# locals array will be used for the value of that variable.
#
# The good thing about using a per-EC structure to hold values, rather than
# a global, is that no synchronization is needed when reading and writing
# those values (since the structure is only ever accessed by a single
# thread).
#
# Of course, when a local variable is GC'd, 1) we need to recover its index
# for use by other new local variables (otherwise the locals arrays could
# get bigger and bigger with time), and 2) we need to null out all the
# references held in the now-unused slots (both to avoid blocking GC of those
# objects, and also to prevent "stale" values from being passed on to a new
# local when the index is reused).
#
# Because we need to null out freed slots, we need to keep references to
# ALL the locals arrays, so we can null out the appropriate slots in all of
# them. This is why we need to use a finalizer to clean up the locals array
# when the EC goes out of scope.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:35
class Concurrent::AbstractLocals
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:36
  def initialize; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:89
  def fetch(index); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:71
  def free_index(index); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:55
  def next_index(local); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:102
  def set(index, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:43
  def synchronize; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:48
  def weak_synchronize; end

  private

  # When the local goes out of scope, clean up that slot across all locals currently assigned.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:112
  def local_finalizer(index); end

  # Returns the locals for the current scope, or nil if none exist.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:128
  def locals; end

  # Returns the locals for the current scope, creating them if necessary.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:133
  def locals!; end

  # When a thread/fiber goes out of scope, remove the array from @all_arrays.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:119
  def thread_fiber_finalizer(array_object_id); end
end

# `Agent` is inspired by Clojure's [agent](http://clojure.org/agents)
# function. An agent is a shared, mutable variable providing independent,
# uncoordinated, *asynchronous* change of individual values. Best used when
# the value will undergo frequent, complex updates. Suitable when the result
# of an update does not need to be known immediately. `Agent` is (mostly)
# functionally equivalent to Clojure's agent, except where the runtime
# prevents parity.
#
# Agents are reactive, not autonomous - there is no imperative message loop
# and no blocking receive. The state of an Agent should be itself immutable
# and the `#value` of an Agent is always immediately available for reading by
# any thread without any messages, i.e. observation does not require
# cooperation or coordination.
#
# Agent action dispatches are made using the various `#send` methods. These
# methods always return immediately. At some point later, in another thread,
# the following will happen:
#
# 1. The given `action` will be applied to the state of the Agent and the
#    `args`, if any were supplied.
# 2. The return value of `action` will be passed to the validator lambda,
#    if one has been set on the Agent.
# 3. If the validator succeeds or if no validator was given, the return value
#    of the given `action` will become the new `#value` of the Agent. See
#    `#initialize` for details.
# 4. If any observers were added to the Agent, they will be notified. See
#    `#add_observer` for details.
# 5. If during the `action` execution any other dispatches are made (directly
#    or indirectly), they will be held until after the `#value` of the Agent
#    has been changed.
#
# If any exceptions are thrown by an action function, no nested dispatches
# will occur, and the exception will be cached in the Agent itself. When an
# Agent has errors cached, any subsequent interactions will immediately throw
# an exception, until the agent's errors are cleared. Agent errors can be
# examined with `#error` and the agent restarted with `#restart`.
#
# The actions of all Agents get interleaved amongst threads in a thread pool.
# At any point in time, at most one action for each Agent is being executed.
# Actions dispatched to an agent from another single agent or thread will
# occur in the order they were sent, potentially interleaved with actions
# dispatched to the same agent from other sources. The `#send` method should
# be used for actions that are CPU limited, while the `#send_off` method is
# appropriate for actions that may block on IO.
#
# Unlike in Clojure, `Agent` cannot participate in `Concurrent::TVar` transactions.
#
# ## Example
#
# ```
# def next_fibonacci(set = nil)
#   return [0, 1] if set.nil?
#   set + [set[-2..-1].reduce{|sum,x| sum + x }]
# end
#
# # create an agent with an initial value
# agent = Concurrent::Agent.new(next_fibonacci)
#
# # send a few update requests
# 5.times do
#   agent.send{|set| next_fibonacci(set) }
# end
#
# # wait for them to complete
# agent.await
#
# # get the current value
# agent.value #=> [0, 1, 1, 2, 3, 5, 8]
# ```
#
# ## Observation
#
# Agents support observers through the {Concurrent::Observable} mixin module.
# Notification of observers occurs every time an action dispatch returns and
# the new value is successfully validated. Observation will *not* occur if the
# action raises an exception, if validation fails, or when a {#restart} occurs.
#
# When notified the observer will receive three arguments: `time`, `old_value`,
# and `new_value`. The `time` argument is the time at which the value change
# occurred. The `old_value` is the value of the Agent when the action began
# processing. The `new_value` is the value to which the Agent was set when the
# action completed. Note that `old_value` and `new_value` may be the same.
# This is not an error. It simply means that the action returned the same
# value.
#
# ## Nested Actions
#
# It is possible for an Agent action to post further actions back to itself.
# The nested actions will be enqueued normally then processed *after* the
# outer action completes, in the order they were sent, possibly interleaved
# with action dispatches from other threads. Nested actions never deadlock
# with one another and a failure in a nested action will never affect the
# outer action.
#
# Nested actions can be called using the Agent reference from the enclosing
# scope or by passing the reference in as a "send" argument. Nested actions
# cannot be post using `self` from within the action block/proc/lambda; `self`
# in this context will not reference the Agent. The preferred method for
# dispatching nested actions is to pass the Agent as an argument. This allows
# Ruby to more effectively manage the closing scope.
#
# Prefer this:
#
# ```
# agent = Concurrent::Agent.new(0)
# agent.send(agent) do |value, this|
#   this.send {|v| v + 42 }
#   3.14
# end
# agent.value #=> 45.14
# ```
#
# Over this:
#
# ```
# agent = Concurrent::Agent.new(0)
# agent.send do |value|
#   agent.send {|v| v + 42 }
#   3.14
# end
# ```
#
# @!macro agent_await_warning
#
#   **NOTE** Never, *under any circumstances*, call any of the "await" methods
#   ({#await}, {#await_for}, {#await_for!}, and {#wait}) from within an action
#   block/proc/lambda. The call will block the Agent and will always fail.
#   Calling either {#await} or {#wait} (with a timeout of `nil`) will
#   hopelessly deadlock the Agent with no possibility of recovery.
#
# @!macro thread_safe_variable_comparison
#
# @see http://clojure.org/Agents Clojure Agents
# @see http://clojure.org/state Values and Change - Clojure's approach to Identity and State
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:145
class Concurrent::Agent < ::Concurrent::Synchronization::LockableObject
  include ::Concurrent::Concern::Observable

  # Create a new `Agent` with the given initial value and options.
  #
  # The `:validator` option must be `nil` or a side-effect free proc/lambda
  # which takes one argument. On any intended value change the validator, if
  # provided, will be called. If the new value is invalid the validator should
  # return `false` or raise an error.
  #
  # The `:error_handler` option must be `nil` or a proc/lambda which takes two
  # arguments. When an action raises an error or validation fails, either by
  # returning false or raising an error, the error handler will be called. The
  # arguments to the error handler will be a reference to the agent itself and
  # the error object which was raised.
  #
  # The `:error_mode` may be either `:continue` (the default if an error
  # handler is given) or `:fail` (the default if error handler nil or not
  # given).
  #
  # If an action being run by the agent throws an error or doesn't pass
  # validation the error handler, if present, will be called. After the
  # handler executes if the error mode is `:continue` the Agent will continue
  # as if neither the action that caused the error nor the error itself ever
  # happened.
  #
  # If the mode is `:fail` the Agent will become {#failed?} and will stop
  # accepting new action dispatches. Any previously queued actions will be
  # held until {#restart} is called. The {#value} method will still work,
  # returning the value of the Agent before the error.
  #
  # @param [Object] initial the initial value
  # @param [Hash] opts the configuration options
  #
  # @option opts [Symbol] :error_mode either `:continue` or `:fail`
  # @option opts [nil, Proc] :error_handler the (optional) error handler
  # @option opts [nil, Proc] :validator the (optional) validation procedure
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:220
  def initialize(initial, opts = T.unsafe(nil)); end

  # Dispatches an action to the Agent and returns immediately. Subsequently,
  # in a thread from a thread pool, the {#value} will be set to the return
  # value of the action. Appropriate for actions that may block on IO.
  #
  # @param [Proc] action the action dispatch to be enqueued
  # @return [Concurrent::Agent] self
  # @see #send_off
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:331
  def <<(action); end

  # Blocks the current thread (indefinitely!) until all actions dispatched
  # thus far, from this thread or nested by the Agent, have occurred. Will
  # block when {#failed?}. Will never return if a failed Agent is {#restart}
  # with `:clear_actions` true.
  #
  # Returns a reference to `self` to support method chaining:
  #
  # ```
  # current_value = agent.await.value
  # ```
  #
  # @return [Boolean] self
  #
  # @!macro agent_await_warning
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:350
  def await; end

  # Blocks the current thread until all actions dispatched thus far, from this
  # thread or nested by the Agent, have occurred, or the timeout (in seconds)
  # has elapsed.
  #
  # @param [Float] timeout the maximum number of seconds to wait
  # @return [Boolean] true if all actions complete before timeout else false
  #
  # @!macro agent_await_warning
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:363
  def await_for(timeout); end

  # Blocks the current thread until all actions dispatched thus far, from this
  # thread or nested by the Agent, have occurred, or the timeout (in seconds)
  # has elapsed.
  #
  # @param [Float] timeout the maximum number of seconds to wait
  # @return [Boolean] true if all actions complete before timeout
  #
  # @raise [Concurrent::TimeoutError] when timeout is reached
  #
  # @!macro agent_await_warning
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:377
  def await_for!(timeout); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:233
  def deref; end

  # When {#failed?} and {#error_mode} is `:fail`, returns the error object
  # which caused the failure, else `nil`. When {#error_mode} is `:continue`
  # will *always* return `nil`.
  #
  # @return [nil, Error] the error which caused the failure when {#failed?}
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:240
  def error; end

  # The error mode this Agent is operating in. See {#initialize} for details.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:184
  def error_mode; end

  # Is the Agent in a failed state?
  #
  # @see #restart
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:402
  def failed?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:298
  def post(*args, &action); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:244
  def reason; end

  # When an Agent is {#failed?}, changes the Agent {#value} to `new_value`
  # then un-fails the Agent so that action dispatches are allowed again. If
  # the `:clear_actions` option is give and true, any actions queued on the
  # Agent that were being held while it was failed will be discarded,
  # otherwise those held actions will proceed. The `new_value` must pass the
  # validator if any, or `restart` will raise an exception and the Agent will
  # remain failed with its old {#value} and {#error}. Observers, if any, will
  # not be notified of the new state.
  #
  # @param [Object] new_value the new value for the Agent once restarted
  # @param [Hash] opts the configuration options
  # @option opts [Symbol] :clear_actions true if all enqueued but unprocessed
  #   actions should be discarded on restart, else false (default: false)
  # @return [Boolean] true
  #
  # @raise [Concurrent:AgentError] when not failed
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:424
  def restart(new_value, opts = T.unsafe(nil)); end

  # @!macro agent_send
  #
  #   Dispatches an action to the Agent and returns immediately. Subsequently,
  #   in a thread from a thread pool, the {#value} will be set to the return
  #   value of the action. Action dispatches are only allowed when the Agent
  #   is not {#failed?}.
  #
  #   The action must be a block/proc/lambda which takes 1 or more arguments.
  #   The first argument is the current {#value} of the Agent. Any arguments
  #   passed to the send method via the `args` parameter will be passed to the
  #   action as the remaining arguments. The action must return the new value
  #   of the Agent.
  #
  #   * {#send} and {#send!} should be used for actions that are CPU limited
  #   * {#send_off}, {#send_off!}, and {#<<} are appropriate for actions that
  #     may block on IO
  #   * {#send_via} and {#send_via!} are used when a specific executor is to
  #     be used for the action
  #
  #   @param [Array<Object>] args zero or more arguments to be passed to
  #     the action
  #   @param [Proc] action the action dispatch to be enqueued
  #
  #   @yield [agent, value, *args] process the old value and return the new
  #   @yieldparam [Object] value the current {#value} of the Agent
  #   @yieldparam [Array<Object>] args zero or more arguments to pass to the
  #     action
  #   @yieldreturn [Object] the new value of the Agent
  #
  # @!macro send_return
  #   @return [Boolean] true if the action is successfully enqueued, false if
  #     the Agent is {#failed?}
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:278
  def send(*args, &action); end

  # @!macro agent_send
  #
  # @!macro send_bang_return_and_raise
  #   @return [Boolean] true if the action is successfully enqueued
  #   @raise [Concurrent::Agent::Error] if the Agent is {#failed?}
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:287
  def send!(*args, &action); end

  # @!macro agent_send
  # @!macro send_return
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:294
  def send_off(*args, &action); end

  # @!macro agent_send
  # @!macro send_bang_return_and_raise
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:302
  def send_off!(*args, &action); end

  # @!macro agent_send
  # @!macro send_return
  # @param [Concurrent::ExecutorService] executor the executor on which the
  #   action is to be dispatched
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:311
  def send_via(executor, *args, &action); end

  # @!macro agent_send
  # @!macro send_bang_return_and_raise
  # @param [Concurrent::ExecutorService] executor the executor on which the
  #   action is to be dispatched
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:319
  def send_via!(executor, *args, &action); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:406
  def stopped?; end

  # The current value (state) of the Agent, irrespective of any pending or
  # in-progress actions. The value is always available and is non-blocking.
  #
  # @return [Object] the current value
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:229
  def value; end

  # Blocks the current thread until all actions dispatched thus far, from this
  # thread or nested by the Agent, have occurred, or the timeout (in seconds)
  # has elapsed. Will block indefinitely when timeout is nil or not given.
  #
  # Provided mainly for consistency with other classes in this library. Prefer
  # the various `await` methods instead.
  #
  # @param [Float] timeout the maximum number of seconds to wait
  # @return [Boolean] true if all actions complete before timeout else false
  #
  # @!macro agent_await_warning
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:393
  def wait(timeout = T.unsafe(nil)); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:510
  def enqueue_action_job(action, args, executor); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:516
  def enqueue_await_job(latch); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:543
  def execute_next_job; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:576
  def handle_error(error); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:529
  def ns_enqueue_job(job, index = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:584
  def ns_find_last_job_for_thread; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:490
  def ns_initialize(initial, opts); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:539
  def ns_post_next_job; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:570
  def ns_validate(value); end

  class << self
    # Blocks the current thread (indefinitely!) until all actions dispatched
    # thus far to all the given Agents, from this thread or nested by the
    # given Agents, have occurred. Will block when any of the agents are
    # failed. Will never return if a failed Agent is restart with
    # `:clear_actions` true.
    #
    # @param [Array<Concurrent::Agent>] agents the Agents on which to wait
    # @return [Boolean] true
    #
    # @!macro agent_await_warning
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:449
    def await(*agents); end

    # Blocks the current thread until all actions dispatched thus far to all
    # the given Agents, from this thread or nested by the given Agents, have
    # occurred, or the timeout (in seconds) has elapsed.
    #
    # @param [Float] timeout the maximum number of seconds to wait
    # @param [Array<Concurrent::Agent>] agents the Agents on which to wait
    # @return [Boolean] true if all actions complete before timeout else false
    #
    # @!macro agent_await_warning
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:463
    def await_for(timeout, *agents); end

    # Blocks the current thread until all actions dispatched thus far to all
    # the given Agents, from this thread or nested by the given Agents, have
    # occurred, or the timeout (in seconds) has elapsed.
    #
    # @param [Float] timeout the maximum number of seconds to wait
    # @param [Array<Concurrent::Agent>] agents the Agents on which to wait
    # @return [Boolean] true if all actions complete before timeout
    #
    # @raise [Concurrent::TimeoutError] when timeout is reached
    # @!macro agent_await_warning
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:482
    def await_for!(timeout, *agents); end
  end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:154
Concurrent::Agent::AWAIT_ACTION = T.let(T.unsafe(nil), Proc)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:151
Concurrent::Agent::AWAIT_FLAG = T.let(T.unsafe(nil), Object)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:157
Concurrent::Agent::DEFAULT_ERROR_HANDLER = T.let(T.unsafe(nil), Proc)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:160
Concurrent::Agent::DEFAULT_VALIDATOR = T.let(T.unsafe(nil), Proc)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:148
Concurrent::Agent::ERROR_MODES = T.let(T.unsafe(nil), Array)

# Raised during action processing or any other time in an Agent's lifecycle.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:167
class Concurrent::Agent::Error < ::StandardError
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:168
  def initialize(message = T.unsafe(nil)); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
class Concurrent::Agent::Job < ::Struct
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
  def action; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
  def action=(_); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
  def args; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
  def args=(_); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
  def caller; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
  def caller=(_); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
  def executor; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
  def executor=(_); end

  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
    def [](*_arg0); end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
    def inspect; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
    def keyword_init?; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
    def members; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:163
    def new(*_arg0); end
  end
end

# Raised when a new value obtained during action processing or at `#restart`
# fails validation.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:176
class Concurrent::Agent::ValidationError < ::Concurrent::Agent::Error
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/agent.rb:177
  def initialize(message = T.unsafe(nil)); end
end

# @!macro concurrent_array
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/array.rb:53
class Concurrent::Array < ::Array; end

# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/array.rb:22
Concurrent::ArrayImplementation = Array

# A mixin module that provides simple asynchronous behavior to a class,
# turning it into a simple actor. Loosely based on Erlang's
# [gen_server](http://www.erlang.org/doc/man/gen_server.html), but without
# supervision or linking.
#
# A more feature-rich {Concurrent::Actor} is also available when the
# capabilities of `Async` are too limited.
#
# ```cucumber
# Feature:
#   As a stateful, plain old Ruby class
#   I want safe, asynchronous behavior
#   So my long-running methods don't block the main thread
# ```
#
# The `Async` module is a way to mix simple yet powerful asynchronous
# capabilities into any plain old Ruby object or class, turning each object
# into a simple Actor. Method calls are processed on a background thread. The
# caller is free to perform other actions while processing occurs in the
# background.
#
# Method calls to the asynchronous object are made via two proxy methods:
# `async` (alias `cast`) and `await` (alias `call`). These proxy methods post
# the method call to the object's background thread and return a "future"
# which will eventually contain the result of the method call.
#
# This behavior is loosely patterned after Erlang's `gen_server` behavior.
# When an Erlang module implements the `gen_server` behavior it becomes
# inherently asynchronous. The `start` or `start_link` function spawns a
# process (similar to a thread but much more lightweight and efficient) and
# returns the ID of the process. Using the process ID, other processes can
# send messages to the `gen_server` via the `cast` and `call` methods. Unlike
# Erlang's `gen_server`, however, `Async` classes do not support linking or
# supervision trees.
#
# ## Basic Usage
#
# When this module is mixed into a class, objects of the class become inherently
# asynchronous. Each object gets its own background thread on which to post
# asynchronous method calls. Asynchronous method calls are executed in the
# background one at a time in the order they are received.
#
# To create an asynchronous class, simply mix in the `Concurrent::Async` module:
#
# ```
# class Hello
#   include Concurrent::Async
#
#   def hello(name)
#     "Hello, #{name}!"
#   end
# end
# ```
#
# Mixing this module into a class provides each object two proxy methods:
# `async` and `await`. These methods are thread safe with respect to the
# enclosing object. The former proxy allows methods to be called
# asynchronously by posting to the object's internal thread. The latter proxy
# allows a method to be called synchronously but does so safely with respect
# to any pending asynchronous method calls and ensures proper ordering. Both
# methods return a {Concurrent::IVar} which can be inspected for the result
# of the proxied method call. Calling a method with `async` will return a
# `:pending` `IVar` whereas `await` will return a `:complete` `IVar`.
#
# ```
# class Echo
#   include Concurrent::Async
#
#   def echo(msg)
#     print "#{msg}\n"
#   end
# end
#
# horn = Echo.new
# horn.echo('zero')      # synchronous, not thread-safe
#                        # returns the actual return value of the method
#
# horn.async.echo('one') # asynchronous, non-blocking, thread-safe
#                        # returns an IVar in the :pending state
#
# horn.await.echo('two') # synchronous, blocking, thread-safe
#                        # returns an IVar in the :complete state
# ```
#
# ## Let It Fail
#
# The `async` and `await` proxy methods have built-in error protection based
# on Erlang's famous "let it fail" philosophy. Instance methods should not be
# programmed defensively. When an exception is raised by a delegated method
# the proxy will rescue the exception, expose it to the caller as the `reason`
# attribute of the returned future, then process the next method call.
#
# ## Calling Methods Internally
#
# External method calls should *always* use the `async` and `await` proxy
# methods. When one method calls another method, the `async` proxy should
# rarely be used and the `await` proxy should *never* be used.
#
# When an object calls one of its own methods using the `await` proxy the
# second call will be enqueued *behind* the currently running method call.
# Any attempt to wait on the result will fail as the second call will never
# run until after the current call completes.
#
# Calling a method using the `await` proxy from within a method that was
# itself called using `async` or `await` will irreversibly deadlock the
# object. Do *not* do this, ever.
#
# ## Instance Variables and Attribute Accessors
#
# Instance variables do not need to be thread-safe so long as they are private.
# Asynchronous method calls are processed in the order they are received and
# are processed one at a time. Therefore private instance variables can only
# be accessed by one thread at a time. This is inherently thread-safe.
#
# When using private instance variables within asynchronous methods, the best
# practice is to read the instance variable into a local variable at the start
# of the method then update the instance variable at the *end* of the method.
# This way, should an exception be raised during method execution the internal
# state of the object will not have been changed.
#
# ### Reader Attributes
#
# The use of `attr_reader` is discouraged. Internal state exposed externally,
# when necessary, should be done through accessor methods. The instance
# variables exposed by these methods *must* be thread-safe, or they must be
# called using the `async` and `await` proxy methods. These two approaches are
# subtly different.
#
# When internal state is accessed via the `async` and `await` proxy methods,
# the returned value represents the object's state *at the time the call is
# processed*, which may *not* be the state of the object at the time the call
# is made.
#
# To get the state *at the current* time, irrespective of an enqueued method
# calls, a reader method must be called directly. This is inherently unsafe
# unless the instance variable is itself thread-safe, preferably using one
# of the thread-safe classes within this library. Because the thread-safe
# classes within this library are internally-locking or non-locking, they can
# be safely used from within asynchronous methods without causing deadlocks.
#
# Generally speaking, the best practice is to *not* expose internal state via
# reader methods. The best practice is to simply use the method's return value.
#
# ### Writer Attributes
#
# Writer attributes should never be used with asynchronous classes. Changing
# the state externally, even when done in the thread-safe way, is not logically
# consistent. Changes to state need to be timed with respect to all asynchronous
# method calls which my be in-process or enqueued. The only safe practice is to
# pass all necessary data to each method as arguments and let the method update
# the internal state as necessary.
#
# ## Class Constants, Variables, and Methods
#
# ### Class Constants
#
# Class constants do not need to be thread-safe. Since they are read-only and
# immutable they may be safely read both externally and from within
# asynchronous methods.
#
# ### Class Variables
#
# Class variables should be avoided. Class variables represent shared state.
# Shared state is anathema to concurrency. Should there be a need to share
# state using class variables they *must* be thread-safe, preferably
# using the thread-safe classes within this library. When updating class
# variables, never assign a new value/object to the variable itself. Assignment
# is not thread-safe in Ruby. Instead, use the thread-safe update functions
# of the variable itself to change the value.
#
# The best practice is to *never* use class variables with `Async` classes.
#
# ### Class Methods
#
# Class methods which are pure functions are safe. Class methods which modify
# class variables should be avoided, for all the reasons listed above.
#
# ## An Important Note About Thread Safe Guarantees
#
# > Thread safe guarantees can only be made when asynchronous method calls
# > are not mixed with direct method calls. Use only direct method calls
# > when the object is used exclusively on a single thread. Use only
# > `async` and `await` when the object is shared between threads. Once you
# > call a method using `async` or `await`, you should no longer call methods
# > directly on the object. Use `async` and `await` exclusively from then on.
#
# @example
#
#   class Echo
#     include Concurrent::Async
#
#     def echo(msg)
#       print "#{msg}\n"
#     end
#   end
#
#   horn = Echo.new
#   horn.echo('zero')      # synchronous, not thread-safe
#                          # returns the actual return value of the method
#
#   horn.async.echo('one') # asynchronous, non-blocking, thread-safe
#                          # returns an IVar in the :pending state
#
#   horn.await.echo('two') # synchronous, blocking, thread-safe
#                          # returns an IVar in the :complete state
#
# @see Concurrent::Actor
# @see https://en.wikipedia.org/wiki/Actor_model "Actor Model" at Wikipedia
# @see http://www.erlang.org/doc/man/gen_server.html Erlang gen_server
# @see http://c2.com/cgi/wiki?LetItCrash "Let It Crash" at http://c2.com/
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:217
module Concurrent::Async
  mixes_in_class_methods ::Concurrent::Async::ClassMethods

  # Causes the chained method call to be performed asynchronously on the
  # object's thread. The delegated method will return a future in the
  # `:pending` state and the method call will have been scheduled on the
  # object's thread. The final disposition of the method call can be obtained
  # by inspecting the returned future.
  #
  # @!macro async_thread_safety_warning
  #   @note The method call is guaranteed to be thread safe with respect to
  #     all other method calls against the same object that are called with
  #     either `async` or `await`. The mutable nature of Ruby references
  #     (and object orientation in general) prevent any other thread safety
  #     guarantees. Do NOT mix direct method calls with delegated method calls.
  #     Use *only* delegated method calls when sharing the object between threads.
  #
  # @return [Concurrent::IVar] the pending result of the asynchronous operation
  #
  # @raise [NameError] the object does not respond to the requested method
  # @raise [ArgumentError] the given `args` do not match the arity of
  #   the requested method
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:412
  def async; end

  # Causes the chained method call to be performed synchronously on the
  # current thread. The delegated will return a future in either the
  # `:fulfilled` or `:rejected` state and the delegated method will have
  # completed. The final disposition of the delegated method can be obtained
  # by inspecting the returned future.
  #
  # @!macro async_thread_safety_warning
  #
  # @return [Concurrent::IVar] the completed result of the synchronous operation
  #
  # @raise [NameError] the object does not respond to the requested method
  # @raise [ArgumentError] the given `args` do not match the arity of the
  #   requested method
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:430
  def await; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:433
  def call; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:415
  def cast; end

  # Initialize the internal serializer and other stnchronization mechanisms.
  #
  # @note This method *must* be called immediately upon object construction.
  #   This is the only way thread-safe initialization can be guaranteed.
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:441
  def init_synchronization; end

  class << self
    # @!visibility private
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:262
    def included(base); end

    # Check for the presence of a method on an object and determine if a given
    # set of arguments matches the required arity.
    #
    # @param [Object] obj the object to check against
    # @param [Symbol] method the method to check the object for
    # @param [Array] args zero or more arguments for the arity check
    #
    # @raise [NameError] the object does not respond to `method` method
    # @raise [ArgumentError] the given `args` do not match the arity of `method`
    #
    # @note This check is imperfect because of the way Ruby reports the arity of
    #   methods with a variable number of arguments. It is possible to determine
    #   if too few arguments are given but impossible to determine if too many
    #   arguments are given. This check may also fail to recognize dynamic behavior
    #   of the object, such as methods simulated with `method_missing`.
    #
    # @see http://www.ruby-doc.org/core-2.1.1/Method.html#method-i-arity Method#arity
    # @see http://ruby-doc.org/core-2.1.0/Object.html#method-i-respond_to-3F Object#respond_to?
    # @see http://www.ruby-doc.org/core-2.1.0/BasicObject.html#method-i-method_missing BasicObject#method_missing
    #
    # @!visibility private
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:250
    def validate_argc(obj, method, *args); end
  end
end

# Delegates asynchronous, thread-safe method calls to the wrapped object.
#
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:282
class Concurrent::Async::AsyncDelegator < ::Concurrent::Synchronization::LockableObject
  # Create a new delegator object wrapping the given delegate.
  #
  # @param [Object] delegate the object to wrap and delegate method calls to
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:288
  def initialize(delegate); end

  # Delegates method calls to the wrapped object.
  #
  # @param [Symbol] method the method being called
  # @param [Array] args zero or more arguments to the method
  #
  # @return [IVar] the result of the method call
  #
  # @raise [NameError] the object does not respond to `method` method
  # @raise [ArgumentError] the given `args` do not match the arity of `method`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:305
  def method_missing(method, *args, &block); end

  # Perform all enqueued tasks.
  #
  # This method must be called from within the executor. It must not be
  # called while already running. It will loop until the queue is empty.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:330
  def perform; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:348
  def reset_if_forked; end

  private

  # Check whether the method is responsive
  #
  # @param [Symbol] method the method being called
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:322
  def respond_to_missing?(method, include_private = T.unsafe(nil)); end
end

# Delegates synchronous, thread-safe method calls to the wrapped object.
#
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:360
class Concurrent::Async::AwaitDelegator
  # Create a new delegator object wrapping the given delegate.
  #
  # @param [AsyncDelegator] delegate the object to wrap and delegate method calls to
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:365
  def initialize(delegate); end

  # Delegates method calls to the wrapped object.
  #
  # @param [Symbol] method the method being called
  # @param [Array] args zero or more arguments to the method
  #
  # @return [IVar] the result of the method call
  #
  # @raise [NameError] the object does not respond to `method` method
  # @raise [ArgumentError] the given `args` do not match the arity of `method`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:378
  def method_missing(method, *args, &block); end

  private

  # Check whether the method is responsive
  #
  # @param [Symbol] method the method being called
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:387
  def respond_to_missing?(method, include_private = T.unsafe(nil)); end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:269
module Concurrent::Async::ClassMethods
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/async.rb:270
  def new(*args, **_arg1, &block); end
end

# Atoms provide a way to manage shared, synchronous, independent state.
#
# An atom is initialized with an initial value and an optional validation
# proc. At any time the value of the atom can be synchronously and safely
# changed. If a validator is given at construction then any new value
# will be checked against the validator and will be rejected if the
# validator returns false or raises an exception.
#
# There are two ways to change the value of an atom: {#compare_and_set} and
# {#swap}. The former will set the new value if and only if it validates and
# the current value matches the new value. The latter will atomically set the
# new value to the result of running the given block if and only if that
# value validates.
#
# ## Example
#
# ```
# def next_fibonacci(set = nil)
#   return [0, 1] if set.nil?
#   set + [set[-2..-1].reduce{|sum,x| sum + x }]
# end
#
# # create an atom with an initial value
# atom = Concurrent::Atom.new(next_fibonacci)
#
# # send a few update requests
# 5.times do
#   atom.swap{|set| next_fibonacci(set) }
# end
#
# # get the current value
# atom.value #=> [0, 1, 1, 2, 3, 5, 8]
# ```
#
# ## Observation
#
# Atoms support observers through the {Concurrent::Observable} mixin module.
# Notification of observers occurs every time the value of the Atom changes.
# When notified the observer will receive three arguments: `time`, `old_value`,
# and `new_value`. The `time` argument is the time at which the value change
# occurred. The `old_value` is the value of the Atom when the change began
# The `new_value` is the value to which the Atom was set when the change
# completed. Note that `old_value` and `new_value` may be the same. This is
# not an error. It simply means that the change operation returned the same
# value.
#
# Unlike in Clojure, `Atom` cannot participate in {Concurrent::TVar} transactions.
#
# @!macro thread_safe_variable_comparison
#
# @see http://clojure.org/atoms Clojure Atoms
# @see http://clojure.org/state Values and Change - Clojure's approach to Identity and State
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:95
class Concurrent::Atom < ::Concurrent::Synchronization::Object
  include ::Concurrent::Concern::Observable
  extend ::Concurrent::Synchronization::SafeInitialization

  # Create a new atom with the given initial value.
  #
  # @param [Object] value The initial value
  # @param [Hash] opts The options used to configure the atom
  # @option opts [Proc] :validator (nil) Optional proc used to validate new
  #   values. It must accept one and only one argument which will be the
  #   intended new value. The validator will return true if the new value
  #   is acceptable else return false (preferably) or raise an exception.
  #
  # @!macro deref_options
  #
  # @raise [ArgumentError] if the validator is not a `Proc` (when given)
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:121
  def initialize(value, opts = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:99
  def __initialize_atomic_fields__; end

  # Atomically sets the value of atom to the new value if and only if the
  # current value of the atom is identical to the old value and the new
  # value successfully validates against the (optional) validator given
  # at construction.
  #
  # @param [Object] old_value The expected current value.
  # @param [Object] new_value The intended new value.
  #
  # @return [Boolean] True if the value is changed else false.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:181
  def compare_and_set(old_value, new_value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:102
  def deref; end

  # Atomically sets the value of atom to the new value without regard for the
  # current value so long as the new value successfully validates against the
  # (optional) validator given at construction.
  #
  # @param [Object] new_value The intended new value.
  #
  # @return [Object] The final value of the atom after all operations and
  #   validations are complete.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:198
  def reset(new_value); end

  # Atomically swaps the value of atom using the given block. The current
  # value will be passed to the block, as will any arguments passed as
  # arguments to the function. The new value will be validated against the
  # (optional) validator proc given at construction. If validation fails the
  # value will not be changed.
  #
  # Internally, {#swap} reads the current value, applies the block to it, and
  # attempts to compare-and-set it in. Since another thread may have changed
  # the value in the intervening time, it may have to retry, and does so in a
  # spin loop. The net effect is that the value will always be the result of
  # the application of the supplied block to a current value, atomically.
  # However, because the block might be called multiple times, it must be free
  # of side effects.
  #
  # @note The given block may be called multiple times, and thus should be free
  #   of side effects.
  #
  # @param [Object] args Zero or more arguments passed to the block.
  #
  # @yield [value, args] Calculates a new value for the atom based on the
  #   current value and any supplied arguments.
  # @yieldparam value [Object] The current value of the atom.
  # @yieldparam args [Object] All arguments passed to the function, in order.
  # @yieldreturn [Object] The intended new value of the atom.
  #
  # @return [Object] The final value of the atom after all operations and
  #   validations are complete.
  #
  # @raise [ArgumentError] When no block is given.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:157
  def swap(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:99
  def value; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:99
  def compare_and_set_value(expected, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:99
  def swap_value(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:99
  def update_value(&block); end

  # Is the new value valid?
  #
  # @param [Object] new_value The intended new value.
  # @return [Boolean] false if the validator function returns false or raises
  #   an exception else true
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:216
  def valid?(new_value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atom.rb:99
  def value=(value); end
end

# @!macro atomic_boolean
#
#   A boolean value that can be updated atomically. Reads and writes to an atomic
#   boolean and thread-safe and guaranteed to succeed. Reads and writes may block
#   briefly but no explicit locking is required.
#
#   @!macro thread_safe_variable_comparison
#
#   Performance:
#
#   ```
#   Testing with ruby 2.1.2
#   Testing with Concurrent::MutexAtomicBoolean...
#     2.790000   0.000000   2.790000 (  2.791454)
#   Testing with Concurrent::CAtomicBoolean...
#     0.740000   0.000000   0.740000 (  0.740206)
#
#   Testing with jruby 1.9.3
#   Testing with Concurrent::MutexAtomicBoolean...
#     5.240000   2.520000   7.760000 (  3.683000)
#   Testing with Concurrent::JavaAtomicBoolean...
#     3.340000   0.010000   3.350000 (  0.855000)
#   ```
#
#   @see http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/atomic/AtomicBoolean.html java.util.concurrent.atomic.AtomicBoolean
#
# @!macro atomic_boolean_public_api
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_boolean.rb:119
class Concurrent::AtomicBoolean < ::Concurrent::MutexAtomicBoolean
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_boolean.rb:125
  def inspect; end

  # @return [String] Short string representation.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_boolean.rb:121
  def to_s; end
end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_boolean.rb:82
Concurrent::AtomicBooleanImplementation = Concurrent::MutexAtomicBoolean

# Define update methods that use direct paths
#
# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/atomic_direct_update.rb:9
module Concurrent::AtomicDirectUpdate
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/atomic_direct_update.rb:15
  def try_update; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/atomic_direct_update.rb:24
  def try_update!; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/atomic_direct_update.rb:10
  def update; end
end

# @!macro atomic_fixnum
#
#   A numeric value that can be updated atomically. Reads and writes to an atomic
#   fixnum and thread-safe and guaranteed to succeed. Reads and writes may block
#   briefly but no explicit locking is required.
#
#   @!macro thread_safe_variable_comparison
#
#   Performance:
#
#   ```
#   Testing with ruby 2.1.2
#   Testing with Concurrent::MutexAtomicFixnum...
#     3.130000   0.000000   3.130000 (  3.136505)
#   Testing with Concurrent::CAtomicFixnum...
#     0.790000   0.000000   0.790000 (  0.785550)
#
#   Testing with jruby 1.9.3
#   Testing with Concurrent::MutexAtomicFixnum...
#     5.460000   2.460000   7.920000 (  3.715000)
#   Testing with Concurrent::JavaAtomicFixnum...
#     4.520000   0.030000   4.550000 (  1.187000)
#   ```
#
#   @see http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/atomic/AtomicLong.html java.util.concurrent.atomic.AtomicLong
#
# @!macro atomic_fixnum_public_api
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_fixnum.rb:136
class Concurrent::AtomicFixnum < ::Concurrent::MutexAtomicFixnum
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_fixnum.rb:142
  def inspect; end

  # @return [String] Short string representation.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_fixnum.rb:138
  def to_s; end
end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_fixnum.rb:99
Concurrent::AtomicFixnumImplementation = Concurrent::MutexAtomicFixnum

# An atomic reference which maintains an object reference along with a mark bit
# that can be updated atomically.
#
# @see http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/atomic/AtomicMarkableReference.html
#   java.util.concurrent.atomic.AtomicMarkableReference
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:10
class Concurrent::AtomicMarkableReference < ::Concurrent::Synchronization::Object
  extend ::Concurrent::Synchronization::SafeInitialization

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:15
  def initialize(value = T.unsafe(nil), mark = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:12
  def __initialize_atomic_fields__; end

  # Atomically sets the value and mark to the given updated value and
  # mark given both:
  #   - the current value == the expected value &&
  #   - the current mark == the expected mark
  #
  # @param [Object] expected_val the expected value
  # @param [Object] new_val the new value
  # @param [Boolean] expected_mark the expected mark
  # @param [Boolean] new_mark the new mark
  #
  # @return [Boolean] `true` if successful. A `false` return indicates
  # that the actual value was not equal to the expected value or the
  # actual mark was not equal to the expected mark
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:33
  def compare_and_set(expected_val, new_val, expected_mark, new_mark); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:59
  def compare_and_swap(expected_val, new_val, expected_mark, new_mark); end

  # Gets the current reference and marked values.
  #
  # @return [Array] the current reference and marked values
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:64
  def get; end

  # Gets the current marked value
  #
  # @return [Boolean] the current marked value
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:78
  def mark; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:82
  def marked?; end

  # _Unconditionally_ sets to the given value of both the reference and
  # the mark.
  #
  # @param [Object] new_val the new value
  # @param [Boolean] new_mark the new mark
  #
  # @return [Array] both the new value and the new mark
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:91
  def set(new_val, new_mark); end

  # Pass the current value to the given block, replacing it with the
  # block's result. Simply return nil if update fails.
  #
  # @yield [Object] Calculate a new value and marked state for the atomic
  #   reference using given (old) value and (old) marked
  # @yieldparam [Object] old_val the starting value of the atomic reference
  # @yieldparam [Boolean] old_mark the starting state of marked
  #
  # @return [Array] the new value and marked state, or nil if
  # the update failed
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:152
  def try_update; end

  # Pass the current value to the given block, replacing it
  # with the block's result. Raise an exception if the update
  # fails.
  #
  # @yield [Object] Calculate a new value and marked state for the atomic
  #   reference using given (old) value and (old) marked
  # @yieldparam [Object] old_val the starting value of the atomic reference
  # @yieldparam [Boolean] old_mark the starting state of marked
  #
  # @return [Array] the new value and marked state
  #
  # @raise [Concurrent::ConcurrentUpdateError] if the update fails
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:128
  def try_update!; end

  # Pass the current value and marked state to the given block, replacing it
  # with the block's results. May retry if the value changes during the
  # block's execution.
  #
  # @yield [Object] Calculate a new value and marked state for the atomic
  #   reference using given (old) value and (old) marked
  # @yieldparam [Object] old_val the starting value of the atomic reference
  # @yieldparam [Boolean] old_mark the starting state of marked
  #
  # @return [Array] the new value and new mark
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:105
  def update; end

  # Gets the current value of the reference
  #
  # @return [Object] the current value of the reference
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:71
  def value; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:12
  def compare_and_set_reference(expected, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:163
  def immutable_array(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:12
  def reference; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:12
  def reference=(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:12
  def swap_reference(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_markable_reference.rb:12
  def update_reference(&block); end
end

# Special "compare and set" handling of numeric values.
#
# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/numeric_cas_wrapper.rb:7
module Concurrent::AtomicNumericCompareAndSetWrapper
  # @!macro atomic_reference_method_compare_and_set
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/numeric_cas_wrapper.rb:10
  def compare_and_set(old_value, new_value); end
end

# An object reference that may be updated atomically. All read and write
# operations have java volatile semantic.
#
# @!macro thread_safe_variable_comparison
#
# @see http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/atomic/AtomicReference.html
# @see http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/atomic/package-summary.html
#
# @!method initialize(value = nil)
#   @!macro atomic_reference_method_initialize
#     @param [Object] value The initial value.
#
# @!method get
#   @!macro atomic_reference_method_get
#     Gets the current value.
#     @return [Object] the current value
#
# @!method set(new_value)
#   @!macro atomic_reference_method_set
#     Sets to the given value.
#     @param [Object] new_value the new value
#     @return [Object] the new value
#
# @!method get_and_set(new_value)
#   @!macro atomic_reference_method_get_and_set
#     Atomically sets to the given value and returns the old value.
#     @param [Object] new_value the new value
#     @return [Object] the old value
#
# @!method compare_and_set(old_value, new_value)
#   @!macro atomic_reference_method_compare_and_set
#
#     Atomically sets the value to the given updated value if
#     the current value == the expected value.
#
#     @param [Object] old_value the expected value
#     @param [Object] new_value the new value
#
#     @return [Boolean] `true` if successful. A `false` return indicates
#     that the actual value was not equal to the expected value.
#
# @!method update
#   Pass the current value to the given block, replacing it
#   with the block's result. May retry if the value changes
#   during the block's execution.
#
#   @yield [Object] Calculate a new value for the atomic reference using
#     given (old) value
#   @yieldparam [Object] old_value the starting value of the atomic reference
#   @return [Object] the new value
#
# @!method try_update
#   Pass the current value to the given block, replacing it
#   with the block's result. Return nil if the update fails.
#
#   @yield [Object] Calculate a new value for the atomic reference using
#     given (old) value
#   @yieldparam [Object] old_value the starting value of the atomic reference
#   @note This method was altered to avoid raising an exception by default.
#     Instead, this method now returns `nil` in case of failure. For more info,
#     please see: https://github.com/ruby-concurrency/concurrent-ruby/pull/336
#   @return [Object] the new value, or nil if update failed
#
# @!method try_update!
#   Pass the current value to the given block, replacing it
#   with the block's result. Raise an exception if the update
#   fails.
#
#   @yield [Object] Calculate a new value for the atomic reference using
#     given (old) value
#   @yieldparam [Object] old_value the starting value of the atomic reference
#   @note This behavior mimics the behavior of the original
#     `AtomicReference#try_update` API. The reason this was changed was to
#     avoid raising exceptions (which are inherently slow) by default. For more
#     info: https://github.com/ruby-concurrency/concurrent-ruby/pull/336
#   @return [Object] the new value
#   @raise [Concurrent::ConcurrentUpdateError] if the update fails
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_reference.rb:126
class Concurrent::AtomicReference < ::Concurrent::MutexAtomicReference
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_reference.rb:133
  def inspect; end

  # @return [String] Short string representation.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_reference.rb:129
  def to_s; end
end

# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/atomic_reference.rb:18
Concurrent::AtomicReferenceImplementation = Concurrent::MutexAtomicReference

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:30
class Concurrent::CRubySet < ::Set
  include ::Set::SubclassCompatible
  extend ::Set::SubclassCompatible::ClassMethods

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def initialize(*args, &block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def &(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def +(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def -(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def <(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def <<(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def <=(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def <=>(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def ==(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def ===(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def >(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def >=(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def ^(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def add(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def add?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def classify(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def clear(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def collect!(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def compare_by_identity(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def compare_by_identity?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def delete(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def delete?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def delete_if(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def difference(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def disjoint?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def divide(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def each(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def empty?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def encode_with(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def eql?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def filter!(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def flatten(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def flatten!(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def hash(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def include?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def init_with(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def inspect(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def intersect?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def intersection(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def join(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def keep_if(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def length(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def map!(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def member?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def merge(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def pretty_print(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def pretty_print_cycle(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def proper_subset?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def proper_superset?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def reject!(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def replace(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def reset(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def select!(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def size(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def subset?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def subtract(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def superset?(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def to_a(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def to_s(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def to_set(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def union(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def |(*args); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:33
  def initialize_copy(other); end
end

# A thread pool that dynamically grows and shrinks to fit the current workload.
# New threads are created as needed, existing threads are reused, and threads
# that remain idle for too long are killed and removed from the pool. These
# pools are particularly suited to applications that perform a high volume of
# short-lived tasks.
#
# On creation a `CachedThreadPool` has zero running threads. New threads are
# created on the pool as new operations are `#post`. The size of the pool
# will grow until `#max_length` threads are in the pool or until the number
# of threads exceeds the number of running and pending operations. When a new
# operation is post to the pool the first available idle thread will be tasked
# with the new operation.
#
# Should a thread crash for any reason the thread will immediately be removed
# from the pool. Similarly, threads which remain idle for an extended period
# of time will be killed and reclaimed. Thus these thread pools are very
# efficient at reclaiming unused resources.
#
# The API and behavior of this class are based on Java's `CachedThreadPool`
#
# @!macro thread_pool_options
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/cached_thread_pool.rb:27
class Concurrent::CachedThreadPool < ::Concurrent::ThreadPoolExecutor
  # @!macro cached_thread_pool_method_initialize
  #
  #   Create a new thread pool.
  #
  #   @param [Hash] opts the options defining pool behavior.
  #   @option opts [Symbol] :fallback_policy (`:abort`) the fallback policy
  #
  #   @raise [ArgumentError] if `fallback_policy` is not a known policy
  #
  #   @see http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Executors.html#newCachedThreadPool--
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/cached_thread_pool.rb:39
  def initialize(opts = T.unsafe(nil)); end

  private

  # @!macro cached_thread_pool_method_initialize
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/cached_thread_pool.rb:51
  def ns_initialize(opts); end
end

# Raised when an asynchronous operation is cancelled before execution.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:9
class Concurrent::CancelledOperationError < ::Concurrent::Error; end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:7
module Concurrent::Collection; end

# A thread safe observer set implemented using copy-on-read approach:
# observers are added and removed from a thread safe collection; every time
# a notification is required the internal data structure is copied to
# prevent concurrency issues
#
# @api private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb:12
class Concurrent::Collection::CopyOnNotifyObserverSet < ::Concurrent::Synchronization::LockableObject
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb:14
  def initialize; end

  # @!macro observable_add_observer
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb:20
  def add_observer(observer = T.unsafe(nil), func = T.unsafe(nil), &block); end

  # @!macro observable_count_observers
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb:55
  def count_observers; end

  # @!macro observable_delete_observer
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb:39
  def delete_observer(observer); end

  # @!macro observable_delete_observers
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb:47
  def delete_observers; end

  # Notifies all registered observers with optional args and deletes them.
  #
  # @param [Object] args arguments to be passed to each observer
  # @return [CopyOnWriteObserverSet] self
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb:72
  def notify_and_delete_observers(*args, &block); end

  # Notifies all registered observers with optional args
  # @param [Object] args arguments to be passed to each observer
  # @return [CopyOnWriteObserverSet] self
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb:62
  def notify_observers(*args, &block); end

  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb:80
  def ns_initialize; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb:86
  def duplicate_and_clear_observers; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb:94
  def duplicate_observers; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb:98
  def notify_to(observers, *args); end
end

# A thread safe observer set implemented using copy-on-write approach:
# every time an observer is added or removed the whole internal data structure is
# duplicated and replaced with a new one.
#
# @api private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:11
class Concurrent::Collection::CopyOnWriteObserverSet < ::Concurrent::Synchronization::LockableObject
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:13
  def initialize; end

  # @!macro observable_add_observer
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:19
  def add_observer(observer = T.unsafe(nil), func = T.unsafe(nil), &block); end

  # @!macro observable_count_observers
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:56
  def count_observers; end

  # @!macro observable_delete_observer
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:40
  def delete_observer(observer); end

  # @!macro observable_delete_observers
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:50
  def delete_observers; end

  # Notifies all registered observers with optional args and deletes them.
  #
  # @param [Object] args arguments to be passed to each observer
  # @return [CopyOnWriteObserverSet] self
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:72
  def notify_and_delete_observers(*args, &block); end

  # Notifies all registered observers with optional args
  # @param [Object] args arguments to be passed to each observer
  # @return [CopyOnWriteObserverSet] self
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:63
  def notify_observers(*args, &block); end

  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:80
  def ns_initialize; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:102
  def clear_observers_and_return_old; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:86
  def notify_to(observers, *args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:94
  def observers; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb:98
  def observers=(new_set); end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:10
Concurrent::Collection::MapImplementation = Concurrent::Collection::MriMapBackend

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:10
class Concurrent::Collection::MriMapBackend < ::Concurrent::Collection::NonConcurrentMapBackend
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:12
  def initialize(options = T.unsafe(nil), &default_proc); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:17
  def []=(key, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:61
  def clear; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:33
  def compute(key); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:21
  def compute_if_absent(key); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:29
  def compute_if_present(key); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:53
  def delete(key); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:57
  def delete_pair(key, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:49
  def get_and_set(key, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:37
  def merge_pair(key, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:45
  def replace_if_exists(key, new_value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/mri_map_backend.rb:41
  def replace_pair(key, old_value, new_value); end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:9
class Concurrent::Collection::NonConcurrentMapBackend
  # WARNING: all public methods of the class must operate on the @backend
  # directly without calling each other. This is important because of the
  # SynchronizedMapBackend which uses a non-reentrant mutex for performance
  # reasons.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:15
  def initialize(options = T.unsafe(nil), &default_proc); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:21
  def [](key); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:25
  def []=(key, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:94
  def clear; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:59
  def compute(key); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:29
  def compute_if_absent(key); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:53
  def compute_if_present(key); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:81
  def delete(key); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:85
  def delete_pair(key, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:99
  def each_pair; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:71
  def get_and_set(key, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:110
  def get_or_default(key, default_value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:77
  def key?(key); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:63
  def merge_pair(key, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:46
  def replace_if_exists(key, new_value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:37
  def replace_pair(key, old_value, new_value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:106
  def size; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:130
  def dupped_backend; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:124
  def initialize_copy(other); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:134
  def pair?(key, expected_value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:116
  def set_backend(default_proc); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/map/non_concurrent_map_backend.rb:138
  def store_computed_value(key, new_value); end
end

# @!macro priority_queue
#
#   A queue collection in which the elements are sorted based on their
#   comparison (spaceship) operator `<=>`. Items are added to the queue
#   at a position relative to their priority. On removal the element
#   with the "highest" priority is removed. By default the sort order is
#   from highest to lowest, but a lowest-to-highest sort order can be
#   set on construction.
#
#   The API is based on the `Queue` class from the Ruby standard library.
#
#   The pure Ruby implementation, `RubyNonConcurrentPriorityQueue` uses a heap algorithm
#   stored in an array. The algorithm is based on the work of Robert Sedgewick
#   and Kevin Wayne.
#
#   The JRuby native implementation is a thin wrapper around the standard
#   library `java.util.NonConcurrentPriorityQueue`.
#
#   When running under JRuby the class `NonConcurrentPriorityQueue` extends `JavaNonConcurrentPriorityQueue`.
#   When running under all other interpreters it extends `RubyNonConcurrentPriorityQueue`.
#
#   @note This implementation is *not* thread safe.
#
#   @see http://en.wikipedia.org/wiki/Priority_queue
#   @see http://ruby-doc.org/stdlib-2.0.0/libdoc/thread/rdoc/Queue.html
#
#   @see http://algs4.cs.princeton.edu/24pq/index.php#2.6
#   @see http://algs4.cs.princeton.edu/24pq/MaxPQ.java.html
#
#   @see http://docs.oracle.com/javase/7/docs/api/java/util/PriorityQueue.html
#
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/non_concurrent_priority_queue.rb:50
class Concurrent::Collection::NonConcurrentPriorityQueue < ::Concurrent::Collection::RubyNonConcurrentPriorityQueue
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/non_concurrent_priority_queue.rb:59
  def <<(item); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/non_concurrent_priority_queue.rb:56
  def deq; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/non_concurrent_priority_queue.rb:60
  def enq(item); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/non_concurrent_priority_queue.rb:52
  def has_priority?(item); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/non_concurrent_priority_queue.rb:57
  def shift; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/non_concurrent_priority_queue.rb:54
  def size; end
end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/non_concurrent_priority_queue.rb:10
Concurrent::Collection::NonConcurrentPriorityQueueImplementation = Concurrent::Collection::RubyNonConcurrentPriorityQueue

# @!macro priority_queue
#
# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:8
class Concurrent::Collection::RubyNonConcurrentPriorityQueue
  # @!macro priority_queue_method_initialize
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:11
  def initialize(opts = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:85
  def <<(item); end

  # @!macro priority_queue_method_clear
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:18
  def clear; end

  # @!macro priority_queue_method_delete
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:25
  def delete(item); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:74
  def deq; end

  # @!macro priority_queue_method_empty
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:43
  def empty?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:86
  def enq(item); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:51
  def has_priority?(item); end

  # @!macro priority_queue_method_include
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:48
  def include?(item); end

  # @!macro priority_queue_method_length
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:54
  def length; end

  # @!macro priority_queue_method_peek
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:60
  def peek; end

  # @!macro priority_queue_method_pop
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:65
  def pop; end

  # @!macro priority_queue_method_push
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:78
  def push(item); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:75
  def shift; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:57
  def size; end

  private

  # Are the items at the given indexes ordered based on the priority
  # order specified at construction?
  #
  # @param [Integer] x the first index from which to retrieve a comparable value
  # @param [Integer] y the second index from which to retrieve a comparable value
  #
  # @return [Boolean] true if the two elements are in the correct priority order
  #   else false
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:119
  def ordered?(x, y); end

  # Percolate down to maintain heap invariant.
  #
  # @param [Integer] k the index at which to start the percolation
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:128
  def sink(k); end

  # Exchange the values at the given indexes within the internal array.
  #
  # @param [Integer] x the first index to swap
  # @param [Integer] y the second index to swap
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:103
  def swap(x, y); end

  # Percolate up to maintain heap invariant.
  #
  # @param [Integer] k the index at which to start the percolation
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:147
  def swim(k); end

  class << self
    #   @!macro priority_queue_method_from_list
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb:89
    def from_list(list, opts = T.unsafe(nil)); end
  end
end

# @!visibility private
# @!macro timeout_queue
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/timeout_queue.rb:15
class Concurrent::Collection::TimeoutQueue < ::Thread::Queue; end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/timeout_queue.rb:5
Concurrent::Collection::TimeoutQueueImplementation = Thread::Queue

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/dereferenceable.rb:2
module Concurrent::Concern; end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/deprecation.rb:8
module Concurrent::Concern::Deprecation
  include ::Concurrent::Concern::Logging
  extend ::Concurrent::Concern::Logging
  extend ::Concurrent::Concern::Deprecation

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/deprecation.rb:12
  def deprecated(message, strip = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/deprecation.rb:27
  def deprecated_method(old_name, new_name); end
end

# Object references in Ruby are mutable. This can lead to serious problems when
# the `#value` of a concurrent object is a mutable reference. Which is always the
# case unless the value is a `Fixnum`, `Symbol`, or similar "primitive" data type.
# Most classes in this library that expose a `#value` getter method do so using the
# `Dereferenceable` mixin module.
#
# @!macro copy_options
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/dereferenceable.rb:11
module Concurrent::Concern::Dereferenceable
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/dereferenceable.rb:24
  def deref; end

  # Return the value this object represents after applying the options specified
  # by the `#set_deref_options` method.
  #
  # @return [Object] the current value of the object
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/dereferenceable.rb:21
  def value; end

  protected

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/dereferenceable.rb:63
  def apply_deref_options(value); end

  # @!macro dereferenceable_set_deref_options
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/dereferenceable.rb:54
  def ns_set_deref_options(opts); end

  # @!macro dereferenceable_set_deref_options
  #   Set the options which define the operations #value performs before
  #   returning data to the caller (dereferencing).
  #
  #   @note Most classes that include this module will call `#set_deref_options`
  #     from within the constructor, thus allowing these options to be set at
  #     object creation.
  #
  #   @param [Hash] opts the options defining dereference behavior.
  #   @option opts [String] :dup_on_deref (false) call `#dup` before returning the data
  #   @option opts [String] :freeze_on_deref (false) call `#freeze` before returning the data
  #   @option opts [String] :copy_on_deref (nil) call the given `Proc` passing
  #     the internal value and returning the value returned from the proc
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/dereferenceable.rb:48
  def set_deref_options(opts = T.unsafe(nil)); end

  # Set the internal value of this object
  #
  # @param [Object] value the new value
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/dereferenceable.rb:31
  def value=(value); end
end

# Include where logging is needed
#
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:9
module Concurrent::Concern::Logging
  # Logs through {Concurrent.global_logger}, it can be overridden by setting @logger
  # @param [Integer] level one of Concurrent::Concern::Logging constants
  # @param [String] progname e.g. a path of an Actor
  # @param [String, nil] message when nil block is used to generate the message
  # @yieldreturn [String] a message
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:19
  def log(level, progname, message = T.unsafe(nil), &block); end
end

# The same as Logger::Severity but we copy it here to avoid a dependency on the logger gem just for these 7 constants
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:11
Concurrent::Concern::Logging::DEBUG = T.let(T.unsafe(nil), Integer)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:11
Concurrent::Concern::Logging::ERROR = T.let(T.unsafe(nil), Integer)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:11
Concurrent::Concern::Logging::FATAL = T.let(T.unsafe(nil), Integer)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:11
Concurrent::Concern::Logging::INFO = T.let(T.unsafe(nil), Integer)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:12
Concurrent::Concern::Logging::SEV_LABEL = T.let(T.unsafe(nil), Array)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:11
Concurrent::Concern::Logging::UNKNOWN = T.let(T.unsafe(nil), Integer)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:11
Concurrent::Concern::Logging::WARN = T.let(T.unsafe(nil), Integer)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:10
module Concurrent::Concern::Obligation
  include ::Concurrent::Concern::Dereferenceable

  # Has the obligation completed processing?
  #
  # @return [Boolean]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:49
  def complete?; end

  # @example allows Obligation to be risen
  #   rejected_ivar = Ivar.new.fail
  #   raise rejected_ivar
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:126
  def exception(*args); end

  # Has the obligation been fulfilled?
  #
  # @return [Boolean]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:20
  def fulfilled?; end

  # Is the obligation still awaiting completion of processing?
  #
  # @return [Boolean]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:56
  def incomplete?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:89
  def no_error!(timeout = T.unsafe(nil)); end

  # Is obligation completion still pending?
  #
  # @return [Boolean]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:35
  def pending?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:23
  def realized?; end

  # If an exception was raised during processing this will return the
  # exception object. Will return `nil` when the state is pending or if
  # the obligation has been successfully fulfilled.
  #
  # @return [Exception] the exception raised during processing or `nil`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:119
  def reason; end

  # Has the obligation been rejected?
  #
  # @return [Boolean]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:28
  def rejected?; end

  # The current state of the obligation.
  #
  # @return [Symbol] the current state
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:110
  def state; end

  # Is the obligation still unscheduled?
  #
  # @return [Boolean]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:42
  def unscheduled?; end

  # The current value of the obligation. Will be `nil` while the state is
  # pending or the operation has been rejected.
  #
  # @param [Numeric] timeout the maximum time in seconds to wait.
  # @return [Object] see Dereferenceable#deref
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:65
  def value(timeout = T.unsafe(nil)); end

  # The current value of the obligation. Will be `nil` while the state is
  # pending or the operation has been rejected. Will re-raise any exceptions
  # raised during processing (but will not raise an exception on timeout).
  #
  # @param [Numeric] timeout the maximum time in seconds to wait.
  # @return [Object] see Dereferenceable#deref
  # @raise [Exception] raises the reason when rejected
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:98
  def value!(timeout = T.unsafe(nil)); end

  # Wait until obligation is complete or the timeout has been reached.
  #
  # @param [Numeric] timeout the maximum time in seconds to wait.
  # @return [Obligation] self
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:74
  def wait(timeout = T.unsafe(nil)); end

  # Wait until obligation is complete or the timeout is reached. Will re-raise
  # any exceptions raised during processing (but will not raise an exception
  # on timeout).
  #
  # @param [Numeric] timeout the maximum time in seconds to wait.
  # @return [Obligation] self
  # @raise [Exception] raises the reason when rejected
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:86
  def wait!(timeout = T.unsafe(nil)); end

  protected

  # Atomic compare and set operation
  # State is set to `next_state` only if `current state == expected_current`.
  #
  # @param [Symbol] next_state
  # @param [Symbol] expected_current
  #
  # @return [Boolean] true is state is changed, false otherwise
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:174
  def compare_and_set_state(next_state, *expected_current); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:145
  def event; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:134
  def get_arguments_from(opts = T.unsafe(nil)); end

  # Executes the block within mutex if current state is included in expected_states
  #
  # @return block value if executed, false otherwise
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:190
  def if_state(*expected_states); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:139
  def init_obligation; end

  # Am I in the current state?
  #
  # @param [Symbol] expected The state to check against
  # @return [Boolean] true if in the expected state else false
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:210
  def ns_check_state?(expected); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:215
  def ns_set_state(value); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:150
  def set_state(success, value, reason); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/obligation.rb:161
  def state=(value); end
end

# The [observer pattern](http://en.wikipedia.org/wiki/Observer_pattern) is one
# of the most useful design patterns.
#
# The workflow is very simple:
# - an `observer` can register itself to a `subject` via a callback
# - many `observers` can be registered to the same `subject`
# - the `subject` notifies all registered observers when its status changes
# - an `observer` can deregister itself when is no more interested to receive
#     event notifications
#
# In a single threaded environment the whole pattern is very easy: the
# `subject` can use a simple data structure to manage all its subscribed
# `observer`s and every `observer` can react directly to every event without
# caring about synchronization.
#
# In a multi threaded environment things are more complex. The `subject` must
# synchronize the access to its data structure and to do so currently we're
# using two specialized ObserverSet: {Concurrent::Concern::CopyOnWriteObserverSet}
# and {Concurrent::Concern::CopyOnNotifyObserverSet}.
#
# When implementing and `observer` there's a very important rule to remember:
# **there are no guarantees about the thread that will execute the callback**
#
# Let's take this example
# ```
# class Observer
#   def initialize
#     @count = 0
#   end
#
#   def update
#     @count += 1
#   end
# end
#
# obs = Observer.new
# [obj1, obj2, obj3, obj4].each { |o| o.add_observer(obs) }
# # execute [obj1, obj2, obj3, obj4]
# ```
#
# `obs` is wrong because the variable `@count` can be accessed by different
# threads at the same time, so it should be synchronized (using either a Mutex
# or an AtomicFixum)
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/observable.rb:50
module Concurrent::Concern::Observable
  # @!macro observable_add_observer
  #
  #   Adds an observer to this set. If a block is passed, the observer will be
  #   created by this method and no other params should be passed.
  #
  #   @param [Object] observer the observer to add
  #   @param [Symbol] func the function to call on the observer during notification.
  #     Default is :update
  #   @return [Object] the added observer
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/observable.rb:61
  def add_observer(observer = T.unsafe(nil), func = T.unsafe(nil), &block); end

  # @!macro observable_count_observers
  #
  #   Return the number of observers associated with this object.
  #
  #   @return [Integer] the observers count
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/observable.rb:101
  def count_observers; end

  # @!macro observable_delete_observer
  #
  #   Remove `observer` as an observer on this object so that it will no
  #   longer receive notifications.
  #
  #   @param [Object] observer the observer to remove
  #   @return [Object] the deleted observer
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/observable.rb:82
  def delete_observer(observer); end

  # @!macro observable_delete_observers
  #
  #   Remove all observers associated with this object.
  #
  #   @return [Observable] self
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/observable.rb:91
  def delete_observers; end

  # As `#add_observer` but can be used for chaining.
  #
  # @param [Object] observer the observer to add
  # @param [Symbol] func the function to call on the observer during notification.
  # @return [Observable] self
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/observable.rb:70
  def with_observer(observer = T.unsafe(nil), func = T.unsafe(nil), &block); end

  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/observable.rb:107
  def observers; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/observable.rb:107
  def observers=(_arg0); end
end

# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:70
class Concurrent::ConcurrentUpdateError < ::ThreadError; end

# frozen pre-allocated backtrace to speed ConcurrentUpdateError
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:72
Concurrent::ConcurrentUpdateError::CONC_UP_ERR_BACKTRACE = T.let(T.unsafe(nil), Array)

# Raised when errors occur during configuration.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:6
class Concurrent::ConfigurationError < ::Concurrent::Error; end

# @!macro count_down_latch
#
#   A synchronization object that allows one thread to wait on multiple other threads.
#   The thread that will wait creates a `CountDownLatch` and sets the initial value
#   (normally equal to the number of other threads). The initiating thread passes the
#   latch to the other threads then waits for the other threads by calling the `#wait`
#   method. Each of the other threads calls `#count_down` when done with its work.
#   When the latch counter reaches zero the waiting thread is unblocked and continues
#   with its work. A `CountDownLatch` can be used only once. Its value cannot be reset.
#
# @!macro count_down_latch_public_api
# @example Waiter and Decrementer
#   latch = Concurrent::CountDownLatch.new(3)
#
#   waiter = Thread.new do
#     latch.wait()
#     puts ("Waiter released")
#   end
#
#   decrementer = Thread.new do
#     sleep(1)
#     latch.count_down
#     puts latch.count
#
#     sleep(1)
#     latch.count_down
#     puts latch.count
#
#     sleep(1)
#     latch.count_down
#     puts latch.count
#   end
#
#   [waiter, decrementer].each(&:join)
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/count_down_latch.rb:98
class Concurrent::CountDownLatch < ::Concurrent::MutexCountDownLatch; end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/count_down_latch.rb:56
Concurrent::CountDownLatchImplementation = Concurrent::MutexCountDownLatch

# A synchronization aid that allows a set of threads to all wait for each
# other to reach a common barrier point.
# @example
#   barrier = Concurrent::CyclicBarrier.new(3)
#   jobs    = Array.new(3) { |i| -> { sleep i; p done: i } }
#   process = -> (i) do
#     # waiting to start at the same time
#     barrier.wait
#     # execute job
#     jobs[i].call
#     # wait for others to finish
#     barrier.wait
#   end
#   threads = 2.times.map do |i|
#     Thread.new(i, &process)
#   end
#
#   # use main as well
#   process.call 2
#
#   # here we can be sure that all jobs are processed
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:27
class Concurrent::CyclicBarrier < ::Concurrent::Synchronization::LockableObject
  # Create a new `CyclicBarrier` that waits for `parties` threads
  #
  # @param [Fixnum] parties the number of parties
  # @yield an optional block that will be executed that will be executed after
  #  the last thread arrives and before the others are released
  #
  # @raise [ArgumentError] if `parties` is not an integer or is less than zero
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:40
  def initialize(parties, &block); end

  # A barrier can be broken when:
  # - a thread called the `reset` method while at least one other thread was waiting
  # - at least one thread timed out on `wait` method
  #
  # A broken barrier can be restored using `reset` it's safer to create a new one
  # @return [Boolean] true if the barrier is broken otherwise false
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:105
  def broken?; end

  # @return [Fixnum] the number of threads currently waiting on the barrier
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:54
  def number_waiting; end

  # @return [Fixnum] the number of threads needed to pass the barrier
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:49
  def parties; end

  # resets the barrier to its initial state
  # If there is at least one waiting thread, it will be woken up, the `wait`
  # method will return false and the barrier will be broken
  # If the barrier is broken, this method restores it to the original state
  #
  # @return [nil]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:95
  def reset; end

  # Blocks on the barrier until the number of waiting threads is equal to
  # `parties` or until `timeout` is reached or `reset` is called
  # If a block has been passed to the constructor, it will be executed once by
  #  the last arrived thread before releasing the others
  # @param [Fixnum] timeout the number of seconds to wait for the counter or
  #  `nil` to block indefinitely
  # @return [Boolean] `true` if the `count` reaches zero else false on
  #  `timeout` or on `reset` or if the barrier is broken
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:66
  def wait(timeout = T.unsafe(nil)); end

  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:111
  def ns_generation_done(generation, status, continue = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:122
  def ns_initialize(parties, &block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:117
  def ns_next_generation; end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:30
class Concurrent::CyclicBarrier::Generation < ::Struct
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:30
  def status; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:30
  def status=(_); end

  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:30
    def [](*_arg0); end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:30
    def inspect; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:30
    def keyword_init?; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:30
    def members; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/cyclic_barrier.rb:30
    def new(*_arg0); end
  end
end

# Lazy evaluation of a block yielding an immutable result. Useful for
# expensive operations that may never be needed. It may be non-blocking,
# supports the `Concern::Obligation` interface, and accepts the injection of
# custom executor upon which to execute the block. Processing of
# block will be deferred until the first time `#value` is called.
# At that time the caller can choose to return immediately and let
# the block execute asynchronously, block indefinitely, or block
# with a timeout.
#
# When a `Delay` is created its state is set to `pending`. The value and
# reason are both `nil`. The first time the `#value` method is called the
# enclosed operation will be run and the calling thread will block. Other
# threads attempting to call `#value` will block as well. Once the operation
# is complete the *value* will be set to the result of the operation or the
# *reason* will be set to the raised exception, as appropriate. All threads
# blocked on `#value` will return. Subsequent calls to `#value` will immediately
# return the cached value. The operation will only be run once. This means that
# any side effects created by the operation will only happen once as well.
#
# `Delay` includes the `Concurrent::Concern::Dereferenceable` mixin to support thread
# safety of the reference returned by `#value`.
#
# @!macro copy_options
#
# @!macro delay_note_regarding_blocking
#   @note The default behavior of `Delay` is to block indefinitely when
#     calling either `value` or `wait`, executing the delayed operation on
#     the current thread. This makes the `timeout` value completely
#     irrelevant. To enable non-blocking behavior, use the `executor`
#     constructor option. This will cause the delayed operation to be
#     execute on the given executor, allowing the call to timeout.
#
# @see Concurrent::Concern::Dereferenceable
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/delay.rb:44
class Concurrent::Delay < ::Concurrent::Synchronization::LockableObject
  include ::Concurrent::Concern::Dereferenceable
  include ::Concurrent::Concern::Obligation

  # Create a new `Delay` in the `:pending` state.
  #
  # @!macro executor_and_deref_options
  #
  # @yield the delayed operation to perform
  #
  # @raise [ArgumentError] if no block is given
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/delay.rb:62
  def initialize(opts = T.unsafe(nil), &block); end

  # Reconfigures the block returning the value if still `#incomplete?`
  #
  # @yield the delayed operation to perform
  # @return [true, false] if success
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/delay.rb:146
  def reconfigure(&block); end

  # Return the value this object represents after applying the options
  # specified by the `#set_deref_options` method. If the delayed operation
  # raised an exception this method will return nil. The exception object
  # can be accessed via the `#reason` method.
  #
  # @param [Numeric] timeout the maximum number of seconds to wait
  # @return [Object] the current value of the object
  #
  # @!macro delay_note_regarding_blocking
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/delay.rb:77
  def value(timeout = T.unsafe(nil)); end

  # Return the value this object represents after applying the options
  # specified by the `#set_deref_options` method. If the delayed operation
  # raised an exception, this method will raise that exception (even when)
  # the operation has already been executed).
  #
  # @param [Numeric] timeout the maximum number of seconds to wait
  # @return [Object] the current value of the object
  # @raise [Exception] when `#rejected?` raises `#reason`
  #
  # @!macro delay_note_regarding_blocking
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/delay.rb:113
  def value!(timeout = T.unsafe(nil)); end

  # Return the value this object represents after applying the options
  # specified by the `#set_deref_options` method.
  #
  # @param [Integer] timeout (nil) the maximum number of seconds to wait for
  #   the value to be computed. When `nil` the caller will block indefinitely.
  #
  # @return [Object] self
  #
  # @!macro delay_note_regarding_blocking
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/delay.rb:132
  def wait(timeout = T.unsafe(nil)); end

  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/delay.rb:160
  def ns_initialize(opts, &block); end

  private

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/delay.rb:173
  def execute_task_once; end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:7
class Concurrent::DependencyCounter
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:9
  def initialize(count, &block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/dataflow.rb:14
  def update(time, value, reason); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:3
class Concurrent::Error < ::StandardError; end

# Old school kernel-style event reminiscent of Win32 programming in C++.
#
# When an `Event` is created it is in the `unset` state. Threads can choose to
# `#wait` on the event, blocking until released by another thread. When one
# thread wants to alert all blocking threads it calls the `#set` method which
# will then wake up all listeners. Once an `Event` has been set it remains set.
# New threads calling `#wait` will return immediately. An `Event` may be
# `#reset` at any time once it has been set.
#
# @see http://msdn.microsoft.com/en-us/library/windows/desktop/ms682655.aspx
# @example
#   event = Concurrent::Event.new
#
#   t1 = Thread.new do
#     puts "t1 is waiting"
#     event.wait(1)
#     puts "event occurred"
#   end
#
#   t2 = Thread.new do
#     puts "t2 calling set"
#     event.set
#   end
#
#   [t1, t2].each(&:join)
#
#   # prints:
#   # t1 is waiting
#   # t2 calling set
#   # event occurred
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/event.rb:36
class Concurrent::Event < ::Concurrent::Synchronization::LockableObject
  # Creates a new `Event` in the unset state. Threads calling `#wait` on the
  # `Event` will block.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/event.rb:40
  def initialize; end

  # Reset a previously set event back to the `unset` state.
  # Has no effect if the `Event` has not yet been set.
  #
  # @return [Boolean] should always return `true`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/event.rb:68
  def reset; end

  # Trigger the event, setting the state to `set` and releasing all threads
  # waiting on the event. Has no effect if the `Event` has already been set.
  #
  # @return [Boolean] should always return `true`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/event.rb:56
  def set; end

  # Is the object in the set state?
  #
  # @return [Boolean] indicating whether or not the `Event` has been set
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/event.rb:48
  def set?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/event.rb:60
  def try?; end

  # Wait a given number of seconds for the `Event` to be set by another
  # thread. Will wait forever when no `timeout` value is given. Returns
  # immediately if the `Event` has already been set.
  #
  # @return [Boolean] true if the `Event` was set before timeout else false
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/event.rb:83
  def wait(timeout = T.unsafe(nil)); end

  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/event.rb:104
  def ns_initialize; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/event.rb:96
  def ns_set; end
end

# @!macro exchanger
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:336
class Concurrent::Exchanger < ::Concurrent::RubyExchanger; end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:327
Concurrent::ExchangerImplementation = Concurrent::RubyExchanger

# @!macro executor_service_public_api
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/executor_service.rb:157
module Concurrent::ExecutorService
  include ::Concurrent::Concern::Logging

  # @!macro executor_service_method_left_shift
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/executor_service.rb:166
  def <<(task); end

  # @!macro executor_service_method_can_overflow_question
  #
  # @note Always returns `false`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/executor_service.rb:174
  def can_overflow?; end

  # @!macro executor_service_method_post
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/executor_service.rb:161
  def post(*args, &task); end

  # @!macro executor_service_method_serialized_question
  #
  # @note Always returns `false`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/executor_service.rb:181
  def serialized?; end
end

# A `FiberLocalVar` is a variable where the value is different for each fiber.
# Each variable may have a default value, but when you modify the variable only
# the current fiber will ever see that change.
#
# This is similar to Ruby's built-in fiber-local variables (`Thread.current[:name]`),
# but with these major advantages:
# * `FiberLocalVar` has its own identity, it doesn't need a Symbol.
# * Each Ruby's built-in fiber-local variable leaks some memory forever (it's a Symbol held forever on the fiber),
#   so it's only OK to create a small amount of them.
#   `FiberLocalVar` has no such issue and it is fine to create many of them.
# * Ruby's built-in fiber-local variables leak forever the value set on each fiber (unless set to nil explicitly).
#   `FiberLocalVar` automatically removes the mapping for each fiber once the `FiberLocalVar` instance is GC'd.
#
# @example
#   v = FiberLocalVar.new(14)
#   v.value #=> 14
#   v.value = 2
#   v.value #=> 2
#
# @example
#   v = FiberLocalVar.new(14)
#
#   Fiber.new do
#     v.value #=> 14
#     v.value = 1
#     v.value #=> 1
#   end.resume
#
#   Fiber.new do
#     v.value #=> 14
#     v.value = 2
#     v.value #=> 2
#   end.resume
#
#   v.value #=> 14
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/fiber_local_var.rb:41
class Concurrent::FiberLocalVar
  # Creates a fiber local variable.
  #
  # @param [Object] default the default value when otherwise unset
  # @param [Proc] default_block Optional block that gets called to obtain the
  #   default value for each fiber
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/fiber_local_var.rb:49
  def initialize(default = T.unsafe(nil), &default_block); end

  # Bind the given value to fiber local storage during
  # execution of the given block.
  #
  # @param [Object] value the value to bind
  # @yield the operation to be performed with the bound variable
  # @return [Object] the value
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/fiber_local_var.rb:86
  def bind(value); end

  # Returns the value in the current fiber's copy of this fiber-local variable.
  #
  # @return [Object] the current value
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/fiber_local_var.rb:68
  def value; end

  # Sets the current fiber's copy of this fiber-local variable to the specified value.
  #
  # @param [Object] value the value to set
  # @return [Object] the new value
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/fiber_local_var.rb:76
  def value=(value); end

  protected

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/fiber_local_var.rb:101
  def default; end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/fiber_local_var.rb:42
Concurrent::FiberLocalVar::LOCALS = T.let(T.unsafe(nil), Concurrent::FiberLocals)

# @!visibility private
# @!macro internal_implementation_note
# An array-backed storage of indexed variables per fiber.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:166
class Concurrent::FiberLocals < ::Concurrent::AbstractLocals
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:167
  def locals; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:171
  def locals!; end
end

# @!macro fixed_thread_pool
#
#   A thread pool that reuses a fixed number of threads operating off an unbounded queue.
#   At any point, at most `num_threads` will be active processing tasks. When all threads are busy new
#   tasks `#post` to the thread pool are enqueued until a thread becomes available.
#   Should a thread crash for any reason the thread will immediately be removed
#   from the pool and replaced.
#
#   The API and behavior of this class are based on Java's `FixedThreadPool`
#
# @!macro thread_pool_options
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/fixed_thread_pool.rb:199
class Concurrent::FixedThreadPool < ::Concurrent::ThreadPoolExecutor
  # @!macro fixed_thread_pool_method_initialize
  #
  #   Create a new thread pool.
  #
  #   @param [Integer] num_threads the number of threads to allocate
  #   @param [Hash] opts the options defining pool behavior.
  #   @option opts [Symbol] :fallback_policy (`:abort`) the fallback policy
  #
  #   @raise [ArgumentError] if `num_threads` is less than or equal to zero
  #   @raise [ArgumentError] if `fallback_policy` is not a known policy
  #
  #   @see http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Executors.html#newFixedThreadPool-int-
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/fixed_thread_pool.rb:213
  def initialize(num_threads, opts = T.unsafe(nil)); end
end

# {include:file:docs-source/future.md}
#
# @!macro copy_options
#
# @see http://ruby-doc.org/stdlib-2.1.1/libdoc/observer/rdoc/Observable.html Ruby Observable module
# @see http://clojuredocs.org/clojure_core/clojure.core/future Clojure's future function
# @see http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Future.html java.util.concurrent.Future
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/future.rb:21
class Concurrent::Future < ::Concurrent::IVar
  # Create a new `Future` in the `:unscheduled` state.
  #
  # @yield the asynchronous operation to perform
  #
  # @!macro executor_and_deref_options
  #
  # @option opts [object, Array] :args zero or more arguments to be passed the task
  #   block on execution
  #
  # @raise [ArgumentError] if no block is given
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/future.rb:33
  def initialize(opts = T.unsafe(nil), &block); end

  # Attempt to cancel the operation if it has not already processed.
  # The operation can only be cancelled while still `pending`. It cannot
  # be cancelled once it has begun processing or has completed.
  #
  # @return [Boolean] was the operation successfully cancelled.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/future.rb:99
  def cancel; end

  # Has the operation been successfully cancelled?
  #
  # @return [Boolean]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/future.rb:111
  def cancelled?; end

  # Execute an `:unscheduled` `Future`. Immediately sets the state to `:pending` and
  # passes the block to a new thread/thread pool for eventual execution.
  # Does nothing if the `Future` is in any state other than `:unscheduled`.
  #
  # @return [Future] a reference to `self`
  #
  # @example Instance and execute in separate steps
  #   future = Concurrent::Future.new{ sleep(1); 42 }
  #   future.state #=> :unscheduled
  #   future.execute
  #   future.state #=> :pending
  #
  # @example Instance and execute in one line
  #   future = Concurrent::Future.new{ sleep(1); 42 }.execute
  #   future.state #=> :pending
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/future.rb:53
  def execute; end

  # @!macro ivar_set_method
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/future.rb:82
  def set(value = T.unsafe(nil), &block); end

  # Wait the given number of seconds for the operation to complete.
  # On timeout attempt to cancel the operation.
  #
  # @param [Numeric] timeout the maximum time in seconds to wait.
  # @return [Boolean] true if the operation completed before the timeout
  #   else false
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/future.rb:121
  def wait_or_cancel(timeout); end

  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/future.rb:133
  def ns_initialize(value, opts); end

  class << self
    # Create a new `Future` object with the given block, execute it, and return the
    # `:pending` object.
    #
    # @yield the asynchronous operation to perform
    #
    # @!macro executor_and_deref_options
    #
    # @option opts [object, Array] :args zero or more arguments to be passed the task
    #   block on execution
    #
    # @raise [ArgumentError] if no block is given
    #
    # @return [Future] the newly created `Future` in the `:pending` state
    #
    # @example
    #   future = Concurrent::Future.execute{ sleep(1); 42 }
    #   future.state #=> :pending
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/future.rb:77
    def execute(opts = T.unsafe(nil), &block); end
  end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/configuration.rb:18
Concurrent::GLOBAL_FAST_EXECUTOR = T.let(T.unsafe(nil), Concurrent::Delay)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/configuration.rb:30
Concurrent::GLOBAL_IMMEDIATE_EXECUTOR = T.let(T.unsafe(nil), Concurrent::ImmediateExecutor)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/configuration.rb:22
Concurrent::GLOBAL_IO_EXECUTOR = T.let(T.unsafe(nil), Concurrent::Delay)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:111
Concurrent::GLOBAL_LOGGER = T.let(T.unsafe(nil), Concurrent::AtomicReference)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/configuration.rb:26
Concurrent::GLOBAL_TIMER_SET = T.let(T.unsafe(nil), Concurrent::Delay)

# @!macro concurrent_hash
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/hash.rb:49
class Concurrent::Hash < ::Hash; end

# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/hash.rb:16
Concurrent::HashImplementation = Hash

# An `IVar` is like a future that you can assign. As a future is a value that
# is being computed that you can wait on, an `IVar` is a value that is waiting
# to be assigned, that you can wait on. `IVars` are single assignment and
# deterministic.
#
# Then, express futures as an asynchronous computation that assigns an `IVar`.
# The `IVar` becomes the primitive on which [futures](Future) and
# [dataflow](Dataflow) are built.
#
# An `IVar` is a single-element container that is normally created empty, and
# can only be set once. The I in `IVar` stands for immutable. Reading an
# `IVar` normally blocks until it is set. It is safe to set and read an `IVar`
# from different threads.
#
# If you want to have some parallel task set the value in an `IVar`, you want
# a `Future`. If you want to create a graph of parallel tasks all executed
# when the values they depend on are ready you want `dataflow`. `IVar` is
# generally a low-level primitive.
#
# ## Examples
#
# Create, set and get an `IVar`
#
# ```ruby
# ivar = Concurrent::IVar.new
# ivar.set 14
# ivar.value #=> 14
# ivar.set 2 # would now be an error
# ```
#
# ## See Also
#
# 1. For the theory: Arvind, R. Nikhil, and K. Pingali.
#    [I-Structures: Data structures for parallel computing](http://dl.acm.org/citation.cfm?id=69562).
#    In Proceedings of Workshop on Graph Reduction, 1986.
# 2. For recent application:
#    [DataDrivenFuture in Habanero Java from Rice](http://www.cs.rice.edu/~vs3/hjlib/doc/edu/rice/hj/api/HjDataDrivenFuture.html).
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:48
class Concurrent::IVar < ::Concurrent::Synchronization::LockableObject
  include ::Concurrent::Concern::Dereferenceable
  include ::Concurrent::Concern::Obligation
  include ::Concurrent::Concern::Observable

  # Create a new `IVar` in the `:pending` state with the (optional) initial value.
  #
  # @param [Object] value the initial value
  # @param [Hash] opts the options to create a message with
  # @option opts [String] :dup_on_deref (false) call `#dup` before returning
  #   the data
  # @option opts [String] :freeze_on_deref (false) call `#freeze` before
  #   returning the data
  # @option opts [String] :copy_on_deref (nil) call the given `Proc` passing
  #   the internal value and returning the value returned from the proc
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:62
  def initialize(value = T.unsafe(nil), opts = T.unsafe(nil), &block); end

  # Add an observer on this object that will receive notification on update.
  #
  # Upon completion the `IVar` will notify all observers in a thread-safe way.
  # The `func` method of the observer will be called with three arguments: the
  # `Time` at which the `Future` completed the asynchronous operation, the
  # final `value` (or `nil` on rejection), and the final `reason` (or `nil` on
  # fulfillment).
  #
  # @param [Object] observer the object that will be notified of changes
  # @param [Symbol] func symbol naming the method to call when this
  #   `Observable` has changes`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:81
  def add_observer(observer = T.unsafe(nil), func = T.unsafe(nil), &block); end

  # @!macro ivar_fail_method
  #   Set the `IVar` to failed due to some error and wake or notify all threads waiting on it.
  #
  #   @param [Object] reason for the failure
  #   @raise [Concurrent::MultipleAssignmentError] if the `IVar` has already
  #     been set or otherwise completed
  #   @return [IVar] self
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:135
  def fail(reason = T.unsafe(nil)); end

  # @!macro ivar_set_method
  #   Set the `IVar` to a value and wake or notify all threads waiting on it.
  #
  #   @!macro ivar_set_parameters_and_exceptions
  #     @param [Object] value the value to store in the `IVar`
  #     @yield A block operation to use for setting the value
  #     @raise [ArgumentError] if both a value and a block are given
  #     @raise [Concurrent::MultipleAssignmentError] if the `IVar` has already
  #       been set or otherwise completed
  #
  #   @return [IVar] self
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:113
  def set(value = T.unsafe(nil)); end

  # Attempt to set the `IVar` with the given value or block. Return a
  # boolean indicating the success or failure of the set operation.
  #
  # @!macro ivar_set_parameters_and_exceptions
  #
  # @return [Boolean] true if the value was set else false
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:145
  def try_set(value = T.unsafe(nil), &block); end

  protected

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:202
  def check_for_block_or_value!(block_given, value); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:177
  def complete(success, value, reason); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:184
  def complete_without_notification(success, value, reason); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:190
  def notify_observers(value, reason); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:195
  def ns_complete_without_notification(success, value, reason); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:155
  def ns_initialize(value, opts); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/ivar.rb:168
  def safe_execute(task, args = T.unsafe(nil)); end
end

# Raised when an operation is attempted which is not legal given the
# receiver's current state
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:20
class Concurrent::IllegalOperationError < ::Concurrent::Error; end

# An executor service which runs all operations on the current thread,
# blocking as necessary. Operations are performed in the order they are
# received and no two operations can be performed simultaneously.
#
# This executor service exists mainly for testing an debugging. When used
# it immediately runs every `#post` operation on the current thread, blocking
# that thread until the operation is complete. This can be very beneficial
# during testing because it makes all operations deterministic.
#
# @note Intended for use primarily in testing and debugging.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/immediate_executor.rb:17
class Concurrent::ImmediateExecutor < ::Concurrent::AbstractExecutorService
  include ::Concurrent::SerialExecutorService

  # Creates a new executor
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/immediate_executor.rb:21
  def initialize; end

  # @!macro executor_service_method_left_shift
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/immediate_executor.rb:34
  def <<(task); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/immediate_executor.rb:59
  def kill; end

  # @!macro executor_service_method_post
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/immediate_executor.rb:26
  def post(*args, &task); end

  # @!macro executor_service_method_running_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/immediate_executor.rb:40
  def running?; end

  # @!macro executor_service_method_shutdown
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/immediate_executor.rb:55
  def shutdown; end

  # @!macro executor_service_method_shutdown_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/immediate_executor.rb:50
  def shutdown?; end

  # @!macro executor_service_method_shuttingdown_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/immediate_executor.rb:45
  def shuttingdown?; end

  # @!macro executor_service_method_wait_for_termination
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/immediate_executor.rb:62
  def wait_for_termination(timeout = T.unsafe(nil)); end
end

# Raised when an attempt is made to violate an immutability guarantee.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:16
class Concurrent::ImmutabilityError < ::Concurrent::Error; end

# A thread-safe, immutable variation of Ruby's standard `Struct`.
#
# @see http://ruby-doc.org/core/Struct.html Ruby standard library `Struct`
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:9
module Concurrent::ImmutableStruct
  include ::Concurrent::Synchronization::AbstractStruct

  # @!macro struct_equality
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:51
  def ==(other); end

  # @!macro struct_get
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:46
  def [](member); end

  # @!macro struct_each
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:56
  def each(&block); end

  # @!macro struct_each_pair
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:62
  def each_pair(&block); end

  # @!macro struct_inspect
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:29
  def inspect; end

  # @!macro struct_merge
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:36
  def merge(other, &block); end

  # @!macro struct_select
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:68
  def select(&block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:21
  def to_a; end

  # @!macro struct_to_h
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:41
  def to_h; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:33
  def to_s; end

  # @!macro struct_values
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:17
  def values; end

  # @!macro struct_values_at
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:24
  def values_at(*indexes); end

  private

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:76
  def initialize_copy(original); end

  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:12
    def included(base); end

    # @!macro struct_new
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:82
    def new(*args, &block); end
  end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/immutable_struct.rb:92
Concurrent::ImmutableStruct::FACTORY = T.let(T.unsafe(nil), T.untyped)

# An executor service which runs all operations on a new thread, blocking
# until it completes. Operations are performed in the order they are received
# and no two operations can be performed simultaneously.
#
# This executor service exists mainly for testing an debugging. When used it
# immediately runs every `#post` operation on a new thread, blocking the
# current thread until the operation is complete. This is similar to how the
# ImmediateExecutor works, but the operation has the full stack of the new
# thread at its disposal. This can be helpful when the operations will spawn
# more operations on the same executor and so on - such a situation might
# overflow the single stack in case of an ImmediateExecutor, which is
# inconsistent with how it would behave for a threaded executor.
#
# @note Intended for use primarily in testing and debugging.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/indirect_immediate_executor.rb:19
class Concurrent::IndirectImmediateExecutor < ::Concurrent::ImmediateExecutor
  # Creates a new executor
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/indirect_immediate_executor.rb:21
  def initialize; end

  # @!macro executor_service_method_post
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/indirect_immediate_executor.rb:27
  def post(*args, &task); end
end

# Raised when an object's methods are called when it has not been
# properly initialized.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:24
class Concurrent::InitializationError < ::Concurrent::Error; end

# Raised when a lifecycle method (such as `stop`) is called in an improper
# sequence or when the object is in an inappropriate state.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:13
class Concurrent::LifecycleError < ::Concurrent::Error; end

# @!macro warn.edge
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:6
class Concurrent::LockFreeStack < ::Concurrent::Synchronization::Object
  include ::Enumerable
  extend ::Concurrent::Synchronization::SafeInitialization

  # @param [Node] head
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:51
  def initialize(head = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:37
  def __initialize_atomic_fields__; end

  # @return [true, false]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:118
  def clear; end

  # @return [self]
  # @yield over the cleared stack
  # @yieldparam [Object] value
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:142
  def clear_each(&block); end

  # @param [Node] head
  # @return [true, false]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:128
  def clear_if(head); end

  # @param [Node] head
  # @return [true, false]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:99
  def compare_and_clear(head); end

  # @param [Node] head
  # @return [true, false]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:85
  def compare_and_pop(head); end

  # @param [Node] head
  # @param [Object] value
  # @return [true, false]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:65
  def compare_and_push(head, value); end

  # @param [Node] head
  # @return [self]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:107
  def each(head = T.unsafe(nil)); end

  # @param [Node] head
  # @return [true, false]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:58
  def empty?(head = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:158
  def inspect; end

  # @return [Node]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:79
  def peek; end

  # @return [Object]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:90
  def pop; end

  # @param [Object] value
  # @return [self]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:71
  def push(value); end

  # @param [Node] head
  # @param [Node] new_head
  # @return [true, false]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:135
  def replace_if(head, new_head); end

  # @return [String] Short string representation.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:154
  def to_s; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:37
  def compare_and_set_head(expected, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:37
  def head; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:37
  def head=(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:37
  def swap_head(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:37
  def update_head(&block); end

  class << self
    # @!visibility private
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:41
    def of1(value); end

    # @!visibility private
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:46
    def of2(value1, value2); end
  end
end

# The singleton for empty node
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:32
Concurrent::LockFreeStack::EMPTY = T.let(T.unsafe(nil), Concurrent::LockFreeStack::Node)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:10
class Concurrent::LockFreeStack::Node
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:23
  def initialize(value, next_node); end

  # @return [Node]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:14
  def next_node; end

  # @return [Object]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:17
  def value; end

  # @return [Object]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:21
  def value=(_arg0); end

  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/collection/lock_free_stack.rb:28
    def [](*_arg0); end
  end
end

# Either {FiberLocalVar} or {ThreadLocalVar} depending on whether Mutex (and Monitor)
# are held, respectively, per Fiber or per Thread.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/lock_local_var.rb:22
Concurrent::LockLocalVar = Concurrent::FiberLocalVar

# An `MVar` is a synchronized single element container. They are empty or
# contain one item. Taking a value from an empty `MVar` blocks, as does
# putting a value into a full one. You can either think of them as blocking
# queue of length one, or a special kind of mutable variable.
#
# On top of the fundamental `#put` and `#take` operations, we also provide a
# `#modify` that is atomic with respect to operations on the same instance.
# These operations all support timeouts.
#
# We also support non-blocking operations `#try_put!` and `#try_take!`, a
# `#set!` that ignores existing values, a `#value` that returns the value
# without removing it or returns `MVar::EMPTY`, and a `#modify!` that yields
# `MVar::EMPTY` if the `MVar` is empty and can be used to set `MVar::EMPTY`.
# You shouldn't use these operations in the first instance.
#
# `MVar` is a [Dereferenceable](Dereferenceable).
#
# `MVar` is related to M-structures in Id, `MVar` in Haskell and `SyncVar` in Scala.
#
# Note that unlike the original Haskell paper, our `#take` is blocking. This is how
# Haskell and Scala do it today.
#
# @!macro copy_options
#
# ## See Also
#
# 1. P. Barth, R. Nikhil, and Arvind. [M-Structures: Extending a parallel, non- strict, functional language with state](http://dl.acm.org/citation.cfm?id=652538). In Proceedings of the 5th
#    ACM Conference on Functional Programming Languages and Computer Architecture (FPCA), 1991.
#
# 2. S. Peyton Jones, A. Gordon, and S. Finne. [Concurrent Haskell](http://dl.acm.org/citation.cfm?id=237794).
#    In Proceedings of the 23rd Symposium on Principles of Programming Languages
#    (PoPL), 1996.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:38
class Concurrent::MVar < ::Concurrent::Synchronization::Object
  include ::Concurrent::Concern::Dereferenceable
  extend ::Concurrent::Synchronization::SafeInitialization

  # Create a new `MVar`, either empty or with an initial value.
  #
  # @param [Hash] opts the options controlling how the future will be processed
  #
  # @!macro deref_options
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:54
  def initialize(value = T.unsafe(nil), opts = T.unsafe(nil)); end

  # acquires lock on the from an `MVAR`, yields the value to provided block,
  # and release lock. A timeout can be set to limit the time spent blocked,
  # in which case it returns `TIMEOUT` if the time is exceeded.
  # @return [Object] the value returned by the block, or `TIMEOUT`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:86
  def borrow(timeout = T.unsafe(nil)); end

  # Returns if the `MVar` is currently empty.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:195
  def empty?; end

  # Returns if the `MVar` currently contains a value.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:200
  def full?; end

  # Atomically `take`, yield the value to a block for transformation, and then
  # `put` the transformed value. Returns the pre-transform value. A timeout can
  # be set to limit the time spent blocked, in which case it returns `TIMEOUT`
  # if the time is exceeded.
  # @return [Object] the pre-transform value, or `TIMEOUT`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:123
  def modify(timeout = T.unsafe(nil)); end

  # Non-blocking version of `modify` that will yield with `EMPTY` if there is no value yet.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:179
  def modify!; end

  # Put a value into an `MVar`, blocking if there is already a value until
  # it is empty. A timeout can be set to limit the time spent blocked, in
  # which case it returns `TIMEOUT` if the time is exceeded.
  # @return [Object] the value that was put, or `TIMEOUT`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:103
  def put(value, timeout = T.unsafe(nil)); end

  # Non-blocking version of `put` that will overwrite an existing value.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:169
  def set!(value); end

  # Remove the value from an `MVar`, leaving it empty, and blocking if there
  # isn't a value. A timeout can be set to limit the time spent blocked, in
  # which case it returns `TIMEOUT` if the time is exceeded.
  # @return [Object] the value that was taken, or `TIMEOUT`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:66
  def take(timeout = T.unsafe(nil)); end

  # Non-blocking version of `put`, that returns whether or not it was successful.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:156
  def try_put!(value); end

  # Non-blocking version of `take`, that returns `EMPTY` instead of blocking.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:142
  def try_take!; end

  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:206
  def synchronize(&block); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:212
  def unlocked_empty?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:216
  def unlocked_full?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:224
  def wait_for_empty(timeout); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:220
  def wait_for_full(timeout); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:228
  def wait_while(condition, timeout); end
end

# Unique value that represents that an `MVar` was empty
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:43
Concurrent::MVar::EMPTY = T.let(T.unsafe(nil), Object)

# Unique value that represents that an `MVar` timed out before it was able
# to produce a value.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mvar.rb:47
Concurrent::MVar::TIMEOUT = T.let(T.unsafe(nil), Object)

# `Concurrent::Map` is a hash-like object and should have much better performance
# characteristics, especially under high concurrency, than `Concurrent::Hash`.
# However, `Concurrent::Map `is not strictly semantically equivalent to a ruby `Hash`
# -- for instance, it does not necessarily retain ordering by insertion time as `Hash`
# does. For most uses it should do fine though, and we recommend you consider
# `Concurrent::Map` instead of `Concurrent::Hash` for your concurrency-safe hash needs.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:39
class Concurrent::Map < ::Concurrent::Collection::MriMapBackend
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:279
  def each; end

  # Iterates over each key.
  # @yield for each key in the map
  # @yieldparam key [Object]
  # @return [self]
  # @!macro map.atomic_method_with_block
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:255
  def each_key; end

  # Iterates over each key value pair.
  # @yield for each key value pair in the map
  # @yieldparam key [Object]
  # @yieldparam value [Object]
  # @return [self]
  # @!macro map.atomic_method_with_block
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:274
  def each_pair; end

  # Iterates over each value.
  # @yield for each value in the map
  # @yieldparam value [Object]
  # @return [self]
  # @!macro map.atomic_method_with_block
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:264
  def each_value; end

  # Is map empty?
  # @return [true, false]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:291
  def empty?; end

  # Get a value with key, or default_value when key is absent,
  # or fail when no default_value is given.
  # @param [Object] key
  # @param [Object] default_value
  # @yield default value for a key
  # @yieldparam key [Object]
  # @yieldreturn [Object] default value
  # @return [Object] the value or default value
  # @raise [KeyError] when key is missing and no default_value is provided
  # @!macro map_method_not_atomic
  #   @note The "fetch-then-act" methods of `Map` are not atomic. `Map` is intended
  #     to be use as a concurrency primitive with strong happens-before
  #     guarantees. It is not intended to be used as a high-level abstraction
  #     supporting complex operations. All read and write operations are
  #     thread safe, but no guarantees are made regarding race conditions
  #     between the fetch operation and yielding to the block. Additionally,
  #     this method does not support recursion. This is due to internal
  #     constraints that are very unlikely to change in the near future.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:183
  def fetch(key, default_value = T.unsafe(nil)); end

  # Fetch value with key, or store default value when key is absent,
  # or fail when no default_value is given. This is a two step operation,
  # therefore not atomic. The store can overwrite other concurrently
  # stored value.
  # @param [Object] key
  # @param [Object] default_value
  # @yield default value for a key
  # @yieldparam key [Object]
  # @yieldreturn [Object] default value
  # @return [Object] the value or default value
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:205
  def fetch_or_store(key, default_value = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:162
  def get(key); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:321
  def inspect; end

  # Find key of a value.
  # @param [Object] value
  # @return [Object, nil] key or nil when not found
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:284
  def key(value); end

  # All keys
  # @return [::Array<Object>] keys
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:236
  def keys; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:305
  def marshal_dump; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:313
  def marshal_load(hash); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:163
  def put(key, value); end

  # Insert value into map with key if key is absent in one atomic step.
  # @param [Object] key
  # @param [Object] value
  # @return [Object, nil] the previous value when key was present or nil when there was no key
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:215
  def put_if_absent(key, value); end

  # Is the value stored in the map. Iterates over all values.
  # @param [Object] value
  # @return [true, false]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:227
  def value?(value); end

  # All values
  # @return [::Array<Object>] values
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:244
  def values; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:331
  def initialize_copy(other); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:336
  def populate_from(hash); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:327
  def raise_fetch_no_key; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/map.rb:341
  def validate_options_hash!(options); end
end

# Raised when an object with a start/stop lifecycle has been started an
# excessive number of times. Often used in conjunction with a restart
# policy or strategy.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:29
class Concurrent::MaxRestartFrequencyError < ::Concurrent::Error; end

# A `Maybe` encapsulates an optional value. A `Maybe` either contains a value
# of (represented as `Just`), or it is empty (represented as `Nothing`). Using
# `Maybe` is a good way to deal with errors or exceptional cases without
# resorting to drastic measures such as exceptions.
#
# `Maybe` is a replacement for the use of `nil` with better type checking.
#
# For compatibility with {Concurrent::Concern::Obligation} the predicate and
# accessor methods are aliased as `fulfilled?`, `rejected?`, `value`, and
# `reason`.
#
# ## Motivation
#
# A common pattern in languages with pattern matching, such as Erlang and
# Haskell, is to return *either* a value *or* an error from a function
# Consider this Erlang code:
#
# ```erlang
# case file:consult("data.dat") of
#   {ok, Terms} -> do_something_useful(Terms);
#   {error, Reason} -> lager:error(Reason)
# end.
# ```
#
# In this example the standard library function `file:consult` returns a
# [tuple](http://erlang.org/doc/reference_manual/data_types.html#id69044)
# with two elements: an [atom](http://erlang.org/doc/reference_manual/data_types.html#id64134)
# (similar to a ruby symbol) and a variable containing ancillary data. On
# success it returns the atom `ok` and the data from the file. On failure it
# returns `error` and a string with an explanation of the problem. With this
# pattern there is no ambiguity regarding success or failure. If the file is
# empty the return value cannot be misinterpreted as an error. And when an
# error occurs the return value provides useful information.
#
# In Ruby we tend to return `nil` when an error occurs or else we raise an
# exception. Both of these idioms are problematic. Returning `nil` is
# ambiguous because `nil` may also be a valid value. It also lacks
# information pertaining to the nature of the error. Raising an exception
# is both expensive and usurps the normal flow of control. All of these
# problems can be solved with the use of a `Maybe`.
#
# A `Maybe` is unambiguous with regard to whether or not it contains a value.
# When `Just` it contains a value, when `Nothing` it does not. When `Just`
# the value it contains may be `nil`, which is perfectly valid. When
# `Nothing` the reason for the lack of a value is contained as well. The
# previous Erlang example can be duplicated in Ruby in a principled way by
# having functions return `Maybe` objects:
#
# ```ruby
# result = MyFileUtils.consult("data.dat") # returns a Maybe
# if result.just?
#   do_something_useful(result.value)      # or result.just
# else
#   logger.error(result.reason)            # or result.nothing
# end
# ```
#
# @example Returning a Maybe from a Function
#   module MyFileUtils
#     def self.consult(path)
#       file = File.open(path, 'r')
#       Concurrent::Maybe.just(file.read)
#     rescue => ex
#       return Concurrent::Maybe.nothing(ex)
#     ensure
#       file.close if file
#     end
#   end
#
#   maybe = MyFileUtils.consult('bogus.file')
#   maybe.just?    #=> false
#   maybe.nothing? #=> true
#   maybe.reason   #=> #<Errno::ENOENT: No such file or directory @ rb_sysopen - bogus.file>
#
#   maybe = MyFileUtils.consult('README.md')
#   maybe.just?    #=> true
#   maybe.nothing? #=> false
#   maybe.value    #=> "# Concurrent Ruby\n[![Gem Version..."
#
# @example Using Maybe with a Block
#   result = Concurrent::Maybe.from do
#     Client.find(10) # Client is an ActiveRecord model
#   end
#
#   # -- if the record was found
#   result.just? #=> true
#   result.value #=> #<Client id: 10, first_name: "Ryan">
#
#   # -- if the record was not found
#   result.just?  #=> false
#   result.reason #=> ActiveRecord::RecordNotFound
#
# @example Using Maybe with the Null Object Pattern
#   # In a Rails controller...
#   result = ClientService.new(10).find    # returns a Maybe
#   render json: result.or(NullClient.new)
#
# @see https://hackage.haskell.org/package/base-4.2.0.1/docs/Data-Maybe.html Haskell Data.Maybe
# @see https://github.com/purescript/purescript-maybe/blob/master/docs/Data.Maybe.md PureScript Data.Maybe
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:104
class Concurrent::Maybe < ::Concurrent::Synchronization::Object
  include ::Comparable
  extend ::Concurrent::Synchronization::SafeInitialization

  # Create a new `Maybe` with the given attributes.
  #
  # @param [Object] just The value when `Just` else `NONE`.
  # @param [Exception, Object] nothing The exception when `Nothing` else `NONE`.
  #
  # @return [Maybe] The new `Maybe`.
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:224
  def initialize(just, nothing); end

  # Comparison operator.
  #
  # @return [Integer] 0 if self and other are both `Nothing`;
  #   -1 if self is `Nothing` and other is `Just`;
  #   1 if self is `Just` and other is nothing;
  #   `self.just <=> other.just` if both self and other are `Just`.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:199
  def <=>(other); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:179
  def fulfilled?; end

  # The value of a `Maybe` when `Just`. Will be `NONE` when `Nothing`.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:114
  def just; end

  # Is this `Maybe` a `Just` (successfully fulfilled with a value)?
  #
  # @return [Boolean] True if `Just` or false if `Nothing`.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:176
  def just?; end

  # The reason for the `Maybe` when `Nothing`. Will be `NONE` when `Just`.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:117
  def nothing; end

  # Is this `Maybe` a `nothing` (rejected with an exception upon fulfillment)?
  #
  # @return [Boolean] True if `Nothing` or false if `Just`.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:184
  def nothing?; end

  # Return either the value of self or the given default value.
  #
  # @return [Object] The value of self when `Just`; else the given default.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:210
  def or(other); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:191
  def reason; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:187
  def rejected?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:189
  def value; end

  class << self
    # Create a new `Maybe` using the given block.
    #
    # Runs the given block passing all function arguments to the block as block
    # arguments. If the block runs to completion without raising an exception
    # a new `Just` is created with the value set to the return value of the
    # block. If the block raises an exception a new `Nothing` is created with
    # the reason being set to the raised exception.
    #
    # @param [Array<Object>] args Zero or more arguments to pass to the block.
    # @yield The block from which to create a new `Maybe`.
    # @yieldparam [Array<Object>] args Zero or more block arguments passed as
    #   arguments to the function.
    #
    # @return [Maybe] The newly created object.
    #
    # @raise [ArgumentError] when no block given.
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:137
    def from(*args); end

    # Create a new `Just` with the given value.
    #
    # @param [Object] value The value to set for the new `Maybe` object.
    #
    # @return [Maybe] The newly created object.
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:152
    def just(value); end

    # Create a new `Nothing` with the given (optional) reason.
    #
    # @param [Exception] error The reason to set for the new `Maybe` object.
    #   When given a string a new `StandardError` will be created with the
    #   argument as the message. When no argument is given a new
    #   `StandardError` with an empty message will be created.
    #
    # @return [Maybe] The newly created object.
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:164
    def nothing(error = T.unsafe(nil)); end

    private

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:119
    def new(*args, &block); end
  end
end

# Indicates that the given attribute has not been set.
# When `Just` the {#nothing} getter will return `NONE`.
# When `Nothing` the {#just} getter will return `NONE`.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/maybe.rb:111
Concurrent::Maybe::NONE = T.let(T.unsafe(nil), Object)

# Raised when an attempt is made to modify an immutable object
# (such as an `IVar`) after its final state has been set.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:33
class Concurrent::MultipleAssignmentError < ::Concurrent::Error
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:36
  def initialize(message = T.unsafe(nil), inspection_data = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:41
  def inspect; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:34
  def inspection_data; end
end

# Aggregates multiple exceptions.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:58
class Concurrent::MultipleErrors < ::Concurrent::Error
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:61
  def initialize(errors, message = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:59
  def errors; end
end

# An thread-safe variation of Ruby's standard `Struct`. Values can be set at
# construction or safely changed at any time during the object's lifecycle.
#
# @see http://ruby-doc.org/core/Struct.html Ruby standard library `Struct`
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:10
module Concurrent::MutableStruct
  include ::Concurrent::Synchronization::AbstractStruct

  # @!macro struct_equality
  #
  #   Equality
  #
  #   @return [Boolean] true if other has the same struct subclass and has
  #     equal member values (according to `Object#==`)
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:128
  def ==(other); end

  # @!macro struct_get
  #
  #   Attribute Reference
  #
  #   @param [Symbol, String, Integer] member the string or symbol name of the member
  #     for which to obtain the value or the member's index
  #
  #   @return [Object] the value of the given struct member or the member at the given index.
  #
  #   @raise [NameError] if the member does not exist
  #   @raise [IndexError] if the index is out of range.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:118
  def [](member); end

  # @!macro struct_set
  #
  #   Attribute Assignment
  #
  #   Sets the value of the given struct member or the member at the given index.
  #
  #   @param [Symbol, String, Integer] member the string or symbol name of the member
  #     for which to obtain the value or the member's index
  #
  #   @return [Object] the value of the given struct member or the member at the given index.
  #
  #   @raise [NameError] if the name does not exist
  #   @raise [IndexError] if the index is out of range.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:185
  def []=(member, value); end

  # @!macro struct_each
  #
  #   Yields the value of each struct member in order. If no block is given
  #   an enumerator is returned.
  #
  #   @yield the operation to be performed on each struct member
  #   @yieldparam [Object] value each struct value (in order)
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:139
  def each(&block); end

  # @!macro struct_each_pair
  #
  #   Yields the name and value of each struct member in order. If no block is
  #   given an enumerator is returned.
  #
  #   @yield the operation to be performed on each struct member/value pair
  #   @yieldparam [Object] member each struct member (in order)
  #   @yieldparam [Object] value each struct value (in order)
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:152
  def each_pair(&block); end

  # @!macro struct_inspect
  #
  #   Describe the contents of this struct in a string.
  #
  #   @return [String] the contents of this struct in a string
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:72
  def inspect; end

  # @!macro struct_merge
  #
  #   Returns a new struct containing the contents of `other` and the contents
  #   of `self`. If no block is specified, the value for entries with duplicate
  #   keys will be that of `other`. Otherwise the value for each duplicate key
  #   is determined by calling the block with the key, its value in `self` and
  #   its value in `other`.
  #
  #   @param [Hash] other the hash from which to set the new values
  #   @yield an options block for resolving duplicate keys
  #   @yieldparam [String, Symbol] member the name of the member which is duplicated
  #   @yieldparam [Object] selfvalue the value of the member in `self`
  #   @yieldparam [Object] othervalue the value of the member in `other`
  #
  #   @return [Synchronization::AbstractStruct] a new struct with the new values
  #
  #   @raise [ArgumentError] of given a member that is not defined in the struct
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:94
  def merge(other, &block); end

  # @!macro struct_select
  #
  #   Yields each member value from the struct to the block and returns an Array
  #   containing the member values from the struct for which the given block
  #   returns a true value (equivalent to `Enumerable#select`).
  #
  #   @yield the operation to be performed on each struct member
  #   @yieldparam [Object] value each struct value (in order)
  #
  #   @return [Array] an array containing each value for which the block returns true
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:167
  def select(&block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:54
  def to_a; end

  # @!macro struct_to_h
  #
  #   Returns a hash containing the names and values for the structs members.
  #
  #   @return [Hash] the names and values for the structs members
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:103
  def to_h; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:75
  def to_s; end

  # @!macro struct_values
  #
  #   Returns the values for this struct as an Array.
  #
  #   @return [Array] the values for this struct
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:51
  def values; end

  # @!macro struct_values_at
  #
  #   Returns the struct member values for each selector as an Array.
  #
  #   A selector may be either an Integer offset or a Range of offsets (as in `Array#values_at`).
  #
  #   @param [Fixnum, Range] indexes the index(es) from which to obatin the values (in order)
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:63
  def values_at(*indexes); end

  private

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:202
  def initialize_copy(original); end

  class << self
    # @!macro struct_new
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:210
    def new(*args, &block); end
  end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/mutable_struct.rb:220
Concurrent::MutableStruct::FACTORY = T.let(T.unsafe(nil), T.untyped)

# @!macro atomic_boolean
# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_boolean.rb:8
class Concurrent::MutexAtomicBoolean
  extend ::Concurrent::Synchronization::SafeInitialization

  # @!macro atomic_boolean_method_initialize
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_boolean.rb:12
  def initialize(initial = T.unsafe(nil)); end

  # @!macro atomic_boolean_method_false_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_boolean.rb:34
  def false?; end

  # @!macro atomic_boolean_method_make_false
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_boolean.rb:44
  def make_false; end

  # @!macro atomic_boolean_method_make_true
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_boolean.rb:39
  def make_true; end

  # @!macro atomic_boolean_method_true_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_boolean.rb:29
  def true?; end

  # @!macro atomic_boolean_method_value_get
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_boolean.rb:19
  def value; end

  # @!macro atomic_boolean_method_value_set
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_boolean.rb:24
  def value=(value); end

  protected

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_boolean.rb:51
  def synchronize; end

  private

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_boolean.rb:62
  def ns_make_value(value); end
end

# @!macro atomic_fixnum
# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_fixnum.rb:9
class Concurrent::MutexAtomicFixnum
  extend ::Concurrent::Synchronization::SafeInitialization

  # @!macro atomic_fixnum_method_initialize
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_fixnum.rb:13
  def initialize(initial = T.unsafe(nil)); end

  # @!macro atomic_fixnum_method_compare_and_set
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_fixnum.rb:44
  def compare_and_set(expect, update); end

  # @!macro atomic_fixnum_method_decrement
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_fixnum.rb:37
  def decrement(delta = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_fixnum.rb:41
  def down(delta = T.unsafe(nil)); end

  # @!macro atomic_fixnum_method_increment
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_fixnum.rb:30
  def increment(delta = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_fixnum.rb:34
  def up(delta = T.unsafe(nil)); end

  # @!macro atomic_fixnum_method_update
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_fixnum.rb:56
  def update; end

  # @!macro atomic_fixnum_method_value_get
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_fixnum.rb:20
  def value; end

  # @!macro atomic_fixnum_method_value_set
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_fixnum.rb:25
  def value=(value); end

  protected

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_fixnum.rb:65
  def synchronize; end

  private

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_atomic_fixnum.rb:76
  def ns_set(value); end
end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb:9
class Concurrent::MutexAtomicReference
  include ::Concurrent::AtomicDirectUpdate
  include ::Concurrent::AtomicNumericCompareAndSetWrapper
  extend ::Concurrent::Synchronization::SafeInitialization

  # @!macro atomic_reference_method_initialize
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb:16
  def initialize(value = T.unsafe(nil)); end

  # @!macro atomic_reference_method_compare_and_set
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb:45
  def _compare_and_set(old_value, new_value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb:13
  def compare_and_swap(old_value, new_value); end

  # @!macro atomic_reference_method_get
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb:23
  def get; end

  # @!macro atomic_reference_method_get_and_set
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb:35
  def get_and_set(new_value); end

  # @!macro atomic_reference_method_set
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb:29
  def set(new_value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb:42
  def swap(new_value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb:26
  def value; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb:32
  def value=(new_value); end

  protected

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb:59
  def synchronize; end
end

# @!macro count_down_latch
# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_count_down_latch.rb:9
class Concurrent::MutexCountDownLatch < ::Concurrent::Synchronization::LockableObject
  # @!macro count_down_latch_method_initialize
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_count_down_latch.rb:12
  def initialize(count = T.unsafe(nil)); end

  # @!macro count_down_latch_method_count
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_count_down_latch.rb:34
  def count; end

  # @!macro count_down_latch_method_count_down
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_count_down_latch.rb:26
  def count_down; end

  # @!macro count_down_latch_method_wait
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_count_down_latch.rb:21
  def wait(timeout = T.unsafe(nil)); end

  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_count_down_latch.rb:40
  def ns_initialize(count); end
end

# @!macro semaphore
# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_semaphore.rb:9
class Concurrent::MutexSemaphore < ::Concurrent::Synchronization::LockableObject
  # @!macro semaphore_method_initialize
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_semaphore.rb:12
  def initialize(count); end

  # @!macro semaphore_method_acquire
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_semaphore.rb:20
  def acquire(permits = T.unsafe(nil)); end

  # @!macro semaphore_method_available_permits
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_semaphore.rb:38
  def available_permits; end

  # @!macro semaphore_method_drain_permits
  #
  #   Acquires and returns all permits that are immediately available.
  #
  #   @return [Integer]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_semaphore.rb:47
  def drain_permits; end

  # Shrinks the number of available permits by the indicated reduction.
  #
  # @param [Fixnum] reduction Number of permits to remove.
  #
  # @raise [ArgumentError] if `reduction` is not an integer or is negative
  #
  # @raise [ArgumentError] if `@free` - `@reduction` is less than zero
  #
  # @return [nil]
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_semaphore.rb:99
  def reduce_permits(reduction); end

  # @!macro semaphore_method_release
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_semaphore.rb:77
  def release(permits = T.unsafe(nil)); end

  # @!macro semaphore_method_try_acquire
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_semaphore.rb:54
  def try_acquire(permits = T.unsafe(nil), timeout = T.unsafe(nil)); end

  protected

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_semaphore.rb:110
  def ns_initialize(count); end

  private

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_semaphore.rb:117
  def try_acquire_now(permits); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/mutex_semaphore.rb:127
  def try_acquire_timed(permits, timeout); end
end

# Various classes within allows for +nil+ values to be stored,
# so a special +NULL+ token is required to indicate the "nil-ness".
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/constants.rb:6
Concurrent::NULL = T.let(T.unsafe(nil), Object)

# Suppresses all output when used for logging.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/concern/logging.rb:108
Concurrent::NULL_LOGGER = T.let(T.unsafe(nil), Proc)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/options.rb:6
module Concurrent::Options
  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/options.rb:27
    def executor(executor_identifier); end

    # Get the requested `Executor` based on the values set in the options hash.
    #
    # @param [Hash] opts the options defining the requested executor
    # @option opts [Executor] :executor when set use the given `Executor` instance.
    #   Three special values are also supported: `:fast` returns the global fast executor,
    #   `:io` returns the global io executor, and `:immediate` returns a new
    #   `ImmediateExecutor` object.
    #
    # @return [Executor, nil] the requested thread pool, or nil when no option specified
    #
    # @!visibility private
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/options.rb:19
    def executor_from_options(opts = T.unsafe(nil)); end
  end
end

# Promises are inspired by the JavaScript [Promises/A](http://wiki.commonjs.org/wiki/Promises/A)
# and [Promises/A+](http://promises-aplus.github.io/promises-spec/) specifications.
#
# > A promise represents the eventual value returned from the single
# > completion of an operation.
#
# Promises are similar to futures and share many of the same behaviours.
# Promises are far more robust, however. Promises can be chained in a tree
# structure where each promise may have zero or more children. Promises are
# chained using the `then` method. The result of a call to `then` is always
# another promise. Promises are resolved asynchronously (with respect to the
# main thread) but in a strict order: parents are guaranteed to be resolved
# before their children, children before their younger siblings. The `then`
# method takes two parameters: an optional block to be executed upon parent
# resolution and an optional callable to be executed upon parent failure. The
# result of each promise is passed to each of its children upon resolution.
# When a promise is rejected all its children will be summarily rejected and
# will receive the reason.
#
# Promises have several possible states: *:unscheduled*, *:pending*,
# *:processing*, *:rejected*, or *:fulfilled*. These are also aggregated as
# `#incomplete?` and `#complete?`. When a Promise is created it is set to
# *:unscheduled*. Once the `#execute` method is called the state becomes
# *:pending*. Once a job is pulled from the thread pool's queue and is given
# to a thread for processing (often immediately upon `#post`) the state
# becomes *:processing*. The future will remain in this state until processing
# is complete. A future that is in the *:unscheduled*, *:pending*, or
# *:processing* is considered `#incomplete?`. A `#complete?` Promise is either
# *:rejected*, indicating that an exception was thrown during processing, or
# *:fulfilled*, indicating success. If a Promise is *:fulfilled* its `#value`
# will be updated to reflect the result of the operation. If *:rejected* the
# `reason` will be updated with a reference to the thrown exception. The
# predicate methods `#unscheduled?`, `#pending?`, `#rejected?`, and
# `#fulfilled?` can be called at any time to obtain the state of the Promise,
# as can the `#state` method, which returns a symbol.
#
# Retrieving the value of a promise is done through the `value` (alias:
# `deref`) method. Obtaining the value of a promise is a potentially blocking
# operation. When a promise is *rejected* a call to `value` will return `nil`
# immediately. When a promise is *fulfilled* a call to `value` will
# immediately return the current value. When a promise is *pending* a call to
# `value` will block until the promise is either *rejected* or *fulfilled*. A
# *timeout* value can be passed to `value` to limit how long the call will
# block. If `nil` the call will block indefinitely. If `0` the call will not
# block. Any other integer or float value will indicate the maximum number of
# seconds to block.
#
# Promises run on the global thread pool.
#
# @!macro copy_options
#
# ### Examples
#
# Start by requiring promises
#
# ```ruby
# require 'concurrent/promise'
# ```
#
# Then create one
#
# ```ruby
# p = Concurrent::Promise.execute do
#       # do something
#       42
#     end
# ```
#
# Promises can be chained using the `then` method. The `then` method accepts a
# block and an executor, to be executed on fulfillment, and a callable argument to be executed
# on rejection. The result of the each promise is passed as the block argument
# to chained promises.
#
# ```ruby
# p = Concurrent::Promise.new{10}.then{|x| x * 2}.then{|result| result - 10 }.execute
# ```
#
# And so on, and so on, and so on...
#
# ```ruby
# p = Concurrent::Promise.fulfill(20).
#     then{|result| result - 10 }.
#     then{|result| result * 3 }.
#     then(executor: different_executor){|result| result % 5 }.execute
# ```
#
# The initial state of a newly created Promise depends on the state of its parent:
# - if parent is *unscheduled* the child will be *unscheduled*
# - if parent is *pending* the child will be *pending*
# - if parent is *fulfilled* the child will be *pending*
# - if parent is *rejected* the child will be *pending* (but will ultimately be *rejected*)
#
# Promises are executed asynchronously from the main thread. By the time a
# child Promise finishes initialization it may be in a different state than its
# parent (by the time a child is created its parent may have completed
# execution and changed state). Despite being asynchronous, however, the order
# of execution of Promise objects in a chain (or tree) is strictly defined.
#
# There are multiple ways to create and execute a new `Promise`. Both ways
# provide identical behavior:
#
# ```ruby
# # create, operate, then execute
# p1 = Concurrent::Promise.new{ "Hello World!" }
# p1.state #=> :unscheduled
# p1.execute
#
# # create and immediately execute
# p2 = Concurrent::Promise.new{ "Hello World!" }.execute
#
# # execute during creation
# p3 = Concurrent::Promise.execute{ "Hello World!" }
# ```
#
# Once the `execute` method is called a `Promise` becomes `pending`:
#
# ```ruby
# p = Concurrent::Promise.execute{ "Hello, world!" }
# p.state    #=> :pending
# p.pending? #=> true
# ```
#
# Wait a little bit, and the promise will resolve and provide a value:
#
# ```ruby
# p = Concurrent::Promise.execute{ "Hello, world!" }
# sleep(0.1)
#
# p.state      #=> :fulfilled
# p.fulfilled? #=> true
# p.value      #=> "Hello, world!"
# ```
#
# If an exception occurs, the promise will be rejected and will provide
# a reason for the rejection:
#
# ```ruby
# p = Concurrent::Promise.execute{ raise StandardError.new("Here comes the Boom!") }
# sleep(0.1)
#
# p.state     #=> :rejected
# p.rejected? #=> true
# p.reason    #=> "#<StandardError: Here comes the Boom!>"
# ```
#
# #### Rejection
#
# When a promise is rejected all its children will be rejected and will
# receive the rejection `reason` as the rejection callable parameter:
#
# ```ruby
# p = Concurrent::Promise.execute { Thread.pass; raise StandardError }
#
# c1 = p.then(-> reason { 42 })
# c2 = p.then(-> reason { raise 'Boom!' })
#
# c1.wait.state  #=> :fulfilled
# c1.value       #=> 42
# c2.wait.state  #=> :rejected
# c2.reason      #=> #<RuntimeError: Boom!>
# ```
#
# Once a promise is rejected it will continue to accept children that will
# receive immediately rejection (they will be executed asynchronously).
#
# #### Aliases
#
# The `then` method is the most generic alias: it accepts a block to be
# executed upon parent fulfillment and a callable to be executed upon parent
# rejection. At least one of them should be passed. The default block is `{
# |result| result }` that fulfills the child with the parent value. The
# default callable is `{ |reason| raise reason }` that rejects the child with
# the parent reason.
#
# - `on_success { |result| ... }` is the same as `then {|result| ... }`
# - `rescue { |reason| ... }` is the same as `then(Proc.new { |reason| ... } )`
# - `rescue` is aliased by `catch` and `on_error`
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:190
class Concurrent::Promise < ::Concurrent::IVar
  # Initialize a new Promise with the provided options.
  #
  # @!macro executor_and_deref_options
  #
  # @!macro promise_init_options
  #
  #   @option opts [Promise] :parent the parent `Promise` when building a chain/tree
  #   @option opts [Proc] :on_fulfill fulfillment handler
  #   @option opts [Proc] :on_reject rejection handler
  #   @option opts [object, Array] :args zero or more arguments to be passed
  #    the task block on execution
  #
  # @yield The block operation to be performed asynchronously.
  #
  # @raise [ArgumentError] if no block is given
  #
  # @see http://wiki.commonjs.org/wiki/Promises/A
  # @see http://promises-aplus.github.io/promises-spec/
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:210
  def initialize(opts = T.unsafe(nil), &block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:364
  def catch(&block); end

  # Execute an `:unscheduled` `Promise`. Immediately sets the state to `:pending` and
  # passes the block to a new thread/thread pool for eventual execution.
  # Does nothing if the `Promise` is in any state other than `:unscheduled`.
  #
  # @return [Promise] a reference to `self`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:246
  def execute; end

  # @!macro ivar_fail_method
  #
  # @raise [Concurrent::PromiseExecutionError] if not the root promise
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:278
  def fail(reason = T.unsafe(nil)); end

  # Yield the successful result to the block that returns a promise. If that
  # promise is also successful the result is the result of the yielded promise.
  # If either part fails the whole also fails.
  #
  # @example
  #   Promise.execute { 1 }.flat_map { |v| Promise.execute { v + 2 } }.value! #=> 3
  #
  # @return [Promise]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:375
  def flat_map(&block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:365
  def on_error(&block); end

  # Chain onto this promise an action to be undertaken on success
  # (fulfillment).
  #
  # @yield The block to execute
  #
  # @return [Promise] self
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:349
  def on_success(&block); end

  # Chain onto this promise an action to be undertaken on failure
  # (rejection).
  #
  # @yield The block to execute
  #
  # @return [Promise] self
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:360
  def rescue(&block); end

  # @!macro ivar_set_method
  #
  # @raise [Concurrent::PromiseExecutionError] if not the root promise
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:262
  def set(value = T.unsafe(nil), &block); end

  # Chain a new promise off the current promise.
  #
  # @return [Promise] the new promise
  # @yield The block operation to be performed asynchronously.
  # @overload then(rescuer, executor, &block)
  #   @param [Proc] rescuer An optional rescue block to be executed if the
  #     promise is rejected.
  #   @param [ThreadPool] executor An optional thread pool executor to be used
  #     in the new Promise
  # @overload then(rescuer, executor: executor, &block)
  #   @param [Proc] rescuer An optional rescue block to be executed if the
  #     promise is rejected.
  #   @param [ThreadPool] executor An optional thread pool executor to be used
  #     in the new Promise
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:314
  def then(*args, &block); end

  # Builds a promise that produces the result of self and others in an Array
  # and fails if any of them fails.
  #
  # @overload zip(*promises)
  #   @param [Array<Promise>] others
  #
  # @overload zip(*promises, opts)
  #   @param [Array<Promise>] others
  #   @param [Hash] opts the configuration options
  #   @option opts [Executor] :executor (ImmediateExecutor.new) when set use the given `Executor` instance.
  #   @option opts [Boolean] :execute (true) execute promise before returning
  #
  # @return [Promise<Array>]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:440
  def zip(*others); end

  protected

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:551
  def complete(success, value, reason); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:545
  def notify_child(child); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:481
  def ns_initialize(value, opts); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:533
  def on_fulfill(result); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:539
  def on_reject(reason); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:562
  def realize(task); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:528
  def root?; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:520
  def set_pending; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:570
  def set_state!(success, value, reason); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:576
  def synchronized_set_state!(success, value, reason); end

  class << self
    # Aggregate a collection of zero or more promises under a composite promise,
    # execute the aggregated promises and collect them into a standard Ruby array,
    # call the given Ruby `Ennnumerable` predicate (such as `any?`, `all?`, `none?`,
    # or `one?`) on the collection checking for the success or failure of each,
    # then executing the composite's `#then` handlers if the predicate returns
    # `true` or executing the composite's `#rescue` handlers if the predicate
    # returns false.
    #
    # @!macro promise_self_aggregate
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:505
    def aggregate(method, *promises); end

    # Aggregates a collection of promises and executes the `then` condition
    # if all aggregated promises succeed. Executes the `rescue` handler with
    # a `Concurrent::PromiseExecutionError` if any of the aggregated promises
    # fail. Upon execution will execute any of the aggregate promises that
    # were not already executed.
    #
    # @!macro promise_self_aggregate
    #
    #   The returned promise will not yet have been executed. Additional `#then`
    #   and `#rescue` handlers may still be provided. Once the returned promise
    #   is execute the aggregate promises will be also be executed (if they have
    #   not been executed already). The results of the aggregate promises will
    #   be checked upon completion. The necessary `#then` and `#rescue` blocks
    #   on the aggregating promise will then be executed as appropriate. If the
    #   `#rescue` handlers are executed the raises exception will be
    #   `Concurrent::PromiseExecutionError`.
    #
    #   @param [Array] promises Zero or more promises to aggregate
    #   @return [Promise] an unscheduled (not executed) promise that aggregates
    #     the promises given as arguments
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:464
    def all?(*promises); end

    # Aggregates a collection of promises and executes the `then` condition
    # if any aggregated promises succeed. Executes the `rescue` handler with
    # a `Concurrent::PromiseExecutionError` if any of the aggregated promises
    # fail. Upon execution will execute any of the aggregate promises that
    # were not already executed.
    #
    # @!macro promise_self_aggregate
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:475
    def any?(*promises); end

    # Create a new `Promise` object with the given block, execute it, and return the
    # `:pending` object.
    #
    # @!macro executor_and_deref_options
    #
    # @!macro promise_init_options
    #
    # @return [Promise] the newly created `Promise` in the `:pending` state
    #
    # @raise [ArgumentError] if no block is given
    #
    # @example
    #   promise = Concurrent::Promise.execute{ sleep(1); 42 }
    #   promise.state #=> :pending
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:296
    def execute(opts = T.unsafe(nil), &block); end

    # Create a new `Promise` and fulfill it immediately.
    #
    # @!macro executor_and_deref_options
    #
    # @!macro promise_init_options
    #
    # @raise [ArgumentError] if no block is given
    #
    # @return [Promise] the newly created `Promise`
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:224
    def fulfill(value, opts = T.unsafe(nil)); end

    # Create a new `Promise` and reject it immediately.
    #
    # @!macro executor_and_deref_options
    #
    # @!macro promise_init_options
    #
    # @raise [ArgumentError] if no block is given
    #
    # @return [Promise] the newly created `Promise`
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:237
    def reject(reason, opts = T.unsafe(nil)); end

    # Builds a promise that produces the result of promises in an Array
    # and fails if any of them fails.
    #
    # @overload zip(*promises)
    #   @param [Array<Promise>] promises
    #
    # @overload zip(*promises, opts)
    #   @param [Array<Promise>] promises
    #   @param [Hash] opts the configuration options
    #   @option opts [Executor] :executor (ImmediateExecutor.new) when set use the given `Executor` instance.
    #   @option opts [Boolean] :execute (true) execute promise before returning
    #
    # @return [Promise<Array>]
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:409
    def zip(*promises); end
  end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promise.rb:11
class Concurrent::PromiseExecutionError < ::StandardError; end

# {include:file:docs-source/promises-main.md}
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:13
module Concurrent::Promises
  extend ::Concurrent::Promises::FactoryMethods::Configuration
  extend ::Concurrent::Promises::FactoryMethods
end

# @abstract
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2047
class Concurrent::Promises::AbstractAnyPromise < ::Concurrent::Promises::BlockedPromise; end

# Common ancestor of {Event} and {Future} classes, many shared methods are defined here.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:513
class Concurrent::Promises::AbstractEventFuture < ::Concurrent::Synchronization::Object
  include ::Concurrent::Promises::InternalStates
  extend ::Concurrent::Synchronization::SafeInitialization

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:522
  def initialize(promise, default_executor); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:515
  def __initialize_atomic_fields__; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:738
  def add_callback_clear_delayed_node(node); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:733
  def add_callback_notify_blocked(promise, index); end

  # For inspection.
  # @!visibility private
  # @return [Array<AbstractPromise>]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:702
  def blocks; end

  # For inspection.
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:710
  def callbacks; end

  # @!macro promises.shortcut.on
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:596
  def chain(*args, &task); end

  # Chains the task to be executed asynchronously on executor after it is resolved.
  #
  # @!macro promises.param.executor
  # @!macro promises.param.args
  # @return [Future]
  # @!macro promise.param.task-future
  #
  # @overload an_event.chain_on(executor, *args, &task)
  #   @yield [*args] to the task.
  # @overload a_future.chain_on(executor, *args, &task)
  #   @yield [fulfilled, value, reason, *args] to the task.
  #   @yieldparam [true, false] fulfilled
  #   @yieldparam [Object] value
  #   @yieldparam [Object] reason
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:614
  def chain_on(executor, *args, &task); end

  # Resolves the resolvable when receiver is resolved.
  #
  # @param [Resolvable] resolvable
  # @return [self]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:629
  def chain_resolvable(resolvable); end

  # Returns default executor.
  # @return [Executor] default executor
  # @see #with_default_executor
  # @see FactoryMethods#future_on
  # @see FactoryMethods#resolvable_future
  # @see FactoryMethods#any_fulfilled_future_on
  # @see similar
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:590
  def default_executor; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:623
  def inspect; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:515
  def internal_state; end

  # @!macro promises.shortcut.using
  # @return [self]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:637
  def on_resolution(*args, &callback); end

  # Stores the callback to be executed synchronously on resolving thread after it is
  # resolved.
  #
  # @!macro promises.param.args
  # @!macro promise.param.callback
  # @return [self]
  #
  # @overload an_event.on_resolution!(*args, &callback)
  #   @yield [*args] to the callback.
  # @overload a_future.on_resolution!(*args, &callback)
  #   @yield [fulfilled, value, reason, *args] to the callback.
  #   @yieldparam [true, false] fulfilled
  #   @yieldparam [Object] value
  #   @yieldparam [Object] reason
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:655
  def on_resolution!(*args, &callback); end

  # Stores the callback to be executed asynchronously on executor after it is resolved.
  #
  # @!macro promises.param.executor
  # @!macro promises.param.args
  # @!macro promise.param.callback
  # @return [self]
  #
  # @overload an_event.on_resolution_using(executor, *args, &callback)
  #   @yield [*args] to the callback.
  # @overload a_future.on_resolution_using(executor, *args, &callback)
  #   @yield [fulfilled, value, reason, *args] to the callback.
  #   @yieldparam [true, false] fulfilled
  #   @yieldparam [Object] value
  #   @yieldparam [Object] reason
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:673
  def on_resolution_using(executor, *args, &callback); end

  # Is it in pending state?
  # @return [Boolean]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:549
  def pending?; end

  # For inspection.
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:716
  def promise; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:688
  def resolve_with(state, raise_on_reassign = T.unsafe(nil), reserved = T.unsafe(nil)); end

  # Is it in resolved state?
  # @return [Boolean]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:555
  def resolved?; end

  # Returns its state.
  # @return [Symbol]
  #
  # @overload an_event.state
  #   @return [:pending, :resolved]
  # @overload a_future.state
  #   Both :fulfilled, :rejected implies :resolved.
  #   @return [:pending, :fulfilled, :rejected]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:543
  def state; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:633
  def tangle(resolvable); end

  # @return [String] Short string representation.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:619
  def to_s; end

  # Propagates touch. Requests all the delayed futures, which it depends on, to be
  # executed. This method is called by any other method requiring resolved state, like {#wait}.
  # @return [self]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:562
  def touch; end

  # For inspection.
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:722
  def touched?; end

  # @!macro promises.method.wait
  #   Wait (block the Thread) until receiver is {#resolved?}.
  #   @!macro promises.touches
  #
  #   @!macro promises.warn.blocks
  #   @!macro promises.param.timeout
  #   @return [self, true, false] self implies timeout was not used, true implies timeout was used
  #     and it was resolved, false implies it was not resolved within timeout.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:578
  def wait(timeout = T.unsafe(nil)); end

  # For inspection.
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:728
  def waiting_threads; end

  # @!macro promises.method.with_default_executor
  #   Crates new object with same class with the executor set as its new default executor.
  #   Any futures depending on it will use the new default executor.
  # @!macro promises.shortcut.event-future
  # @abstract
  # @return [AbstractEventFuture]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:683
  def with_default_executor(executor); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:743
  def with_hidden_resolvable; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:750
  def add_callback(method, *args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:812
  def async_callback_on_resolution(state, executor, args, callback); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:796
  def call_callback(method, state, args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:800
  def call_callbacks(state); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:763
  def callback_clear_delayed_node(state, node); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:818
  def callback_notify_blocked(state, promise, index); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:515
  def compare_and_set_internal_state(expected, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:515
  def internal_state=(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:515
  def swap_internal_state(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:515
  def update_internal_state(&block); end

  # @return [Boolean]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:768
  def wait_until_resolved(timeout); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:808
  def with_async(executor, *args, &block); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1796
class Concurrent::Promises::AbstractFlatPromise < ::Concurrent::Promises::BlockedPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1798
  def initialize(delayed_because, blockers_count, event_or_future); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1808
  def touch; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1828
  def add_delayed_of(future); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1820
  def on_resolvable(resolved_future, index); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1824
  def resolvable?(countdown, future, index); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1816
  def touched?; end
end

# @abstract
# @private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1549
class Concurrent::Promises::AbstractPromise < ::Concurrent::Synchronization::Object
  include ::Concurrent::Promises::InternalStates
  extend ::Concurrent::Synchronization::SafeInitialization

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1553
  def initialize(future); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1564
  def default_executor; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1581
  def delayed_because; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1562
  def event; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1558
  def future; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1579
  def inspect; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1568
  def state; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1575
  def to_s; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1572
  def touch; end

  private

  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1592
  def evaluate_to(*args, block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1587
  def resolve_with(new_state, raise_on_reassign = T.unsafe(nil)); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2084
class Concurrent::Promises::AnyFulfilledFuturePromise < ::Concurrent::Promises::AnyResolvedFuturePromise
  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2088
  def resolvable?(countdown, event_or_future, index); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2050
class Concurrent::Promises::AnyResolvedEventPromise < ::Concurrent::Promises::AbstractAnyPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2054
  def initialize(delayed, blockers_count, default_executor); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2062
  def on_resolvable(resolved_future, index); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2058
  def resolvable?(countdown, future, index); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2067
class Concurrent::Promises::AnyResolvedFuturePromise < ::Concurrent::Promises::AbstractAnyPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2071
  def initialize(delayed, blockers_count, default_executor); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2079
  def on_resolvable(resolved_future, index); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2075
  def resolvable?(countdown, future, index); end
end

# @abstract
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1619
class Concurrent::Promises::BlockedPromise < ::Concurrent::Promises::InnerPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1661
  def initialize(delayed, blockers_count, future); end

  # for inspection only
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1683
  def blocked_by; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1674
  def delayed_because; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1667
  def on_blocker_resolution(future, index); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1678
  def touch; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1691
  def clear_and_propagate_touch(stack_or_element = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1710
  def on_resolvable(resolved_future, index); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1706
  def process_on_blocker_resolution(future, index); end

  # @return [true,false] if resolvable
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1702
  def resolvable?(countdown, future, index); end

  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1652
    def add_delayed(delayed1, delayed2); end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1645
    def new_blocked_by(blockers, *args, &block); end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1623
    def new_blocked_by1(blocker, *args, &block); end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1630
    def new_blocked_by2(blocker1, blocker2, *args, &block); end

    private

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1621
    def new(*args, &block); end
  end
end

# @abstract
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1716
class Concurrent::Promises::BlockedTaskPromise < ::Concurrent::Promises::BlockedPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1717
  def initialize(delayed, blockers_count, default_executor, executor, args, &task); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1725
  def executor; end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1766
class Concurrent::Promises::ChainPromise < ::Concurrent::Promises::BlockedTaskPromise
  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1769
  def on_resolvable(resolved_future, index); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2095
class Concurrent::Promises::DelayPromise < ::Concurrent::Promises::InnerPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2097
  def initialize(default_executor); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2108
  def delayed_because; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2104
  def touch; end
end

# Represents an event which will happen in future (will be resolved). The event is either
# pending or resolved. It should be always resolved. Use {Future} to communicate rejections and
# cancellation.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:826
class Concurrent::Promises::Event < ::Concurrent::Promises::AbstractEventFuture
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:847
  def &(other); end

  # Creates a new event which will be resolved when the first of receiver, `event_or_future`
  # resolves.
  #
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:853
  def any(event_or_future); end

  # Creates new event dependent on receiver which will not evaluate until touched, see {#touch}.
  # In other words, it inserts delay into the chain of Futures making rest of it lazy evaluated.
  #
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:863
  def delay; end

  # @!macro promise.method.schedule
  #   Creates new event dependent on receiver scheduled to execute on/in intended_time.
  #   In time is interpreted from the moment the receiver is resolved, therefore it inserts
  #   delay into the chain.
  #
  #   @!macro promises.param.intended_time
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:875
  def schedule(intended_time); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:828
  def then(*args, &task); end

  # Returns self, since this is event
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:893
  def to_event; end

  # Converts event to a future. The future is fulfilled when the event is resolved, the future may never fail.
  #
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:885
  def to_future; end

  # @!macro promises.method.with_default_executor
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:899
  def with_default_executor(executor); end

  # @!macro promises.method.zip
  #   Creates a new event or a future which will be resolved when receiver and other are.
  #   Returns an event if receiver and other are events, otherwise returns a future.
  #   If just one of the parties is Future then the result
  #   of the returned future is equal to the result of the supplied future. If both are futures
  #   then the result is as described in {FactoryMethods#zip_futures_on}.
  #
  # @return [Future, Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:839
  def zip(other); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:857
  def |(event_or_future); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:910
  def callback_on_resolution(state, args, callback); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:905
  def rejected_resolution(raise_on_reassign, state); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1972
class Concurrent::Promises::EventWrapperPromise < ::Concurrent::Promises::BlockedPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1973
  def initialize(delayed, blockers_count, default_executor); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1979
  def on_resolvable(resolved_future, index); end
end

# Container of all {Future}, {Event} factory methods. They are never constructed directly with
# new.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:46
module Concurrent::Promises::FactoryMethods
  include ::Concurrent::Promises::FactoryMethods::Configuration
  extend ::Concurrent::ReInclude
  extend ::Concurrent::Promises::FactoryMethods::Configuration
  extend ::Concurrent::Promises::FactoryMethods

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:282
  def any(*futures_and_or_events); end

  # @!macro promises.shortcut.on
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:319
  def any_event(*futures_and_or_events); end

  # Creates a new event which becomes resolved after the first futures_and_or_events resolves.
  # @!macro promises.any-touch
  #
  # @!macro promises.param.default_executor
  # @param [AbstractEventFuture] futures_and_or_events
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:329
  def any_event_on(default_executor, *futures_and_or_events); end

  # @!macro promises.shortcut.on
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:300
  def any_fulfilled_future(*futures_and_or_events); end

  # Creates a new future which is resolved after the first futures_and_or_events is fulfilled.
  # Its result equals the result of the first resolved future or if all futures_and_or_events reject,
  # it has reason of the last rejected future.
  # @!macro promises.any-touch
  # @!macro promises.event-conversion
  #
  # @!macro promises.param.default_executor
  # @param [AbstractEventFuture] futures_and_or_events
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:313
  def any_fulfilled_future_on(default_executor, *futures_and_or_events); end

  # @!macro promises.shortcut.on
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:278
  def any_resolved_future(*futures_and_or_events); end

  # Creates a new future which is resolved after the first futures_and_or_events is resolved.
  # Its result equals the result of the first resolved future.
  # @!macro promises.any-touch
  #   If resolved it does not propagate {Concurrent::AbstractEventFuture#touch}, leaving delayed
  #   futures un-executed if they are not required any more.
  # @!macro promises.event-conversion
  #
  # @!macro promises.param.default_executor
  # @param [AbstractEventFuture] futures_and_or_events
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:294
  def any_resolved_future_on(default_executor, *futures_and_or_events); end

  # @!macro promises.shortcut.on
  # @return [Future, Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:190
  def delay(*args, &task); end

  # Creates a new event or future which is resolved only after it is touched,
  # see {Concurrent::AbstractEventFuture#touch}.
  #
  # @!macro promises.param.default_executor
  # @overload delay_on(default_executor, *args, &task)
  #   If task is provided it returns a {Future} representing the result of the task.
  #   @!macro promises.param.args
  #   @yield [*args] to the task.
  #   @!macro promise.param.task-future
  #   @return [Future]
  # @overload delay_on(default_executor)
  #   If no task is provided, it returns an {Event}
  #   @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:207
  def delay_on(default_executor, *args, &task); end

  # Creates a resolved future which will be fulfilled with the given value.
  #
  # @!macro promises.param.default_executor
  # @param [Object] value
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:127
  def fulfilled_future(value, default_executor = T.unsafe(nil)); end

  # @!macro promises.shortcut.on
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:94
  def future(*args, &task); end

  # Constructs a new Future which will be resolved after block is evaluated on default executor.
  # Evaluation begins immediately.
  #
  # @!macro promises.param.default_executor
  # @!macro promises.param.args
  # @yield [*args] to the task.
  # @!macro promise.param.task-future
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:106
  def future_on(default_executor, *args, &task); end

  # General constructor. Behaves differently based on the argument's type. It's provided for convenience
  # but it's better to be explicit.
  #
  # @see rejected_future, resolved_event, fulfilled_future
  # @!macro promises.param.default_executor
  # @return [Event, Future]
  #
  # @overload make_future(nil, default_executor = self.default_executor)
  #   @param [nil] nil
  #   @return [Event] resolved event.
  #
  # @overload make_future(a_future, default_executor = self.default_executor)
  #   @param [Future] a_future
  #   @return [Future] a future which will be resolved when a_future is.
  #
  # @overload make_future(an_event, default_executor = self.default_executor)
  #   @param [Event] an_event
  #   @return [Event] an event which will be resolved when an_event is.
  #
  # @overload make_future(exception, default_executor = self.default_executor)
  #   @param [Exception] exception
  #   @return [Future] a rejected future with the exception as its reason.
  #
  # @overload make_future(value, default_executor = self.default_executor)
  #   @param [Object] value when none of the above overloads fits
  #   @return [Future] a fulfilled future with the value.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:174
  def make_future(argument = T.unsafe(nil), default_executor = T.unsafe(nil)); end

  # Creates a resolved future which will be rejected with the given reason.
  #
  # @!macro promises.param.default_executor
  # @param [Object] reason
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:136
  def rejected_future(reason, default_executor = T.unsafe(nil)); end

  # @!macro promises.shortcut.on
  # @return [ResolvableEvent]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:63
  def resolvable_event; end

  # Creates a resolvable event, user is responsible for resolving the event once
  # by calling {Promises::ResolvableEvent#resolve}.
  #
  # @!macro promises.param.default_executor
  # @return [ResolvableEvent]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:72
  def resolvable_event_on(default_executor = T.unsafe(nil)); end

  # @!macro promises.shortcut.on
  # @return [ResolvableFuture]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:78
  def resolvable_future; end

  # Creates resolvable future, user is responsible for resolving the future once by
  # {Promises::ResolvableFuture#resolve}, {Promises::ResolvableFuture#fulfill},
  # or {Promises::ResolvableFuture#reject}
  #
  # @!macro promises.param.default_executor
  # @return [ResolvableFuture]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:88
  def resolvable_future_on(default_executor = T.unsafe(nil)); end

  # Creates resolved event.
  #
  # @!macro promises.param.default_executor
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:144
  def resolved_event(default_executor = T.unsafe(nil)); end

  # Creates a resolved future with will be either fulfilled with the given value or rejected with
  # the given reason.
  #
  # @param [true, false] fulfilled
  # @param [Object] value
  # @param [Object] reason
  # @!macro promises.param.default_executor
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:118
  def resolved_future(fulfilled, value, reason, default_executor = T.unsafe(nil)); end

  # @!macro promises.shortcut.on
  # @return [Future, Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:214
  def schedule(intended_time, *args, &task); end

  # Creates a new event or future which is resolved in intended_time.
  #
  # @!macro promises.param.default_executor
  # @!macro promises.param.intended_time
  #   @param [Numeric, Time] intended_time `Numeric` means to run in `intended_time` seconds.
  #     `Time` means to run on `intended_time`.
  # @overload schedule_on(default_executor, intended_time, *args, &task)
  #   If task is provided it returns a {Future} representing the result of the task.
  #   @!macro promises.param.args
  #   @yield [*args] to the task.
  #   @!macro promise.param.task-future
  #   @return [Future]
  # @overload schedule_on(default_executor, intended_time)
  #   If no task is provided, it returns an {Event}
  #   @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:233
  def schedule_on(default_executor, intended_time, *args, &task); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:258
  def zip(*futures_and_or_events); end

  # @!macro promises.shortcut.on
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:262
  def zip_events(*futures_and_or_events); end

  # Creates a new event which is resolved after all futures_and_or_events are resolved.
  # (Future is resolved when fulfilled or rejected.)
  #
  # @!macro promises.param.default_executor
  # @param [AbstractEventFuture] futures_and_or_events
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:272
  def zip_events_on(default_executor, *futures_and_or_events); end

  # @!macro promises.shortcut.on
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:240
  def zip_futures(*futures_and_or_events); end

  # Creates a new future which is resolved after all futures_and_or_events are resolved.
  # Its value is an array of zipped future values. Its reason is an array of reasons for rejection.
  # If there is an error it rejects.
  # @!macro promises.event-conversion
  #   If event is supplied, which does not have value and can be only resolved, it's
  #   represented as `:fulfilled` with value `nil`.
  #
  # @!macro promises.param.default_executor
  # @param [AbstractEventFuture] futures_and_or_events
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:254
  def zip_futures_on(default_executor, *futures_and_or_events); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:50
module Concurrent::Promises::FactoryMethods::Configuration
  # @return [Executor, :io, :fast] the executor which is used when none is supplied
  #   to a factory method. The method can be overridden in the receivers of
  #   `include FactoryMethod`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:54
  def default_executor; end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1840
class Concurrent::Promises::FlatEventPromise < ::Concurrent::Promises::AbstractFlatPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1844
  def initialize(delayed, blockers_count, default_executor); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1848
  def process_on_blocker_resolution(future, index); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1873
class Concurrent::Promises::FlatFuturePromise < ::Concurrent::Promises::AbstractFlatPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1877
  def initialize(delayed, blockers_count, levels, default_executor); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1884
  def process_on_blocker_resolution(future, index); end
end

# Represents a value which will become available in future. May reject with a reason instead,
# e.g. when the tasks raises an exception.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:917
class Concurrent::Promises::Future < ::Concurrent::Promises::AbstractEventFuture
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1078
  def &(other); end

  # Creates a new event which will be resolved when the first of receiver, `event_or_future`
  # resolves. Returning future will have value nil if event_or_future is event and resolves
  # first.
  #
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1085
  def any(event_or_future); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1215
  def apply(args, block); end

  # Creates new future dependent on receiver which will not evaluate until touched, see {#touch}.
  # In other words, it inserts delay into the chain of Futures making rest of it lazy evaluated.
  #
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1095
  def delay; end

  # Allows rejected Future to be risen with `raise` method.
  # If the reason is not an exception `Runtime.new(reason)` is returned.
  #
  # @example
  #   raise Promises.rejected_future(StandardError.new("boom"))
  #   raise Promises.rejected_future("or just boom")
  # @raise [Concurrent::Error] when raising not rejected future
  # @return [Exception]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1013
  def exception(*args); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1124
  def flat(level = T.unsafe(nil)); end

  # Creates new event which will be resolved when the returned event by receiver is.
  # Be careful if the receiver rejects it will just resolve since Event does not hold reason.
  #
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1130
  def flat_event; end

  # Creates new future which will have result of the future returned by receiver. If receiver
  # rejects it will have its rejection.
  #
  # @param [Integer] level how many levels of futures should flatten
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1120
  def flat_future(level = T.unsafe(nil)); end

  # Is it in fulfilled state?
  # @return [Boolean]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:921
  def fulfilled?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1243
  def inspect; end

  # @!macro promises.shortcut.using
  # @return [self]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1136
  def on_fulfillment(*args, &callback); end

  # Stores the callback to be executed synchronously on resolving thread after it is
  # fulfilled. Does nothing on rejection.
  #
  # @!macro promises.param.args
  # @!macro promise.param.callback
  # @return [self]
  # @yield [value, *args] to the callback.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1147
  def on_fulfillment!(*args, &callback); end

  # Stores the callback to be executed asynchronously on executor after it is
  # fulfilled. Does nothing on rejection.
  #
  # @!macro promises.param.executor
  # @!macro promises.param.args
  # @!macro promise.param.callback
  # @return [self]
  # @yield [value, *args] to the callback.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1159
  def on_fulfillment_using(executor, *args, &callback); end

  # @!macro promises.shortcut.using
  # @return [self]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1165
  def on_rejection(*args, &callback); end

  # Stores the callback to be executed synchronously on resolving thread after it is
  # rejected. Does nothing on fulfillment.
  #
  # @!macro promises.param.args
  # @!macro promise.param.callback
  # @return [self]
  # @yield [reason, *args] to the callback.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1176
  def on_rejection!(*args, &callback); end

  # Stores the callback to be executed asynchronously on executor after it is
  # rejected. Does nothing on fulfillment.
  #
  # @!macro promises.param.executor
  # @!macro promises.param.args
  # @!macro promise.param.callback
  # @return [self]
  # @yield [reason, *args] to the callback.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1188
  def on_rejection_using(executor, *args, &callback); end

  # Returns reason of future's rejection.
  # @!macro promises.touches
  #
  # @!macro promises.warn.blocks
  # @!macro promises.warn.nil
  # @!macro promises.param.timeout
  # @!macro promises.param.timeout_value
  # @return [Object, timeout_value] the reason, or timeout_value on timeout, or nil on fulfillment.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:966
  def reason(timeout = T.unsafe(nil), timeout_value = T.unsafe(nil)); end

  # Is it in rejected state?
  # @return [Boolean]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:928
  def rejected?; end

  # @!macro promises.shortcut.on
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1052
  def rescue(*args, &task); end

  # Chains the task to be executed asynchronously on executor after it rejects. Does not run
  # the task if it fulfills. It will resolve though, triggering any dependent futures.
  #
  # @!macro promises.param.executor
  # @!macro promises.param.args
  # @!macro promise.param.task-future
  # @return [Future]
  # @yield [reason, *args] to the task.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1064
  def rescue_on(executor, *args, &task); end

  # Returns triplet fulfilled?, value, reason.
  # @!macro promises.touches
  #
  # @!macro promises.warn.blocks
  # @!macro promises.param.timeout
  # @return [Array(Boolean, Object, Object), nil] triplet of fulfilled?, value, reason, or nil
  #   on timeout.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:981
  def result(timeout = T.unsafe(nil)); end

  # Allows to use futures as green threads. The receiver has to evaluate to a future which
  # represents what should be done next. It basically flattens indefinitely until non Future
  # values is returned which becomes result of the returned future. Any encountered exception
  # will become reason of the returned future.
  #
  # @return [Future]
  # @param [#call(value)] run_test
  #   an object which when called returns either Future to keep running with
  #   or nil, then the run completes with the value.
  #   The run_test can be used to extract the Future from deeper structure,
  #   or to distinguish Future which is a resulting value from a future
  #   which is suppose to continue running.
  # @example
  #   body = lambda do |v|
  #     v += 1
  #     v < 5 ? Promises.future(v, &body) : v
  #   end
  #   Promises.future(0, &body).run.value! # => 5
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1210
  def run(run_test = T.unsafe(nil)); end

  # @!macro promise.method.schedule
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1102
  def schedule(intended_time); end

  # @!macro promises.shortcut.on
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1034
  def then(*args, &task); end

  # Chains the task to be executed asynchronously on executor after it fulfills. Does not run
  # the task if it rejects. It will resolve though, triggering any dependent futures.
  #
  # @!macro promises.param.executor
  # @!macro promises.param.args
  # @!macro promise.param.task-future
  # @return [Future]
  # @yield [value, *args] to the task.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1046
  def then_on(executor, *args, &task); end

  # Converts future to event which is resolved when future is resolved by fulfillment or rejection.
  #
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1222
  def to_event; end

  # Returns self, since this is a future
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1230
  def to_future; end

  # @return [String] Short string representation.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1235
  def to_s; end

  # @!macro promises.method.value
  #   Return value of the future.
  #   @!macro promises.touches
  #
  #   @!macro promises.warn.blocks
  #   @!macro promises.warn.nil
  #   @!macro promises.param.timeout
  #   @!macro promises.param.timeout_value
  #     @param [Object] timeout_value a value returned by the method when it times out
  # @return [Object, nil, timeout_value] the value of the Future when fulfilled,
  #   timeout_value on timeout,
  #   nil on rejection.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:950
  def value(timeout = T.unsafe(nil), timeout_value = T.unsafe(nil)); end

  # @!macro promises.method.value
  # @return [Object, nil, timeout_value] the value of the Future when fulfilled,
  #   or nil on rejection,
  #   or timeout_value on timeout.
  # @raise [Exception] {#reason} on rejection
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:997
  def value!(timeout = T.unsafe(nil), timeout_value = T.unsafe(nil)); end

  # @!macro promises.method.wait
  # @raise [Exception] {#reason} on rejection
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:987
  def wait!(timeout = T.unsafe(nil)); end

  # @!macro promises.method.with_default_executor
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1111
  def with_default_executor(executor); end

  # @!macro promises.method.zip
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1070
  def zip(other); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1089
  def |(event_or_future); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1272
  def async_callback_on_fulfillment(state, executor, args, callback); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1278
  def async_callback_on_rejection(state, executor, args, callback); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1284
  def callback_on_fulfillment(state, args, callback); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1288
  def callback_on_rejection(state, args, callback); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1292
  def callback_on_resolution(state, args, callback); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1251
  def rejected_resolution(raise_on_reassign, state); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1247
  def run_test(v); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1266
  def wait_until_resolved!(timeout = T.unsafe(nil)); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1984
class Concurrent::Promises::FutureWrapperPromise < ::Concurrent::Promises::BlockedPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1985
  def initialize(delayed, blockers_count, default_executor); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1991
  def on_resolvable(resolved_future, index); end
end

# will be immediately resolved
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1783
class Concurrent::Promises::ImmediateEventPromise < ::Concurrent::Promises::InnerPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1784
  def initialize(default_executor); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1789
class Concurrent::Promises::ImmediateFuturePromise < ::Concurrent::Promises::InnerPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1790
  def initialize(default_executor, fulfilled, value, reason); end
end

# @abstract
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1615
class Concurrent::Promises::InnerPromise < ::Concurrent::Promises::AbstractPromise; end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:338
module Concurrent::Promises::InternalStates; end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:397
class Concurrent::Promises::InternalStates::Fulfilled < ::Concurrent::Promises::InternalStates::ResolvedWithResult
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:399
  def initialize(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:407
  def apply(args, block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:403
  def fulfilled?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:415
  def reason; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:419
  def to_sym; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:411
  def value; end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:425
class Concurrent::Promises::InternalStates::FulfilledArray < ::Concurrent::Promises::InternalStates::Fulfilled
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:426
  def apply(args, block); end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:488
Concurrent::Promises::InternalStates::PENDING = T.let(T.unsafe(nil), Concurrent::Promises::InternalStates::Pending)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:459
class Concurrent::Promises::InternalStates::PartiallyRejected < ::Concurrent::Promises::InternalStates::ResolvedWithResult
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:460
  def initialize(value, reason); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:482
  def apply(args, block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:466
  def fulfilled?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:478
  def reason; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:470
  def to_sym; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:474
  def value; end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:351
class Concurrent::Promises::InternalStates::Pending < ::Concurrent::Promises::InternalStates::State
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:352
  def resolved?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:356
  def to_sym; end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:490
Concurrent::Promises::InternalStates::RESERVED = T.let(T.unsafe(nil), Concurrent::Promises::InternalStates::Reserved)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:492
Concurrent::Promises::InternalStates::RESOLVED = T.let(T.unsafe(nil), Concurrent::Promises::InternalStates::Fulfilled)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:432
class Concurrent::Promises::InternalStates::Rejected < ::Concurrent::Promises::InternalStates::ResolvedWithResult
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:433
  def initialize(reason); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:453
  def apply(args, block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:437
  def fulfilled?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:445
  def reason; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:449
  def to_sym; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:441
  def value; end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:362
class Concurrent::Promises::InternalStates::Reserved < ::Concurrent::Promises::InternalStates::Pending; end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:366
class Concurrent::Promises::InternalStates::ResolvedWithResult < ::Concurrent::Promises::InternalStates::State
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:391
  def apply; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:379
  def fulfilled?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:387
  def reason; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:367
  def resolved?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:375
  def result; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:371
  def to_sym; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:383
  def value; end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:340
class Concurrent::Promises::InternalStates::State
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:341
  def resolved?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:345
  def to_sym; end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1748
class Concurrent::Promises::RescuePromise < ::Concurrent::Promises::BlockedTaskPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1751
  def initialize(delayed, blockers_count, default_executor, executor, args, &task); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1755
  def on_resolvable(resolved_future, index); end
end

# Marker module of Future, Event resolved manually.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1299
module Concurrent::Promises::Resolvable
  include ::Concurrent::Promises::InternalStates
end

# A Event which can be resolved by user.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1304
class Concurrent::Promises::ResolvableEvent < ::Concurrent::Promises::Event
  include ::Concurrent::Promises::Resolvable

  # Makes the event resolved, which triggers all dependent futures.
  #
  # @!macro promise.param.raise_on_reassign
  # @!macro promise.param.reserved
  #   @param [true, false] reserved
  #     Set to true if the resolvable is {#reserve}d by you,
  #     marks resolution of reserved resolvable events and futures explicitly.
  #     Advanced feature, ignore unless you use {Resolvable#reserve} from edge.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1324
  def resolve(raise_on_reassign = T.unsafe(nil), reserved = T.unsafe(nil)); end

  # Behaves as {AbstractEventFuture#wait} but has one additional optional argument
  # resolve_on_timeout.
  #
  # @param [true, false] resolve_on_timeout
  #   If it times out and the argument is true it will also resolve the event.
  # @return [self, true, false]
  # @see AbstractEventFuture#wait
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1342
  def wait(timeout = T.unsafe(nil), resolve_on_timeout = T.unsafe(nil)); end

  # Creates new event wrapping receiver, effectively hiding the resolve method.
  #
  # @return [Event]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1331
  def with_hidden_resolvable; end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1600
class Concurrent::Promises::ResolvableEventPromise < ::Concurrent::Promises::AbstractPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1601
  def initialize(default_executor); end
end

# A Future which can be resolved by user.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1354
class Concurrent::Promises::ResolvableFuture < ::Concurrent::Promises::Future
  include ::Concurrent::Promises::Resolvable

  # Evaluates the block and sets its result as future's value fulfilling, if the block raises
  # an exception the future rejects with it.
  #
  # @yield [*args] to the block.
  # @yieldreturn [Object] value
  # @return [self]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1395
  def evaluate_to(*args, &block); end

  # Evaluates the block and sets its result as future's value fulfilling, if the block raises
  # an exception the future rejects with it.
  #
  # @yield [*args] to the block.
  # @yieldreturn [Object] value
  # @return [self]
  # @raise [Exception] also raise reason on rejection.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1406
  def evaluate_to!(*args, &block); end

  # Makes the future fulfilled with `value`,
  # which triggers all dependent futures.
  #
  # @param [Object] value
  # @!macro promise.param.raise_on_reassign
  # @!macro promise.param.reserved
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1375
  def fulfill(value, raise_on_reassign = T.unsafe(nil), reserved = T.unsafe(nil)); end

  # Behaves as {Future#reason} but has one additional optional argument
  # resolve_on_timeout.
  #
  # @!macro promises.resolvable.resolve_on_timeout
  # @return [Exception, timeout_value, nil]
  # @see Future#reason
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1503
  def reason(timeout = T.unsafe(nil), timeout_value = T.unsafe(nil), resolve_on_timeout = T.unsafe(nil)); end

  # Makes the future rejected with `reason`,
  # which triggers all dependent futures.
  #
  # @param [Object] reason
  # @!macro promise.param.raise_on_reassign
  # @!macro promise.param.reserved
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1385
  def reject(reason, raise_on_reassign = T.unsafe(nil), reserved = T.unsafe(nil)); end

  # Makes the future resolved with result of triplet `fulfilled?`, `value`, `reason`,
  # which triggers all dependent futures.
  #
  # @param [true, false] fulfilled
  # @param [Object] value
  # @param [Object] reason
  # @!macro promise.param.raise_on_reassign
  # @!macro promise.param.reserved
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1365
  def resolve(fulfilled = T.unsafe(nil), value = T.unsafe(nil), reason = T.unsafe(nil), raise_on_reassign = T.unsafe(nil), reserved = T.unsafe(nil)); end

  # Behaves as {Future#result} but has one additional optional argument
  # resolve_on_timeout.
  #
  # @!macro promises.resolvable.resolve_on_timeout
  # @return [::Array(Boolean, Object, Exception), nil]
  # @see Future#result
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1524
  def result(timeout = T.unsafe(nil), resolve_on_timeout = T.unsafe(nil)); end

  # Behaves as {Future#value} but has one additional optional argument
  # resolve_on_timeout.
  #
  # @!macro promises.resolvable.resolve_on_timeout
  # @return [Object, timeout_value, nil]
  # @see Future#value
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1459
  def value(timeout = T.unsafe(nil), timeout_value = T.unsafe(nil), resolve_on_timeout = T.unsafe(nil)); end

  # Behaves as {Future#value!} but has one additional optional argument
  # resolve_on_timeout.
  #
  # @!macro promises.resolvable.resolve_on_timeout
  # @return [Object, timeout_value, nil]
  # @raise [Exception] {#reason} on rejection
  # @see Future#value!
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1481
  def value!(timeout = T.unsafe(nil), timeout_value = T.unsafe(nil), resolve_on_timeout = T.unsafe(nil)); end

  # Behaves as {AbstractEventFuture#wait} but has one additional optional argument
  # resolve_on_timeout.
  #
  # @!macro promises.resolvable.resolve_on_timeout
  # @return [self, true, false]
  # @see AbstractEventFuture#wait
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1421
  def wait(timeout = T.unsafe(nil), resolve_on_timeout = T.unsafe(nil)); end

  # Behaves as {Future#wait!} but has one additional optional argument
  # resolve_on_timeout.
  #
  # @!macro promises.resolvable.resolve_on_timeout
  # @return [self, true, false]
  # @raise [Exception] {#reason} on rejection
  # @see Future#wait!
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1438
  def wait!(timeout = T.unsafe(nil), resolve_on_timeout = T.unsafe(nil)); end

  # Creates new future wrapping receiver, effectively hiding the resolve method and similar.
  #
  # @return [Future]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1542
  def with_hidden_resolvable; end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1606
class Concurrent::Promises::ResolvableFuturePromise < ::Concurrent::Promises::AbstractPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1607
  def initialize(default_executor); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1611
  def evaluate_to(*args, block); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1909
class Concurrent::Promises::RunFuturePromise < ::Concurrent::Promises::AbstractFlatPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1913
  def initialize(delayed, blockers_count, default_executor, run_test); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1918
  def process_on_blocker_resolution(future, index); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2114
class Concurrent::Promises::ScheduledPromise < ::Concurrent::Promises::InnerPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2125
  def initialize(default_executor, intended_time); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2119
  def inspect; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2115
  def intended_time; end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1730
class Concurrent::Promises::ThenPromise < ::Concurrent::Promises::BlockedTaskPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1733
  def initialize(delayed, blockers_count, default_executor, executor, args, &task); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1737
  def on_resolvable(resolved_future, index); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1940
class Concurrent::Promises::ZipEventEventPromise < ::Concurrent::Promises::BlockedPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1941
  def initialize(delayed, blockers_count, default_executor); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1947
  def on_resolvable(resolved_future, index); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2031
class Concurrent::Promises::ZipEventsPromise < ::Concurrent::Promises::BlockedPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2035
  def initialize(delayed, blockers_count, default_executor); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2041
  def on_resolvable(resolved_future, index); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1952
class Concurrent::Promises::ZipFutureEventPromise < ::Concurrent::Promises::BlockedPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1953
  def initialize(delayed, blockers_count, default_executor); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1967
  def on_resolvable(resolved_future, index); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1960
  def process_on_blocker_resolution(future, index); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:1996
class Concurrent::Promises::ZipFuturesPromise < ::Concurrent::Promises::BlockedPromise
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2000
  def initialize(delayed, blockers_count, default_executor); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2013
  def on_resolvable(resolved_future, index); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/promises.rb:2007
  def process_on_blocker_resolution(future, index); end
end

# Methods form module A included to a module B, which is already included into class C,
# will not be visible in the C class. If this module is extended to B then A's methods
# are correctly made visible to C.
#
# @example
#   module A
#     def a
#       :a
#     end
#   end
#
#   module B1
#   end
#
#   class C1
#     include B1
#   end
#
#   module B2
#     extend Concurrent::ReInclude
#   end
#
#   class C2
#     include B2
#   end
#
#   B1.send :include, A
#   B2.send :include, A
#
#   C1.new.respond_to? :a # => false
#   C2.new.respond_to? :a # => true
#
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/re_include.rb:36
module Concurrent::ReInclude
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/re_include.rb:44
  def extended(base); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/re_include.rb:50
  def include(*modules); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/re_include.rb:38
  def included(base); end
end

# Ruby read-write lock implementation
#
# Allows any number of concurrent readers, but only one concurrent writer
# (And if the "write" lock is taken, any readers who come along will have to wait)
#
# If readers are already active when a writer comes along, the writer will wait for
# all the readers to finish before going ahead.
# Any additional readers that come when the writer is already waiting, will also
# wait (so writers are not starved).
#
# This implementation is based on `java.util.concurrent.ReentrantReadWriteLock`.
#
# @example
#   lock = Concurrent::ReadWriteLock.new
#   lock.with_read_lock  { data.retrieve }
#   lock.with_write_lock { data.modify! }
#
# @note Do **not** try to acquire the write lock while already holding a read lock
#   **or** try to acquire the write lock while you already have it.
#   This will lead to deadlock
#
# @see http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/locks/ReentrantReadWriteLock.html java.util.concurrent.ReentrantReadWriteLock
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:31
class Concurrent::ReadWriteLock < ::Concurrent::Synchronization::Object
  extend ::Concurrent::Synchronization::SafeInitialization

  # Create a new `ReadWriteLock` in the unlocked state.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:59
  def initialize; end

  # Acquire a read lock. If a write lock has been acquired will block until
  # it is released. Will not block if other read locks have been acquired.
  #
  # @return [Boolean] true if the lock is successfully acquired
  #
  # @raise [Concurrent::ResourceLimitError] if the maximum number of readers
  #   is exceeded.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:111
  def acquire_read_lock; end

  # Acquire a write lock. Will block and wait for all active readers and writers.
  #
  # @return [Boolean] true if the lock is successfully acquired
  #
  # @raise [Concurrent::ResourceLimitError] if the maximum number of writers
  #   is exceeded.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:160
  def acquire_write_lock; end

  # Queries whether any threads are waiting to acquire the read or write lock.
  #
  # @return [Boolean] true if any threads are waiting for a lock else false
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:214
  def has_waiters?; end

  # Release a previously acquired read lock.
  #
  # @return [Boolean] true if the lock is successfully released
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:140
  def release_read_lock; end

  # Release a previously acquired write lock.
  #
  # @return [Boolean] true if the lock is successfully released
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:196
  def release_write_lock; end

  # Execute a block operation within a read lock.
  #
  # @yield the task to be performed within the lock.
  #
  # @return [Object] the result of the block operation.
  #
  # @raise [ArgumentError] when no block is given.
  # @raise [Concurrent::ResourceLimitError] if the maximum number of readers
  #   is exceeded.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:75
  def with_read_lock; end

  # Execute a block operation within a write lock.
  #
  # @yield the task to be performed within the lock.
  #
  # @return [Object] the result of the block operation.
  #
  # @raise [ArgumentError] when no block is given.
  # @raise [Concurrent::ResourceLimitError] if the maximum number of readers
  #   is exceeded.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:94
  def with_write_lock; end

  # Queries if the write lock is held by any thread.
  #
  # @return [Boolean] true if the write lock is held else false`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:207
  def write_locked?; end

  private

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:246
  def max_readers?(c = T.unsafe(nil)); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:251
  def max_writers?(c = T.unsafe(nil)); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:221
  def running_readers(c = T.unsafe(nil)); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:226
  def running_readers?(c = T.unsafe(nil)); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:231
  def running_writer?(c = T.unsafe(nil)); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:241
  def waiting_writer?(c = T.unsafe(nil)); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:236
  def waiting_writers(c = T.unsafe(nil)); end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:40
Concurrent::ReadWriteLock::MAX_READERS = T.let(T.unsafe(nil), Integer)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:43
Concurrent::ReadWriteLock::MAX_WRITERS = T.let(T.unsafe(nil), Integer)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:37
Concurrent::ReadWriteLock::RUNNING_WRITER = T.let(T.unsafe(nil), Integer)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/read_write_lock.rb:34
Concurrent::ReadWriteLock::WAITING_WRITER = T.let(T.unsafe(nil), Integer)

# Re-entrant read-write lock implementation
#
# Allows any number of concurrent readers, but only one concurrent writer
# (And while the "write" lock is taken, no read locks can be obtained either.
# Hence, the write lock can also be called an "exclusive" lock.)
#
# If another thread has taken a read lock, any thread which wants a write lock
# will block until all the readers release their locks. However, once a thread
# starts waiting to obtain a write lock, any additional readers that come along
# will also wait (so writers are not starved).
#
# A thread can acquire both a read and write lock at the same time. A thread can
# also acquire a read lock OR a write lock more than once. Only when the read (or
# write) lock is released as many times as it was acquired, will the thread
# actually let it go, allowing other threads which might have been waiting
# to proceed. Therefore the lock can be upgraded by first acquiring
# read lock and then write lock and that the lock can be downgraded by first
# having both read and write lock a releasing just the write lock.
#
# If both read and write locks are acquired by the same thread, it is not strictly
# necessary to release them in the same order they were acquired. In other words,
# the following code is legal:
#
# @example
#   lock = Concurrent::ReentrantReadWriteLock.new
#   lock.acquire_write_lock
#   lock.acquire_read_lock
#   lock.release_write_lock
#   # At this point, the current thread is holding only a read lock, not a write
#   # lock. So other threads can take read locks, but not a write lock.
#   lock.release_read_lock
#   # Now the current thread is not holding either a read or write lock, so
#   # another thread could potentially acquire a write lock.
#
# This implementation was inspired by `java.util.concurrent.ReentrantReadWriteLock`.
#
# @example
#   lock = Concurrent::ReentrantReadWriteLock.new
#   lock.with_read_lock  { data.retrieve }
#   lock.with_write_lock { data.modify! }
#
# @see http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/locks/ReentrantReadWriteLock.html java.util.concurrent.ReentrantReadWriteLock
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:53
class Concurrent::ReentrantReadWriteLock < ::Concurrent::Synchronization::Object
  extend ::Concurrent::Synchronization::SafeInitialization

  # Create a new `ReentrantReadWriteLock` in the unlocked state.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:109
  def initialize; end

  # Acquire a read lock. If a write lock is held by another thread, will block
  # until it is released.
  #
  # @return [Boolean] true if the lock is successfully acquired
  #
  # @raise [Concurrent::ResourceLimitError] if the maximum number of readers
  #   is exceeded.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:162
  def acquire_read_lock; end

  # Acquire a write lock. Will block and wait for all active readers and writers.
  #
  # @return [Boolean] true if the lock is successfully acquired
  #
  # @raise [Concurrent::ResourceLimitError] if the maximum number of writers
  #   is exceeded.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:257
  def acquire_write_lock; end

  # Release a previously acquired read lock.
  #
  # @return [Boolean] true if the lock is successfully released
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:236
  def release_read_lock; end

  # Release a previously acquired write lock.
  #
  # @return [Boolean] true if the lock is successfully released
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:329
  def release_write_lock; end

  # Try to acquire a read lock and return true if we succeed. If it cannot be
  # acquired immediately, return false.
  #
  # @return [Boolean] true if the lock is successfully acquired
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:215
  def try_read_lock; end

  # Try to acquire a write lock and return true if we succeed. If it cannot be
  # acquired immediately, return false.
  #
  # @return [Boolean] true if the lock is successfully acquired
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:310
  def try_write_lock; end

  # Execute a block operation within a read lock.
  #
  # @yield the task to be performed within the lock.
  #
  # @return [Object] the result of the block operation.
  #
  # @raise [ArgumentError] when no block is given.
  # @raise [Concurrent::ResourceLimitError] if the maximum number of readers
  #   is exceeded.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:126
  def with_read_lock; end

  # Execute a block operation within a write lock.
  #
  # @yield the task to be performed within the lock.
  #
  # @return [Object] the result of the block operation.
  #
  # @raise [ArgumentError] when no block is given.
  # @raise [Concurrent::ResourceLimitError] if the maximum number of readers
  #   is exceeded.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:145
  def with_write_lock; end

  private

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:370
  def max_readers?(c = T.unsafe(nil)); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:375
  def max_writers?(c = T.unsafe(nil)); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:345
  def running_readers(c = T.unsafe(nil)); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:350
  def running_readers?(c = T.unsafe(nil)); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:355
  def running_writer?(c = T.unsafe(nil)); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:365
  def waiting_or_running_writer?(c = T.unsafe(nil)); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:360
  def waiting_writers(c = T.unsafe(nil)); end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:94
Concurrent::ReentrantReadWriteLock::MAX_READERS = T.let(T.unsafe(nil), Integer)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:96
Concurrent::ReentrantReadWriteLock::MAX_WRITERS = T.let(T.unsafe(nil), Integer)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:84
Concurrent::ReentrantReadWriteLock::READER_BITS = T.let(T.unsafe(nil), Integer)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:102
Concurrent::ReentrantReadWriteLock::READ_LOCK_MASK = T.let(T.unsafe(nil), Integer)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:92
Concurrent::ReentrantReadWriteLock::RUNNING_WRITER = T.let(T.unsafe(nil), Integer)

# Used with @Counter:
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:90
Concurrent::ReentrantReadWriteLock::WAITING_WRITER = T.let(T.unsafe(nil), Integer)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:86
Concurrent::ReentrantReadWriteLock::WRITER_BITS = T.let(T.unsafe(nil), Integer)

# Used with @HeldCount:
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:100
Concurrent::ReentrantReadWriteLock::WRITE_LOCK_HELD = T.let(T.unsafe(nil), Integer)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/reentrant_read_write_lock.rb:104
Concurrent::ReentrantReadWriteLock::WRITE_LOCK_MASK = T.let(T.unsafe(nil), Integer)

# Raised by an `Executor` when it is unable to process a given task,
# possibly because of a reject policy or other internal error.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:48
class Concurrent::RejectedExecutionError < ::Concurrent::Error; end

# Raised when any finite resource, such as a lock counter, exceeds its
# maximum limit/threshold.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:52
class Concurrent::ResourceLimitError < ::Concurrent::Error; end

# @!macro internal_implementation_note
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:129
class Concurrent::RubyExchanger < ::Concurrent::AbstractExchanger
  extend ::Concurrent::Synchronization::SafeInitialization

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:159
  def initialize; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:165
  def __initialize_atomic_fields__; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:165
  def compare_and_set_slot(expected, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:165
  def slot; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:165
  def slot=(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:165
  def swap_slot(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:165
  def update_slot(&block); end

  private

  # @!macro exchanger_method_do_exchange
  #
  # @return [Object, CANCEL] the value exchanged by the other thread; {CANCEL} on timeout
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:170
  def do_exchange(value, timeout); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:138
class Concurrent::RubyExchanger::Node < ::Concurrent::Synchronization::Object
  extend ::Concurrent::Synchronization::SafeInitialization

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:142
  def initialize(item); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:139
  def __initialize_atomic_fields__; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:139
  def compare_and_set_value(expected, value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:153
  def item; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:149
  def latch; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:139
  def swap_value(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:139
  def update_value(&block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:139
  def value; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/exchanger.rb:139
  def value=(value); end
end

# @!macro abstract_executor_service_public_api
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb:8
class Concurrent::RubyExecutorService < ::Concurrent::AbstractExecutorService
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb:11
  def initialize(*args, &block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb:42
  def kill; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb:17
  def post(*args, &task); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb:33
  def shutdown; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb:52
  def wait_for_termination(timeout = T.unsafe(nil)); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb:70
  def ns_running?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb:78
  def ns_shutdown?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb:66
  def ns_shutdown_execution; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb:74
  def ns_shuttingdown?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb:58
  def stop_event; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb:62
  def stopped_event; end
end

# @!macro single_thread_executor
# @!macro abstract_executor_service_public_api
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_single_thread_executor.rb:9
class Concurrent::RubySingleThreadExecutor < ::Concurrent::RubyThreadPoolExecutor
  include ::Concurrent::SerialExecutorService

  # @!macro single_thread_executor_method_initialize
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_single_thread_executor.rb:13
  def initialize(opts = T.unsafe(nil)); end
end

# @!macro thread_pool_executor
# @!macro thread_pool_options
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:13
class Concurrent::RubyThreadPoolExecutor < ::Concurrent::RubyExecutorService
  # @!macro thread_pool_executor_method_initialize
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:47
  def initialize(opts = T.unsafe(nil)); end

  # @!macro thread_pool_executor_method_active_count
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:67
  def active_count; end

  # @!macro executor_service_method_can_overflow_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:74
  def can_overflow?; end

  # @!macro thread_pool_executor_attr_reader_completed_task_count
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:62
  def completed_task_count; end

  # @!macro thread_pool_executor_attr_reader_idletime
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:38
  def idletime; end

  # @!macro thread_pool_executor_attr_reader_largest_length
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:52
  def largest_length; end

  # @!macro thread_pool_executor_attr_reader_length
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:79
  def length; end

  # @!macro thread_pool_executor_attr_reader_max_length
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:32
  def max_length; end

  # @!macro thread_pool_executor_attr_reader_max_queue
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:41
  def max_queue; end

  # @!macro thread_pool_executor_attr_reader_min_length
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:35
  def min_length; end

  # @!macro thread_pool_executor_method_prune_pool
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:139
  def prune_pool; end

  # removes the worker if it can be pruned
  #
  # @return [true, false] if the worker was pruned
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:104
  def prune_worker(worker); end

  # @!macro thread_pool_executor_attr_reader_queue_length
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:84
  def queue_length; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:124
  def ready_worker(worker, last_message); end

  # @!macro thread_pool_executor_attr_reader_remaining_capacity
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:89
  def remaining_capacity; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:116
  def remove_worker(worker); end

  # @!macro thread_pool_executor_attr_reader_scheduled_task_count
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:57
  def scheduled_task_count; end

  # @!macro thread_pool_executor_attr_reader_synchronous
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:44
  def synchronous; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:129
  def worker_died(worker); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:134
  def worker_task_completed; end

  private

  # creates new worker which has to receive work to do after it's added
  # @return [nil, Worker] nil of max capacity is reached
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:257
  def ns_add_busy_worker; end

  # tries to assign task to a worker, tries to get one from @ready or to create new one
  # @return [true, false] if task is assigned to a worker
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:217
  def ns_assign_worker(*args, &task); end

  # tries to enqueue task
  # @return [true, false] if enqueued
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:235
  def ns_enqueue(*args, &task); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:178
  def ns_execute(*args, &task); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:146
  def ns_initialize(opts); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:205
  def ns_kill_execution; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:173
  def ns_limited_queue?; end

  # @return [Integer] number of excess idle workers which can be removed without
  #                   going below min_length, or all workers if not running
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:305
  def ns_prunable_capacity; end

  # handle ready worker, giving it new job or assigning back to @ready
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:269
  def ns_ready_worker(worker, last_message, success = T.unsafe(nil)); end

  # removes a worker which is not tracked in @ready
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:287
  def ns_remove_busy_worker(worker); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:294
  def ns_remove_ready_worker(worker); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:314
  def ns_reset_if_forked; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:190
  def ns_shutdown_execution; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:247
  def ns_worker_died(worker); end
end

# @!macro thread_pool_executor_constant_default_max_pool_size
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:17
Concurrent::RubyThreadPoolExecutor::DEFAULT_MAX_POOL_SIZE = T.let(T.unsafe(nil), Integer)

# @!macro thread_pool_executor_constant_default_max_queue_size
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:23
Concurrent::RubyThreadPoolExecutor::DEFAULT_MAX_QUEUE_SIZE = T.let(T.unsafe(nil), Integer)

# @!macro thread_pool_executor_constant_default_min_pool_size
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:20
Concurrent::RubyThreadPoolExecutor::DEFAULT_MIN_POOL_SIZE = T.let(T.unsafe(nil), Integer)

# @!macro thread_pool_executor_constant_default_synchronous
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:29
Concurrent::RubyThreadPoolExecutor::DEFAULT_SYNCHRONOUS = T.let(T.unsafe(nil), FalseClass)

# @!macro thread_pool_executor_constant_default_thread_timeout
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:26
Concurrent::RubyThreadPoolExecutor::DEFAULT_THREAD_IDLETIMEOUT = T.let(T.unsafe(nil), Integer)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:328
class Concurrent::RubyThreadPoolExecutor::Worker
  include ::Concurrent::Concern::Logging

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:331
  def initialize(pool, id); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:342
  def <<(message); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:350
  def kill; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:346
  def stop; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:356
  def create_worker(queue, pool, idletime); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb:381
  def run_task(pool, task, args); end
end

# A simple utility class that executes a callable and returns and array of three elements:
# success - indicating if the callable has been executed without errors
# value - filled by the callable result if it has been executed without errors, nil otherwise
# reason - the error risen by the callable if it has been executed with errors, nil otherwise
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/safe_task_executor.rb:9
class Concurrent::SafeTaskExecutor < ::Concurrent::Synchronization::LockableObject
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/safe_task_executor.rb:11
  def initialize(task, opts = T.unsafe(nil)); end

  # @return [Array]
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/safe_task_executor.rb:18
  def execute(*args); end
end

# `ScheduledTask` is a close relative of `Concurrent::Future` but with one
# important difference: A `Future` is set to execute as soon as possible
# whereas a `ScheduledTask` is set to execute after a specified delay. This
# implementation is loosely based on Java's
# [ScheduledExecutorService](http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ScheduledExecutorService.html).
# It is a more feature-rich variant of {Concurrent.timer}.
#
# The *intended* schedule time of task execution is set on object construction
# with the `delay` argument. The delay is a numeric (floating point or integer)
# representing a number of seconds in the future. Any other value or a numeric
# equal to or less than zero will result in an exception. The *actual* schedule
# time of task execution is set when the `execute` method is called.
#
# The constructor can also be given zero or more processing options. Currently
# the only supported options are those recognized by the
# [Dereferenceable](Dereferenceable) module.
#
# The final constructor argument is a block representing the task to be performed.
# If no block is given an `ArgumentError` will be raised.
#
# **States**
#
# `ScheduledTask` mixes in the  [Obligation](Obligation) module thus giving it
# "future" behavior. This includes the expected lifecycle states. `ScheduledTask`
# has one additional state, however. While the task (block) is being executed the
# state of the object will be `:processing`. This additional state is necessary
# because it has implications for task cancellation.
#
# **Cancellation**
#
# A `:pending` task can be cancelled using the `#cancel` method. A task in any
# other state, including `:processing`, cannot be cancelled. The `#cancel`
# method returns a boolean indicating the success of the cancellation attempt.
# A cancelled `ScheduledTask` cannot be restarted. It is immutable.
#
# **Obligation and Observation**
#
# The result of a `ScheduledTask` can be obtained either synchronously or
# asynchronously. `ScheduledTask` mixes in both the [Obligation](Obligation)
# module and the
# [Observable](http://ruby-doc.org/stdlib-2.0/libdoc/observer/rdoc/Observable.html)
# module from the Ruby standard library. With one exception `ScheduledTask`
# behaves identically to [Future](Observable) with regard to these modules.
#
# @!macro copy_options
#
# @example Basic usage
#
#   require 'concurrent/scheduled_task'
#   require 'csv'
#   require 'open-uri'
#
#   class Ticker
#     def get_year_end_closing(symbol, year, api_key)
#      uri = "https://www.alphavantage.co/query?function=TIME_SERIES_MONTHLY&symbol=#{symbol}&apikey=#{api_key}&datatype=csv"
#      data = []
#      csv = URI.parse(uri).read
#      if csv.include?('call frequency')
#        return :rate_limit_exceeded
#      end
#      CSV.parse(csv, headers: true) do |row|
#        data << row['close'].to_f if row['timestamp'].include?(year.to_s)
#      end
#      year_end = data.first
#      year_end
#    rescue => e
#      p e
#    end
#   end
#
#   api_key = ENV['ALPHAVANTAGE_KEY']
#   abort(error_message) unless api_key
#
#   # Future
#   price = Concurrent::Future.execute{ Ticker.new.get_year_end_closing('TWTR', 2013, api_key) }
#   price.state #=> :pending
#   price.pending? #=> true
#   price.value(0) #=> nil (does not block)
#
#    sleep(1)    # do other stuff
#
#   price.value #=> 63.65 (after blocking if necessary)
#   price.state #=> :fulfilled
#   price.fulfilled? #=> true
#   price.value #=> 63.65
#
# @example Successful task execution
#
#   task = Concurrent::ScheduledTask.new(2){ 'What does the fox say?' }
#   task.state         #=> :unscheduled
#   task.execute
#   task.state         #=> pending
#
#   # wait for it...
#   sleep(3)
#
#   task.unscheduled? #=> false
#   task.pending?     #=> false
#   task.fulfilled?   #=> true
#   task.rejected?    #=> false
#   task.value        #=> 'What does the fox say?'
#
# @example One line creation and execution
#
#   task = Concurrent::ScheduledTask.new(2){ 'What does the fox say?' }.execute
#   task.state         #=> pending
#
#   task = Concurrent::ScheduledTask.execute(2){ 'What do you get when you multiply 6 by 9?' }
#   task.state         #=> pending
#
# @example Failed task execution
#
#   task = Concurrent::ScheduledTask.execute(2){ raise StandardError.new('Call me maybe?') }
#   task.pending?      #=> true
#
#   # wait for it...
#   sleep(3)
#
#   task.unscheduled? #=> false
#   task.pending?     #=> false
#   task.fulfilled?   #=> false
#   task.rejected?    #=> true
#   task.value        #=> nil
#   task.reason       #=> #<StandardError: Call me maybe?>
#
# @example Task execution with observation
#
#   observer = Class.new{
#     def update(time, value, reason)
#       puts "The task completed at #{time} with value '#{value}'"
#     end
#   }.new
#
#   task = Concurrent::ScheduledTask.new(2){ 'What does the fox say?' }
#   task.add_observer(observer)
#   task.execute
#   task.pending?      #=> true
#
#   # wait for it...
#   sleep(3)
#
#   #>> The task completed at 2013-11-07 12:26:09 -0500 with value 'What does the fox say?'
#
# @!macro monotonic_clock_warning
#
# @see Concurrent.timer
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:158
class Concurrent::ScheduledTask < ::Concurrent::IVar
  include ::Comparable

  # Schedule a task for execution at a specified future time.
  #
  # @param [Float] delay the number of seconds to wait for before executing the task
  #
  # @yield the task to be performed
  #
  # @!macro executor_and_deref_options
  #
  # @option opts [object, Array] :args zero or more arguments to be passed the task
  #   block on execution
  #
  # @raise [ArgumentError] When no block is given
  # @raise [ArgumentError] When given a time that is in the past
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:178
  def initialize(delay, opts = T.unsafe(nil), &task); end

  # Comparator which orders by schedule time.
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:213
  def <=>(other); end

  # Cancel this task and prevent it from executing. A task can only be
  # cancelled if it is pending or unscheduled.
  #
  # @return [Boolean] true if successfully cancelled else false
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:235
  def cancel; end

  # Has the task been cancelled?
  #
  # @return [Boolean] true if the task is in the given state else false
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:220
  def cancelled?; end

  # Execute an `:unscheduled` `ScheduledTask`. Immediately sets the state to `:pending`
  # and starts counting down toward execution. Does nothing if the `ScheduledTask` is
  # in any state other than `:unscheduled`.
  #
  # @return [ScheduledTask] a reference to `self`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:273
  def execute; end

  # The executor on which to execute the task.
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:163
  def executor; end

  # The `delay` value given at instantiation.
  #
  # @return [Float] the initial delay.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:199
  def initial_delay; end

  # Execute the task.
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:297
  def process_task; end

  # In the task execution in progress?
  #
  # @return [Boolean] true if the task is in the given state else false
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:227
  def processing?; end

  # Reschedule the task using the given delay and the current time.
  # A task can only be reset while it is `:pending`.
  #
  # @param [Float] delay the number of seconds to wait for before executing the task
  #
  # @return [Boolean] true if successfully rescheduled else false
  #
  # @raise [ArgumentError] When given a time that is in the past
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:262
  def reschedule(delay); end

  # Reschedule the task using the original delay and the current time.
  # A task can only be reset while it is `:pending`.
  #
  # @return [Boolean] true if successfully rescheduled else false
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:250
  def reset; end

  # The monotonic time at which the the task is scheduled to be executed.
  #
  # @return [Float] the schedule time or nil if `unscheduled`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:206
  def schedule_time; end

  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:301
  def fail(reason = T.unsafe(nil)); end

  # Reschedule the task using the given delay and the current time.
  # A task can only be reset while it is `:pending`.
  #
  # @param [Float] delay the number of seconds to wait for before executing the task
  #
  # @return [Boolean] true if successfully rescheduled else false
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:326
  def ns_reschedule(delay); end

  # Schedule the task using the given delay and the current time.
  #
  # @param [Float] delay the number of seconds to wait for before executing the task
  #
  # @return [Boolean] true if successfully rescheduled else false
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:312
  def ns_schedule(delay); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:301
  def set(value = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:301
  def try_set(value = T.unsafe(nil), &block); end

  class << self
    # Create a new `ScheduledTask` object with the given block, execute it, and return the
    # `:pending` object.
    #
    # @param [Float] delay the number of seconds to wait for before executing the task
    #
    # @!macro executor_and_deref_options
    #
    # @return [ScheduledTask] the newly created `ScheduledTask` in the `:pending` state
    #
    # @raise [ArgumentError] if no block is given
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/scheduled_task.rb:290
    def execute(delay, opts = T.unsafe(nil), &task); end
  end
end

# @!macro semaphore
#
#   A counting semaphore. Conceptually, a semaphore maintains a set of
#   permits. Each {#acquire} blocks if necessary until a permit is
#   available, and then takes it. Each {#release} adds a permit, potentially
#   releasing a blocking acquirer.
#   However, no actual permit objects are used; the Semaphore just keeps a
#   count of the number available and acts accordingly.
#   Alternatively, permits may be acquired within a block, and automatically
#   released after the block finishes executing.
#
# @!macro semaphore_public_api
# @example
#   semaphore = Concurrent::Semaphore.new(2)
#
#   t1 = Thread.new do
#     semaphore.acquire
#     puts "Thread 1 acquired semaphore"
#   end
#
#   t2 = Thread.new do
#     semaphore.acquire
#     puts "Thread 2 acquired semaphore"
#   end
#
#   t3 = Thread.new do
#     semaphore.acquire
#     puts "Thread 3 acquired semaphore"
#   end
#
#   t4 = Thread.new do
#     sleep(2)
#     puts "Thread 4 releasing semaphore"
#     semaphore.release
#   end
#
#   [t1, t2, t3, t4].each(&:join)
#
#   # prints:
#   # Thread 3 acquired semaphore
#   # Thread 2 acquired semaphore
#   # Thread 4 releasing semaphore
#   # Thread 1 acquired semaphore
#
# @example
#   semaphore = Concurrent::Semaphore.new(1)
#
#   puts semaphore.available_permits
#   semaphore.acquire do
#     puts semaphore.available_permits
#   end
#   puts semaphore.available_permits
#
#   # prints:
#   # 1
#   # 0
#   # 1
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/semaphore.rb:161
class Concurrent::Semaphore < ::Concurrent::MutexSemaphore; end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/semaphore.rb:96
Concurrent::SemaphoreImplementation = Concurrent::MutexSemaphore

# Indicates that the including `ExecutorService` guarantees
# that all operations will occur in the order they are post and that no
# two operations may occur simultaneously. This module provides no
# functionality and provides no guarantees. That is the responsibility
# of the including class. This module exists solely to allow the including
# object to be interrogated for its serialization status.
#
# @example
#   class Foo
#     include Concurrent::SerialExecutor
#   end
#
#   foo = Foo.new
#
#   foo.is_a? Concurrent::ExecutorService #=> true
#   foo.is_a? Concurrent::SerialExecutor  #=> true
#   foo.serialized?                       #=> true
#
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serial_executor_service.rb:24
module Concurrent::SerialExecutorService
  include ::Concurrent::Concern::Logging
  include ::Concurrent::ExecutorService

  # @!macro executor_service_method_serialized_question
  #
  # @note Always returns `true`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serial_executor_service.rb:30
  def serialized?; end
end

# Ensures passed jobs in a serialized order never running at the same time.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:8
class Concurrent::SerializedExecution < ::Concurrent::Synchronization::LockableObject
  include ::Concurrent::Concern::Logging

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:11
  def initialize; end

  # Submit a task to the executor for asynchronous processing.
  #
  # @param [Executor] executor to be used for this job
  #
  # @param [Array] args zero or more arguments to be passed to the task
  #
  # @yield the asynchronous task to perform
  #
  # @return [Boolean] `true` if the task is queued, `false` if the executor
  #   is not running
  #
  # @raise [ArgumentError] if no task is given
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:34
  def post(executor, *args, &task); end

  # As {#post} but allows to submit multiple tasks at once, it's guaranteed that they will not
  # be interleaved by other tasks.
  #
  # @param [Array<Array(ExecutorService, Array<Object>, Proc)>] posts array of triplets where
  #   first is a {ExecutorService}, second is array of args for task, third is a task (Proc)
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:44
  def posts(posts); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:75
  def call_job(job); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:70
  def ns_initialize; end

  # ensures next job is executed if any is stashed
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:95
  def work(job); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:16
class Concurrent::SerializedExecution::Job < ::Struct
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:16
  def args; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:16
  def args=(_); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:16
  def block; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:16
  def block=(_); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:17
  def call; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:16
  def executor; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:16
  def executor=(_); end

  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:16
    def [](*_arg0); end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:16
    def inspect; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:16
    def keyword_init?; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:16
    def members; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution.rb:16
    def new(*_arg0); end
  end
end

# A wrapper/delegator for any `ExecutorService` that
# guarantees serialized execution of tasks.
#
# @see [SimpleDelegator](http://www.ruby-doc.org/stdlib-2.1.2/libdoc/delegate/rdoc/SimpleDelegator.html)
# @see Concurrent::SerializedExecution
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution_delegator.rb:12
class Concurrent::SerializedExecutionDelegator < ::SimpleDelegator
  include ::Concurrent::Concern::Logging
  include ::Concurrent::ExecutorService
  include ::Concurrent::SerialExecutorService

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution_delegator.rb:15
  def initialize(executor); end

  # @!macro executor_service_method_post
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/serialized_execution_delegator.rb:22
  def post(*args, &task); end
end

# @!macro concurrent_set
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:61
class Concurrent::Set < ::Concurrent::CRubySet; end

# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/set.rb:23
Concurrent::SetImplementation = Concurrent::CRubySet

# An thread-safe, write-once variation of Ruby's standard `Struct`.
# Each member can have its value set at most once, either at construction
# or any time thereafter. Attempting to assign a value to a member
# that has already been set will result in a `Concurrent::ImmutabilityError`.
#
# @see http://ruby-doc.org/core/Struct.html Ruby standard library `Struct`
# @see http://en.wikipedia.org/wiki/Final_(Java) Java `final` keyword
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:14
module Concurrent::SettableStruct
  include ::Concurrent::Synchronization::AbstractStruct

  # @!macro struct_equality
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:50
  def ==(other); end

  # @!macro struct_get
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:45
  def [](member); end

  # @!macro struct_set
  #
  # @raise [Concurrent::ImmutabilityError] if the given member has already been set
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:75
  def []=(member, value); end

  # @!macro struct_each
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:55
  def each(&block); end

  # @!macro struct_each_pair
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:61
  def each_pair(&block); end

  # @!macro struct_inspect
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:29
  def inspect; end

  # @!macro struct_merge
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:35
  def merge(other, &block); end

  # @!macro struct_select
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:67
  def select(&block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:21
  def to_a; end

  # @!macro struct_to_h
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:40
  def to_h; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:32
  def to_s; end

  # @!macro struct_values
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:18
  def values; end

  # @!macro struct_values_at
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:24
  def values_at(*indexes); end

  private

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:97
  def initialize_copy(original); end

  class << self
    # @!macro struct_new
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:105
    def new(*args, &block); end
  end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/settable_struct.rb:115
Concurrent::SettableStruct::FACTORY = T.let(T.unsafe(nil), T.untyped)

# An executor service in which every operation spawns a new,
# independently operating thread.
#
# This is perhaps the most inefficient executor service in this
# library. It exists mainly for testing an debugging. Thread creation
# and management is expensive in Ruby and this executor performs no
# resource pooling. This can be very beneficial during testing and
# debugging because it decouples the using code from the underlying
# executor implementation. In production this executor will likely
# lead to suboptimal performance.
#
# @note Intended for use primarily in testing and debugging.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/simple_executor_service.rb:21
class Concurrent::SimpleExecutorService < ::Concurrent::RubyExecutorService
  # @!macro executor_service_method_left_shift
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/simple_executor_service.rb:56
  def <<(task); end

  # @!macro executor_service_method_kill
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/simple_executor_service.rb:84
  def kill; end

  # @!macro executor_service_method_post
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/simple_executor_service.rb:40
  def post(*args, &task); end

  # @!macro executor_service_method_running_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/simple_executor_service.rb:62
  def running?; end

  # @!macro executor_service_method_shutdown
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/simple_executor_service.rb:77
  def shutdown; end

  # @!macro executor_service_method_shutdown_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/simple_executor_service.rb:72
  def shutdown?; end

  # @!macro executor_service_method_shuttingdown_question
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/simple_executor_service.rb:67
  def shuttingdown?; end

  # @!macro executor_service_method_wait_for_termination
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/simple_executor_service.rb:91
  def wait_for_termination(timeout = T.unsafe(nil)); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/simple_executor_service.rb:97
  def ns_initialize(*args); end

  class << self
    # @!macro executor_service_method_left_shift
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/simple_executor_service.rb:34
    def <<(task); end

    # @!macro executor_service_method_post
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/simple_executor_service.rb:24
    def post(*args); end
  end
end

# @!macro single_thread_executor
#
#   A thread pool with a single thread an unlimited queue. Should the thread
#   die for any reason it will be removed and replaced, thus ensuring that
#   the executor will always remain viable and available to process jobs.
#
#   A common pattern for background processing is to create a single thread
#   on which an infinite loop is run. The thread's loop blocks on an input
#   source (perhaps blocking I/O or a queue) and processes each input as it
#   is received. This pattern has several issues. The thread itself is highly
#   susceptible to errors during processing. Also, the thread itself must be
#   constantly monitored and restarted should it die. `SingleThreadExecutor`
#   encapsulates all these behaviors. The task processor is highly resilient
#   to errors from within tasks. Also, should the thread die it will
#   automatically be restarted.
#
#   The API and behavior of this class are based on Java's `SingleThreadExecutor`.
#
# @!macro abstract_executor_service_public_api
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/single_thread_executor.rb:37
class Concurrent::SingleThreadExecutor < ::Concurrent::RubySingleThreadExecutor; end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/single_thread_executor.rb:10
Concurrent::SingleThreadExecutorImplementation = Concurrent::RubySingleThreadExecutor

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_object.rb:2
module Concurrent::Synchronization
  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/full_memory_barrier.rb:7
    def full_memory_barrier; end
  end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_lockable_object.rb:9
class Concurrent::Synchronization::AbstractLockableObject < ::Concurrent::Synchronization::Object
  protected

  # @!macro synchronization_object_method_ns_broadcast
  #
  #   Broadcast to all waiting threads.
  #   @return [self]
  #   @note only to be used inside synchronized block
  #   @note to provide direct access to this method in a descendant add method
  #     ```
  #     def broadcast
  #       synchronize { ns_broadcast }
  #     end
  #     ```
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_lockable_object.rb:96
  def ns_broadcast; end

  # @!macro synchronization_object_method_ns_signal
  #
  #   Signal one waiting thread.
  #   @return [self]
  #   @note only to be used inside synchronized block
  #   @note to provide direct access to this method in a descendant add method
  #     ```
  #     def signal
  #       synchronize { ns_signal }
  #     end
  #     ```
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_lockable_object.rb:81
  def ns_signal; end

  # @!macro synchronization_object_method_ns_wait
  #
  #   Wait until another thread calls #signal or #broadcast,
  #   spurious wake-ups can happen.
  #
  #   @param [Numeric, nil] timeout in seconds, `nil` means no timeout
  #   @return [self]
  #   @note only to be used inside synchronized block
  #   @note to provide direct access to this method in a descendant add method
  #     ```
  #     def wait(timeout = nil)
  #       synchronize { ns_wait(timeout) }
  #     end
  #     ```
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_lockable_object.rb:66
  def ns_wait(timeout = T.unsafe(nil)); end

  # @!macro synchronization_object_method_ns_wait_until
  #
  #   Wait until condition is met or timeout passes,
  #   protects against spurious wake-ups.
  #   @param [Numeric, nil] timeout in seconds, `nil` means no timeout
  #   @yield condition to be met
  #   @yieldreturn [true, false]
  #   @return [true, false] if condition met
  #   @note only to be used inside synchronized block
  #   @note to provide direct access to this method in a descendant add method
  #     ```
  #     def wait_until(timeout = nil, &condition)
  #       synchronize { ns_wait_until(timeout, &condition) }
  #     end
  #     ```
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_lockable_object.rb:37
  def ns_wait_until(timeout = T.unsafe(nil), &condition); end

  # @!macro synchronization_object_method_synchronize
  #
  #   @yield runs the block synchronized against this object,
  #     equivalent of java's `synchronize(this) {}`
  #   @note can by made public in descendants if required by `public :synchronize`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_lockable_object.rb:18
  def synchronize; end
end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_object.rb:6
class Concurrent::Synchronization::AbstractObject
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_object.rb:7
  def initialize; end

  # @!visibility private
  # @abstract
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_object.rb:13
  def full_memory_barrier; end

  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_object.rb:17
    def attr_volatile(*names); end
  end
end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:6
module Concurrent::Synchronization::AbstractStruct
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:9
  def initialize(*values); end

  # @!macro struct_length
  #
  #   Returns the number of struct members.
  #
  #   @return [Fixnum] the number of struct members
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:19
  def length; end

  # @!macro struct_members
  #
  #   Returns the struct members as an array of symbols.
  #
  #   @return [Array] the struct members as an array of symbols
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:29
  def members; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:22
  def size; end

  protected

  # @!macro struct_each
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:82
  def ns_each; end

  # @!macro struct_each_pair
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:89
  def ns_each_pair; end

  # @!macro struct_equality
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:75
  def ns_equality(other); end

  # @!macro struct_get
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:59
  def ns_get(member); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:119
  def ns_initialize_copy; end

  # @!macro struct_inspect
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:105
  def ns_inspect; end

  # @!macro struct_merge
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:114
  def ns_merge(other, &block); end

  # @!macro struct_select
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:98
  def ns_select; end

  # @!macro struct_to_h
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:52
  def ns_to_h; end

  # @!macro struct_values
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:38
  def ns_values; end

  # @!macro struct_values_at
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:45
  def ns_values_at(indexes); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:130
  def pr_underscore(clazz); end

  class << self
    # @!visibility private
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/abstract_struct.rb:141
    def define_struct_class(parent, base, name, members, &block); end
  end
end

# @!visibility private
# TODO (pitr-ch 04-Dec-2016): should be in edge
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:8
class Concurrent::Synchronization::Condition < ::Concurrent::Synchronization::LockableObject
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:18
  def initialize(lock); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:47
  def broadcast; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:51
  def ns_broadcast; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:43
  def ns_signal; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:27
  def ns_wait(timeout = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:35
  def ns_wait_until(timeout = T.unsafe(nil), &condition); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:39
  def signal; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:23
  def wait(timeout = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:31
  def wait_until(timeout = T.unsafe(nil), &condition); end

  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:15
    def private_new(*args, &block); end

    private

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:16
    def new(*args, &block); end
  end
end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:8
module Concurrent::Synchronization::ConditionSignalling
  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:16
  def ns_broadcast; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:11
  def ns_signal; end
end

# @!visibility private
# TODO (pitr-ch 04-Dec-2016): should be in edge
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/lock.rb:8
class Concurrent::Synchronization::Lock < ::Concurrent::Synchronization::LockableObject
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/lock.rb:31
  def broadcast; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/lock.rb:35
  def ns_broadcast; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/lock.rb:29
  def ns_signal; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/lock.rb:17
  def ns_wait(timeout = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/lock.rb:23
  def ns_wait_until(timeout = T.unsafe(nil), &condition); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/lock.rb:25
  def signal; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/lock.rb:11
  def synchronize; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/lock.rb:13
  def wait(timeout = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/lock.rb:19
  def wait_until(timeout = T.unsafe(nil), &condition); end
end

#   Safe synchronization under any Ruby implementation.
#   It provides methods like {#synchronize}, {#wait}, {#signal} and {#broadcast}.
#   Provides a single layer which can improve its implementation over time without changes needed to
#   the classes using it. Use {Synchronization::Object} not this abstract class.
#
#   @note this object does not support usage together with
#     [`Thread#wakeup`](http://ruby-doc.org/core/Thread.html#method-i-wakeup)
#     and [`Thread#raise`](http://ruby-doc.org/core/Thread.html#method-i-raise).
#     `Thread#sleep` and `Thread#wakeup` will work as expected but mixing `Synchronization::Object#wait` and
#     `Thread#wakeup` will not work on all platforms.
#
#   @see Event implementation as an example of this class use
#
#   @example simple
#     class AnClass < Synchronization::Object
#       def initialize
#         super
#         synchronize { @value = 'asd' }
#       end
#
#       def value
#         synchronize { @value }
#       end
#     end
#
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/lockable_object.rb:50
class Concurrent::Synchronization::LockableObject < ::Concurrent::Synchronization::MutexLockableObject
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/condition.rb:57
  def new_condition; end
end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/lockable_object.rb:11
Concurrent::Synchronization::LockableObjectImplementation = Concurrent::Synchronization::MutexLockableObject

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:60
class Concurrent::Synchronization::MonitorLockableObject < ::Concurrent::Synchronization::AbstractLockableObject
  include ::Concurrent::Synchronization::ConditionSignalling
  extend ::Concurrent::Synchronization::SafeInitialization

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:65
  def initialize; end

  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:83
  def ns_wait(timeout = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:79
  def synchronize; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:71
  def initialize_copy(other); end
end

# @!visibility private
# @!macro internal_implementation_note
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:25
class Concurrent::Synchronization::MutexLockableObject < ::Concurrent::Synchronization::AbstractLockableObject
  include ::Concurrent::Synchronization::ConditionSignalling
  extend ::Concurrent::Synchronization::SafeInitialization

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:30
  def initialize; end

  protected

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:52
  def ns_wait(timeout = T.unsafe(nil)); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:44
  def synchronize; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb:36
  def initialize_copy(other); end
end

# Abstract object providing final, volatile, ans CAS extensions to build other concurrent abstractions.
# - final instance variables see {Object.safe_initialization!}
# - volatile instance variables see {Object.attr_volatile}
# - volatile instance variables see {Object.attr_atomic}
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/object.rb:15
class Concurrent::Synchronization::Object < ::Concurrent::Synchronization::AbstractObject
  include ::Concurrent::Synchronization::Volatile
  extend ::Concurrent::Synchronization::Volatile::ClassMethods

  # Has to be called by children.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/object.rb:28
  def initialize; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/object.rb:146
  def __initialize_atomic_fields__; end

  class << self
    # @return [true, false] is the attribute with name atomic?
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/object.rb:125
    def atomic_attribute?(name); end

    # @param [true, false] inherited should inherited volatile with CAS fields be returned?
    # @return [::Array<Symbol>] Returns defined volatile with CAS fields on this class.
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/object.rb:119
    def atomic_attributes(inherited = T.unsafe(nil)); end

    # Creates methods for reading and writing to a instance variable with
    # volatile (Java) semantic as {.attr_volatile} does.
    # The instance variable should be accessed only through generated methods.
    # This method generates following methods: `value`, `value=(new_value) #=> new_value`,
    # `swap_value(new_value) #=> old_value`,
    # `compare_and_set_value(expected, value) #=> true || false`, `update_value(&block)`.
    # @param [::Array<Symbol>] names of the instance variables to be volatile with CAS.
    # @return [::Array<Symbol>] names of defined method names.
    # @!macro attr_atomic
    #   @!method $1
    #     @return [Object] The $1.
    #   @!method $1=(new_$1)
    #     Set the $1.
    #     @return [Object] new_$1.
    #   @!method swap_$1(new_$1)
    #     Set the $1 to new_$1 and return the old $1.
    #     @return [Object] old $1
    #   @!method compare_and_set_$1(expected_$1, new_$1)
    #     Sets the $1 to new_$1 if the current $1 is expected_$1
    #     @return [true, false]
    #   @!method update_$1(&block)
    #     Updates the $1 using the block.
    #     @yield [Object] Calculate a new $1 using given (old) $1
    #     @yieldparam [Object] old $1
    #     @return [Object] new $1
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/object.rb:84
    def attr_atomic(*names); end

    # For testing purposes, quite slow. Injects assert code to new method which will raise if class instance contains
    # any instance variables with CamelCase names and isn't {.safe_initialization?}.
    # @raise when offend found
    # @return [true]
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/object.rb:45
    def ensure_safe_initialization_when_final_fields_are_present; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/object.rb:33
    def safe_initialization!; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/object.rb:37
    def safe_initialization?; end

    private

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/object.rb:131
    def define_initialize_atomic_fields; end
  end
end

# @!visibility private
# @!macro internal_implementation_note
#
# By extending this module, a class and all its children are marked to be constructed safely. Meaning that
# all writes (ivar initializations) are made visible to all readers of newly constructed object. It ensures
# same behaviour as Java's final fields.
#
# Due to using Kernel#extend, the module is not included again if already present in the ancestors,
# which avoids extra overhead.
#
# @example
#   class AClass < Concurrent::Synchronization::Object
#     extend Concurrent::Synchronization::SafeInitialization
#
#     def initialize
#       @AFinalValue = 'value' # published safely, #foo will never return nil
#     end
#
#     def foo
#       @AFinalValue
#     end
#   end
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/safe_initialization.rb:28
module Concurrent::Synchronization::SafeInitialization
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/safe_initialization.rb:29
  def new(*args, &block); end
end

# Volatile adds the attr_volatile class method when included.
#
# @example
#   class Foo
#     include Concurrent::Synchronization::Volatile
#
#     attr_volatile :bar
#
#     def initialize
#       self.bar = 1
#     end
#   end
#
#  foo = Foo.new
#  foo.bar
#  => 1
#  foo.bar = 2
#  => 2
#
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/volatile.rb:28
module Concurrent::Synchronization::Volatile
  mixes_in_class_methods ::Concurrent::Synchronization::Volatile::ClassMethods

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/volatile.rb:33
  def full_memory_barrier; end

  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/volatile.rb:29
    def included(base); end
  end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/volatile.rb:37
module Concurrent::Synchronization::Volatile::ClassMethods
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/synchronization/volatile.rb:39
  def attr_volatile(*names); end
end

# This class provides a trivial way to synchronize all calls to a given object
# by wrapping it with a `Delegator` that performs `Monitor#enter/exit` calls
# around the delegated `#send`. Example:
#
#   array = [] # not thread-safe on many impls
#   array = SynchronizedDelegator.new([]) # thread-safe
#
# A simple `Monitor` provides a very coarse-grained way to synchronize a given
# object, in that it will cause synchronization for methods that have no need
# for it, but this is a trivial way to get thread-safety where none may exist
# currently on some implementations.
#
# This class is currently being considered for inclusion into stdlib, via
# https://bugs.ruby-lang.org/issues/8556
#
# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/thread_safe/synchronized_delegator.rb:21
class Concurrent::SynchronizedDelegator < ::SimpleDelegator
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/thread_safe/synchronized_delegator.rb:31
  def initialize(obj); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/thread_safe/synchronized_delegator.rb:36
  def method_missing(method, *args, &block); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/thread_safe/synchronized_delegator.rb:22
  def setup; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/thread_safe/synchronized_delegator.rb:27
  def teardown; end
end

# A `TVar` is a transactional variable - a single-element container that
# is used as part of a transaction - see `Concurrent::atomically`.
#
# @!macro thread_safe_variable_comparison
#
# {include:file:docs-source/tvar.md}
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:12
class Concurrent::TVar < ::Concurrent::Synchronization::Object
  extend ::Concurrent::Synchronization::SafeInitialization

  # Create a new `TVar` with an initial value.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:16
  def initialize(value); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:46
  def unsafe_lock; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:36
  def unsafe_value; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:41
  def unsafe_value=(value); end

  # Get the value of a `TVar`.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:22
  def value; end

  # Set the value of a `TVar`.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:29
  def value=(value); end
end

# A `ThreadLocalVar` is a variable where the value is different for each thread.
# Each variable may have a default value, but when you modify the variable only
# the current thread will ever see that change.
#
# This is similar to Ruby's built-in thread-local variables (`Thread#thread_variable_get`),
# but with these major advantages:
# * `ThreadLocalVar` has its own identity, it doesn't need a Symbol.
# * Each Ruby's built-in thread-local variable leaks some memory forever (it's a Symbol held forever on the thread),
#   so it's only OK to create a small amount of them.
#   `ThreadLocalVar` has no such issue and it is fine to create many of them.
# * Ruby's built-in thread-local variables leak forever the value set on each thread (unless set to nil explicitly).
#   `ThreadLocalVar` automatically removes the mapping for each thread once the `ThreadLocalVar` instance is GC'd.
#
# @!macro thread_safe_variable_comparison
#
# @example
#   v = ThreadLocalVar.new(14)
#   v.value #=> 14
#   v.value = 2
#   v.value #=> 2
#
# @example
#   v = ThreadLocalVar.new(14)
#
#   t1 = Thread.new do
#     v.value #=> 14
#     v.value = 1
#     v.value #=> 1
#   end
#
#   t2 = Thread.new do
#     v.value #=> 14
#     v.value = 2
#     v.value #=> 2
#   end
#
#   v.value #=> 14
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/thread_local_var.rb:43
class Concurrent::ThreadLocalVar
  # Creates a thread local variable.
  #
  # @param [Object] default the default value when otherwise unset
  # @param [Proc] default_block Optional block that gets called to obtain the
  #   default value for each thread
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/thread_local_var.rb:51
  def initialize(default = T.unsafe(nil), &default_block); end

  # Bind the given value to thread local storage during
  # execution of the given block.
  #
  # @param [Object] value the value to bind
  # @yield the operation to be performed with the bound variable
  # @return [Object] the value
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/thread_local_var.rb:88
  def bind(value); end

  # Returns the value in the current thread's copy of this thread-local variable.
  #
  # @return [Object] the current value
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/thread_local_var.rb:70
  def value; end

  # Sets the current thread's copy of this thread-local variable to the specified value.
  #
  # @param [Object] value the value to set
  # @return [Object] the new value
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/thread_local_var.rb:78
  def value=(value); end

  protected

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/thread_local_var.rb:103
  def default; end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/thread_local_var.rb:44
Concurrent::ThreadLocalVar::LOCALS = T.let(T.unsafe(nil), Concurrent::ThreadLocals)

# @!visibility private
# @!macro internal_implementation_note
# An array-backed storage of indexed variables per thread.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:141
class Concurrent::ThreadLocals < ::Concurrent::AbstractLocals
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:142
  def locals; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/atomic/locals.rb:146
  def locals!; end
end

# @!macro thread_pool_executor
#
#   An abstraction composed of one or more threads and a task queue. Tasks
#   (blocks or `proc` objects) are submitted to the pool and added to the queue.
#   The threads in the pool remove the tasks and execute them in the order
#   they were received.
#
#   A `ThreadPoolExecutor` will automatically adjust the pool size according
#   to the bounds set by `min-threads` and `max-threads`. When a new task is
#   submitted and fewer than `min-threads` threads are running, a new thread
#   is created to handle the request, even if other worker threads are idle.
#   If there are more than `min-threads` but less than `max-threads` threads
#   running, a new thread will be created only if the queue is full.
#
#   Threads that are idle for too long will be garbage collected, down to the
#   configured minimum options. Should a thread crash it, too, will be garbage collected.
#
#   `ThreadPoolExecutor` is based on the Java class of the same name. From
#   the official Java documentation;
#
#   > Thread pools address two different problems: they usually provide
#   > improved performance when executing large numbers of asynchronous tasks,
#   > due to reduced per-task invocation overhead, and they provide a means
#   > of bounding and managing the resources, including threads, consumed
#   > when executing a collection of tasks. Each ThreadPoolExecutor also
#   > maintains some basic statistics, such as the number of completed tasks.
#   >
#   > To be useful across a wide range of contexts, this class provides many
#   > adjustable parameters and extensibility hooks. However, programmers are
#   > urged to use the more convenient Executors factory methods
#   > [CachedThreadPool] (unbounded thread pool, with automatic thread reclamation),
#   > [FixedThreadPool] (fixed size thread pool) and [SingleThreadExecutor] (single
#   > background thread), that preconfigure settings for the most common usage
#   > scenarios.
#
# @!macro thread_pool_options
#
# @!macro thread_pool_executor_public_api
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/thread_pool_executor.rb:56
class Concurrent::ThreadPoolExecutor < ::Concurrent::RubyThreadPoolExecutor; end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/thread_pool_executor.rb:10
Concurrent::ThreadPoolExecutorImplementation = Concurrent::RubyThreadPoolExecutor

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/thread_safe/util.rb:4
module Concurrent::ThreadSafe; end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/thread_safe/util.rb:7
module Concurrent::ThreadSafe::Util
  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/thread_safe/util/data_structures.rb:16
    def make_synchronized_on_cruby(klass); end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/thread_safe/util/data_structures.rb:41
    def make_synchronized_on_truffleruby(klass); end
  end
end

# TODO (pitr-ch 15-Oct-2016): migrate to Utility::ProcessorCounter
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/thread_safe/util.rb:13
Concurrent::ThreadSafe::Util::CPU_COUNT = T.let(T.unsafe(nil), Integer)

# TODO (pitr-ch 15-Oct-2016): migrate to Utility::NativeInteger
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/thread_safe/util.rb:10
Concurrent::ThreadSafe::Util::FIXNUM_BIT_SIZE = T.let(T.unsafe(nil), Integer)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/thread_safe/util.rb:11
Concurrent::ThreadSafe::Util::MAX_INT = T.let(T.unsafe(nil), Integer)

# Raised when an operation times out.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/errors.rb:55
class Concurrent::TimeoutError < ::Concurrent::Error; end

# Executes a collection of tasks, each after a given delay. A master task
# monitors the set and schedules each task for execution at the appropriate
# time. Tasks are run on the global thread pool or on the supplied executor.
# Each task is represented as a `ScheduledTask`.
#
# @see Concurrent::ScheduledTask
#
# @!macro monotonic_clock_warning
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/timer_set.rb:19
class Concurrent::TimerSet < ::Concurrent::RubyExecutorService
  # Create a new set of timed tasks.
  #
  # @!macro executor_options
  #
  #   @param [Hash] opts the options used to specify the executor on which to perform actions
  #   @option opts [Executor] :executor when set use the given `Executor` instance.
  #     Three special values are also supported: `:task` returns the global task pool,
  #     `:operation` returns the global operation pool, and `:immediate` returns a new
  #     `ImmediateExecutor` object.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/timer_set.rb:30
  def initialize(opts = T.unsafe(nil)); end

  # Begin an immediate shutdown. In-progress tasks will be allowed to
  # complete but enqueued tasks will be dismissed and no new tasks
  # will be accepted. Has no additional effect if the thread pool is
  # not running.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/timer_set.rb:62
  def kill; end

  # Post a task to be execute run after a given delay (in seconds). If the
  # delay is less than 1/100th of a second the task will be immediately post
  # to the executor.
  #
  # @param [Float] delay the number of seconds to wait for before executing the task.
  # @param [Array<Object>] args the arguments passed to the task on execution.
  #
  # @yield the task to be performed.
  #
  # @return [Concurrent::ScheduledTask, false] IVar representing the task if the post
  #   is successful; false after shutdown.
  #
  # @raise [ArgumentError] if the intended execution time is not in the future.
  # @raise [ArgumentError] if no block is given.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/timer_set.rb:48
  def post(delay, *args, &task); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/timer_set.rb:67
  def <<(task); end

  # Initialize the object.
  #
  # @param [Hash] opts the options to create the object with.
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/timer_set.rb:75
  def ns_initialize(opts); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/timer_set.rb:95
  def ns_post_task(task); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/timer_set.rb:132
  def ns_reset_if_forked; end

  # `ExecutorService` callback called during shutdown.
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/timer_set.rb:123
  def ns_shutdown_execution; end

  # Post the task to the internal queue.
  #
  # @note This is intended as a callback method from ScheduledTask
  #   only. It is not intended to be used directly. Post a task
  #   by using the `SchedulesTask#execute` method.
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/timer_set.rb:90
  def post_task(task); end

  # Run a loop and execute tasks in the scheduled order and at the approximate
  # scheduled time. If no tasks remain the thread will exit gracefully so that
  # garbage collection can occur. If there are no ready tasks it will sleep
  # for up to 60 seconds waiting for the next scheduled task.
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/timer_set.rb:146
  def process_tasks; end

  # Remove the given task from the queue.
  #
  # @note This is intended as a callback method from `ScheduledTask`
  #   only. It is not intended to be used directly. Cancel a task
  #   by using the `ScheduledTask#cancel` method.
  #
  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/executor/timer_set.rb:116
  def remove_task(task); end
end

# A very common concurrency pattern is to run a thread that performs a task at
# regular intervals. The thread that performs the task sleeps for the given
# interval then wakes up and performs the task. Lather, rinse, repeat... This
# pattern causes two problems. First, it is difficult to test the business
# logic of the task because the task itself is tightly coupled with the
# concurrency logic. Second, an exception raised while performing the task can
# cause the entire thread to abend. In a long-running application where the
# task thread is intended to run for days/weeks/years a crashed task thread
# can pose a significant problem. `TimerTask` alleviates both problems.
#
# When a `TimerTask` is launched it starts a thread for monitoring the
# execution interval. The `TimerTask` thread does not perform the task,
# however. Instead, the TimerTask launches the task on a separate thread.
# Should the task experience an unrecoverable crash only the task thread will
# crash. This makes the `TimerTask` very fault tolerant. Additionally, the
# `TimerTask` thread can respond to the success or failure of the task,
# performing logging or ancillary operations.
#
# One other advantage of `TimerTask` is that it forces the business logic to
# be completely decoupled from the concurrency logic. The business logic can
# be tested separately then passed to the `TimerTask` for scheduling and
# running.
#
# A `TimerTask` supports two different types of interval calculations.
# A fixed delay will always wait the same amount of time between the
# completion of one task and the start of the next. A fixed rate will
# attempt to maintain a constant rate of execution regardless of the
# duration of the task. For example, if a fixed rate task is scheduled
# to run every 60 seconds but the task itself takes 10 seconds to
# complete, the next task will be scheduled to run 50 seconds after
# the start of the previous task. If the task takes 70 seconds to
# complete, the next task will be start immediately after the previous
# task completes. Tasks will not be executed concurrently.
#
# In some cases it may be necessary for a `TimerTask` to affect its own
# execution cycle. To facilitate this, a reference to the TimerTask instance
# is passed as an argument to the provided block every time the task is
# executed.
#
# The `TimerTask` class includes the `Dereferenceable` mixin module so the
# result of the last execution is always available via the `#value` method.
# Dereferencing options can be passed to the `TimerTask` during construction or
# at any later time using the `#set_deref_options` method.
#
# `TimerTask` supports notification through the Ruby standard library
# {http://ruby-doc.org/stdlib-2.0/libdoc/observer/rdoc/Observable.html
# Observable} module. On execution the `TimerTask` will notify the observers
# with three arguments: time of execution, the result of the block (or nil on
# failure), and any raised exceptions (or nil on success).
#
# @!macro copy_options
#
# @example Basic usage
#   task = Concurrent::TimerTask.new{ puts 'Boom!' }
#   task.execute
#
#   task.execution_interval #=> 60 (default)
#
#   # wait 60 seconds...
#   #=> 'Boom!'
#
#   task.shutdown #=> true
#
# @example Configuring `:execution_interval`
#   task = Concurrent::TimerTask.new(execution_interval: 5) do
#          puts 'Boom!'
#        end
#
#   task.execution_interval #=> 5
#
# @example Immediate execution with `:run_now`
#   task = Concurrent::TimerTask.new(run_now: true){ puts 'Boom!' }
#   task.execute
#
#   #=> 'Boom!'
#
# @example Configuring `:interval_type` with either :fixed_delay or :fixed_rate, default is :fixed_delay
#   task = Concurrent::TimerTask.new(execution_interval: 5, interval_type: :fixed_rate) do
#          puts 'Boom!'
#        end
#   task.interval_type #=> :fixed_rate
#
# @example Last `#value` and `Dereferenceable` mixin
#   task = Concurrent::TimerTask.new(
#     dup_on_deref: true,
#     execution_interval: 5
#   ){ Time.now }
#
#   task.execute
#   Time.now   #=> 2013-11-07 18:06:50 -0500
#   sleep(10)
#   task.value #=> 2013-11-07 18:06:55 -0500
#
# @example Controlling execution from within the block
#   timer_task = Concurrent::TimerTask.new(execution_interval: 1) do |task|
#     task.execution_interval.to_i.times{ print 'Boom! ' }
#     print "\n"
#     task.execution_interval += 1
#     if task.execution_interval > 5
#       puts 'Stopping...'
#       task.shutdown
#     end
#   end
#
#   timer_task.execute
#   #=> Boom!
#   #=> Boom! Boom!
#   #=> Boom! Boom! Boom!
#   #=> Boom! Boom! Boom! Boom!
#   #=> Boom! Boom! Boom! Boom! Boom!
#   #=> Stopping...
#
# @example Observation
#   class TaskObserver
#     def update(time, result, ex)
#       if result
#         print "(#{time}) Execution successfully returned #{result}\n"
#       else
#         print "(#{time}) Execution failed with error #{ex}\n"
#       end
#     end
#   end
#
#   task = Concurrent::TimerTask.new(execution_interval: 1){ 42 }
#   task.add_observer(TaskObserver.new)
#   task.execute
#   sleep 4
#
#   #=> (2013-10-13 19:08:58 -0400) Execution successfully returned 42
#   #=> (2013-10-13 19:08:59 -0400) Execution successfully returned 42
#   #=> (2013-10-13 19:09:00 -0400) Execution successfully returned 42
#   task.shutdown
#
#   task = Concurrent::TimerTask.new(execution_interval: 1){ sleep }
#   task.add_observer(TaskObserver.new)
#   task.execute
#
#   #=> (2013-10-13 19:07:25 -0400) Execution timed out
#   #=> (2013-10-13 19:07:27 -0400) Execution timed out
#   #=> (2013-10-13 19:07:29 -0400) Execution timed out
#   task.shutdown
#
#   task = Concurrent::TimerTask.new(execution_interval: 1){ raise StandardError }
#   task.add_observer(TaskObserver.new)
#   task.execute
#
#   #=> (2013-10-13 19:09:37 -0400) Execution failed with error StandardError
#   #=> (2013-10-13 19:09:38 -0400) Execution failed with error StandardError
#   #=> (2013-10-13 19:09:39 -0400) Execution failed with error StandardError
#   task.shutdown
#
# @see http://ruby-doc.org/stdlib-2.0/libdoc/observer/rdoc/Observable.html
# @see http://docs.oracle.com/javase/7/docs/api/java/util/TimerTask.html
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:166
class Concurrent::TimerTask < ::Concurrent::RubyExecutorService
  include ::Concurrent::Concern::Dereferenceable
  include ::Concurrent::Concern::Observable

  # Create a new TimerTask with the given task and configuration.
  #
  # @!macro timer_task_initialize
  #   @param [Hash] opts the options defining task execution.
  #   @option opts [Float] :execution_interval number of seconds between
  #     task executions (default: EXECUTION_INTERVAL)
  #   @option opts [Boolean] :run_now Whether to run the task immediately
  #     upon instantiation or to wait until the first #  execution_interval
  #     has passed (default: false)
  #   @options opts [Symbol] :interval_type method to calculate the interval
  #     between executions, can be either :fixed_rate or :fixed_delay.
  #     (default: :fixed_delay)
  #   @option opts [Executor] executor, default is `global_io_executor`
  #
  #   @!macro deref_options
  #
  #   @raise ArgumentError when no block is given.
  #
  #   @yield to the block after :execution_interval seconds have passed since
  #     the last yield
  #   @yieldparam task a reference to the `TimerTask` instance so that the
  #     block can control its own lifecycle. Necessary since `self` will
  #     refer to the execution context of the block rather than the running
  #     `TimerTask`.
  #
  #   @return [TimerTask] the new `TimerTask`
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:210
  def initialize(opts = T.unsafe(nil), &task); end

  # Execute a previously created `TimerTask`.
  #
  # @return [TimerTask] a reference to `self`
  #
  # @example Instance and execute in separate steps
  #   task = Concurrent::TimerTask.new(execution_interval: 10){ print "Hello World\n" }
  #   task.running? #=> false
  #   task.execute
  #   task.running? #=> true
  #
  # @example Instance and execute in one line
  #   task = Concurrent::TimerTask.new(execution_interval: 10){ print "Hello World\n" }.execute
  #   task.running? #=> true
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:236
  def execute; end

  # @!attribute [rw] execution_interval
  # @return [Fixnum] Number of seconds after the task completes before the
  #   task is performed again.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:261
  def execution_interval; end

  # @!attribute [rw] execution_interval
  # @return [Fixnum] Number of seconds after the task completes before the
  #   task is performed again.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:268
  def execution_interval=(value); end

  # @!attribute [r] interval_type
  # @return [Symbol] method to calculate the interval between executions
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:278
  def interval_type; end

  # Is the executor running?
  #
  # @return [Boolean] `true` when running, `false` when shutting down or shutdown
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:219
  def running?; end

  # @!attribute [rw] timeout_interval
  # @return [Fixnum] Number of seconds the task can run before it is
  #   considered to have failed.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:283
  def timeout_interval; end

  # @!attribute [rw] timeout_interval
  # @return [Fixnum] Number of seconds the task can run before it is
  #   considered to have failed.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:290
  def timeout_interval=(value); end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:294
  def <<(task); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:357
  def calculate_next_interval(start_time); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:339
  def execute_task(completion, age_when_scheduled); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:298
  def ns_initialize(opts, &task); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:327
  def ns_kill_execution; end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:321
  def ns_shutdown_execution; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:294
  def post(*args, &task); end

  # @!visibility private
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:333
  def schedule_next_task(interval = T.unsafe(nil)); end

  class << self
    # Create and execute a new `TimerTask`.
    #
    # @!macro timer_task_initialize
    #
    # @example
    #   task = Concurrent::TimerTask.execute(execution_interval: 10){ print "Hello World\n" }
    #   task.running? #=> true
    #
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:254
    def execute(opts = T.unsafe(nil), &task); end
  end
end

# Default `:interval_type`
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:182
Concurrent::TimerTask::DEFAULT_INTERVAL_TYPE = T.let(T.unsafe(nil), Symbol)

# Default `:execution_interval` in seconds.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:171
Concurrent::TimerTask::EXECUTION_INTERVAL = T.let(T.unsafe(nil), Integer)

# Maintain the interval between the end of one execution and the start of the next execution.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:174
Concurrent::TimerTask::FIXED_DELAY = T.let(T.unsafe(nil), Symbol)

# Maintain the interval between the start of one execution and the start of the next.
# If execution time exceeds the interval, the next execution will start immediately
# after the previous execution finishes. Executions will not run concurrently.
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/timer_task.rb:179
Concurrent::TimerTask::FIXED_RATE = T.let(T.unsafe(nil), Symbol)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:153
class Concurrent::Transaction
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:162
  def initialize; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:192
  def abort; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:196
  def commit; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:177
  def open(tvar); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:166
  def read(tvar); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:206
  def unlock; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:171
  def write(tvar, value); end

  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:212
    def current; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:216
    def current=(transaction); end
  end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:155
Concurrent::Transaction::ABORTED = T.let(T.unsafe(nil), Object)

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:159
class Concurrent::Transaction::AbortError < ::StandardError; end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:160
class Concurrent::Transaction::LeaveError < ::StandardError; end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:157
class Concurrent::Transaction::OpenEntry < ::Struct
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:157
  def modified; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:157
  def modified=(_); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:157
  def value; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:157
  def value=(_); end

  class << self
    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:157
    def [](*_arg0); end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:157
    def inspect; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:157
    def keyword_init?; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:157
    def members; end

    # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tvar.rb:157
    def new(*_arg0); end
  end
end

# A fixed size array with volatile (synchronized, thread safe) getters/setters.
# Mixes in Ruby's `Enumerable` module for enhanced search, sort, and traversal.
#
# @example
#   tuple = Concurrent::Tuple.new(16)
#
#   tuple.set(0, :foo)                   #=> :foo  | volatile write
#   tuple.get(0)                         #=> :foo  | volatile read
#   tuple.compare_and_set(0, :foo, :bar) #=> true  | strong CAS
#   tuple.cas(0, :foo, :baz)             #=> false | strong CAS
#   tuple.get(0)                         #=> :bar  | volatile read
#
# @see https://en.wikipedia.org/wiki/Tuple Tuple entry at Wikipedia
# @see http://www.erlang.org/doc/reference_manual/data_types.html#id70396 Erlang Tuple
# @see http://ruby-doc.org/core-2.2.2/Enumerable.html Enumerable
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tuple.rb:20
class Concurrent::Tuple
  include ::Enumerable

  # Create a new tuple of the given size.
  #
  # @param [Integer] size the number of elements in the tuple
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tuple.rb:29
  def initialize(size); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tuple.rb:73
  def cas(i, old_value, new_value); end

  # Set the value at the given index to the new value if and only if the current
  # value matches the given old value.
  #
  # @param [Integer] i the index for the element to set
  # @param [Object] old_value the value to compare against the current value
  # @param [Object] new_value the value to set at the given index
  #
  # @return [Boolean] true if the value at the given element was set else false
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tuple.rb:69
  def compare_and_set(i, old_value, new_value); end

  # Calls the given block once for each element in self, passing that element as a parameter.
  #
  # @yieldparam [Object] ref the `Concurrent::AtomicReference` object at the current index
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tuple.rb:78
  def each; end

  # Get the value of the element at the given index.
  #
  # @param [Integer] i the index from which to retrieve the value
  # @return [Object] the value at the given index or nil if the index is out of bounds
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tuple.rb:43
  def get(i); end

  # Set the element at the given index to the given value
  #
  # @param [Integer] i the index for the element to set
  # @param [Object] value the value to set at the given index
  #
  # @return [Object] the new value of the element at the given index or nil if the index is out of bounds
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tuple.rb:55
  def set(i, value); end

  # The (fixed) size of the tuple.
  #
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tuple.rb:24
  def size; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tuple.rb:47
  def volatile_get(i); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/tuple.rb:59
  def volatile_set(i, value); end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/engine.rb:3
module Concurrent::Utility; end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/engine.rb:6
module Concurrent::Utility::EngineDetector
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/engine.rb:7
  def on_cruby?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/engine.rb:11
  def on_jruby?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/engine.rb:27
  def on_linux?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/engine.rb:23
  def on_osx?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/engine.rb:15
  def on_truffleruby?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/engine.rb:19
  def on_windows?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/engine.rb:31
  def ruby_version(version = T.unsafe(nil), comparison, major, minor, patch); end
end

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb:9
module Concurrent::Utility::NativeExtensionLoader
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb:11
  def allow_c_extensions?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb:15
  def c_extensions_loaded?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb:19
  def load_native_extensions; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb:50
  def java_extensions_loaded?; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb:38
  def load_error_path(error); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb:46
  def set_c_extensions_loaded; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb:54
  def set_java_extensions_loaded; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb:58
  def try_load_c_extension(path); end
end

# @private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_integer.rb:5
module Concurrent::Utility::NativeInteger
  extend ::Concurrent::Utility::NativeInteger

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_integer.rb:24
  def ensure_integer(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_integer.rb:31
  def ensure_integer_and_bounds(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_integer.rb:17
  def ensure_lower_bound(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_integer.rb:37
  def ensure_positive(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_integer.rb:44
  def ensure_positive_and_no_zero(value); end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_integer.rb:10
  def ensure_upper_bound(value); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_integer.rb:8
Concurrent::Utility::NativeInteger::MAX_VALUE = T.let(T.unsafe(nil), Integer)

# http://stackoverflow.com/questions/535721/ruby-max-integer
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/native_integer.rb:7
Concurrent::Utility::NativeInteger::MIN_VALUE = T.let(T.unsafe(nil), Integer)

# @!visibility private
#
# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:10
class Concurrent::Utility::ProcessorCounter
  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:11
  def initialize; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:26
  def available_processor_count; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:41
  def cpu_quota; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:45
  def cpu_shares; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:22
  def physical_processor_count; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:18
  def processor_count; end

  private

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:104
  def compute_cpu_quota; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:124
  def compute_cpu_shares; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:59
  def compute_physical_processor_count; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:51
  def compute_processor_count; end

  # pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/utility/processor_counter.rb:99
  def run(command); end
end

# pkg:gem/concurrent-ruby#lib/concurrent-ruby/concurrent/version.rb:2
Concurrent::VERSION = T.let(T.unsafe(nil), String)
