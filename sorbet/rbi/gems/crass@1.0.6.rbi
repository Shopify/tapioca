# This file is autogenerated. Do not edit it by hand. Regenerate it with:
#   tapioca sync

# typed: true

module Crass
  def self.parse(input, options = _); end
  def self.parse_properties(input, options = _); end
end

class Crass::Parser
  def initialize(input, options = _); end

  def consume_at_rule(input = _); end
  def consume_component_value(input = _); end
  def consume_declaration(input = _); end
  def consume_declarations(input = _, options = _); end
  def consume_function(input = _); end
  def consume_qualified_rule(input = _); end
  def consume_rules(flags = _); end
  def consume_simple_block(input = _); end
  def create_node(type, properties = _); end
  def create_selector(input); end
  def create_style_rule(rule); end
  def parse_component_value(input = _); end
  def parse_component_values(input = _); end
  def parse_declaration(input = _); end
  def parse_declarations(input = _, options = _); end
  def parse_properties(input = _); end
  def parse_rule(input = _); end
  def parse_value(nodes); end
  def tokens; end

  def self.parse_properties(input, options = _); end
  def self.parse_rules(input, options = _); end
  def self.parse_stylesheet(input, options = _); end
  def self.stringify(nodes, options = _); end
end

Crass::Parser::BLOCK_END_TOKENS = T.let(T.unsafe(nil), Hash)

class Crass::Scanner
  def initialize(input); end

  def consume; end
  def consume_rest; end
  def current; end
  def eos?; end
  def mark; end
  def marked; end
  def marker; end
  def marker=(_); end
  def peek(length = _); end
  def pos; end
  def pos=(_); end
  def reconsume; end
  def reset; end
  def scan(pattern); end
  def scan_until(pattern); end
  def string; end
end

class Crass::TokenScanner
  def initialize(tokens); end

  def collect; end
  def consume; end
  def current; end
  def peek; end
  def pos; end
  def reconsume; end
  def reset; end
  def tokens; end
end

class Crass::Tokenizer
  def initialize(input, options = _); end

  def consume; end
  def consume_bad_url; end
  def consume_comments; end
  def consume_escaped; end
  def consume_ident; end
  def consume_name; end
  def consume_number; end
  def consume_numeric; end
  def consume_string(ending = _); end
  def consume_unicode_range; end
  def consume_url; end
  def convert_string_to_number(str); end
  def create_token(type, properties = _); end
  def preprocess(input); end
  def start_identifier?(text = _); end
  def start_number?(text = _); end
  def tokenize; end
  def valid_escape?(text = _); end

  def self.tokenize(input, options = _); end
end

Crass::Tokenizer::RE_COMMENT_CLOSE = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_DIGIT = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_ESCAPE = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_HEX = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_NAME = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_NAME_START = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_NON_PRINTABLE = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_NUMBER_DECIMAL = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_NUMBER_EXPONENT = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_NUMBER_SIGN = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_NUMBER_STR = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_QUOTED_URL_START = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_UNICODE_RANGE_END = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_UNICODE_RANGE_START = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_WHITESPACE = T.let(T.unsafe(nil), Regexp)

Crass::Tokenizer::RE_WHITESPACE_ANCHORED = T.let(T.unsafe(nil), Regexp)
